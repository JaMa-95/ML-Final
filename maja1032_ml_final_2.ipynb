{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maja1032_ML-Final_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eve3qc72IJA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae4a8c9-9fae-498c-83ac-d62d1a006f37"
      },
      "source": [
        "get_ipython().system('git clone https://github.com/JaMa-95/ML-Final.git')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML-Final'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3066 (delta 0), reused 0 (delta 0), pack-reused 3063\u001b[K\n",
            "Receiving objects: 100% (3066/3066), 187.65 MiB | 41.14 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxkgIKQYh8f9"
      },
      "source": [
        "# Final Projext Machine Learning in Python\r\n",
        "**Jakob Mattes**\r\n",
        "\r\n",
        "**Maja1032@hs-karlsruhe.de**\r\n",
        "\r\n",
        "**75269**\r\n",
        "\r\n",
        "Made with google colab\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thc4eiS2HnCd"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import random\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "from tensorflow.keras import applications\r\n",
        "from tensorflow.keras.models import Sequential, Model\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout, MaxPool3D\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "#library np_utils to make labels categorical\r\n",
        "from tensorflow.python.keras.utils import np_utils\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-STbCxoIUT0",
        "outputId": "1bc784e1-2378-4377-b921-0a451b6b62df"
      },
      "source": [
        "categories = ['dog', 'panda', 'cat']\r\n",
        "X_train, X_test = [], []\r\n",
        "y_train, y_test = [], []\r\n",
        "imagePaths = []\r\n",
        "HEIGHT = 32\r\n",
        "WIDTH = 55\r\n",
        "N_CHANNELS = 3\r\n",
        "\r\n",
        "########################################################################\r\n",
        "########Changed the file path because of google colab###################\r\n",
        "########################################################################\r\n",
        "\r\n",
        "# load training data\r\n",
        "for k, category in enumerate(categories):\r\n",
        "    for f in os.listdir('/content/ML-Final/data/train/' + category):\r\n",
        "        imagePaths.append(['/content/ML-Final/data/train/' + category+'/'+f, k])\r\n",
        "\r\n",
        "# loop over the input images\r\n",
        "for imagePath in tqdm(imagePaths):\r\n",
        "    if 'ds_store' in imagePath[0].lower():\r\n",
        "        continue\r\n",
        "    # load the image, resize the image to be HEIGHT * WIDTH pixels (ignoring\r\n",
        "    # aspect ratio) and store the image in the data list\r\n",
        "    image = cv2.imread(imagePath[0])\r\n",
        "    image = cv2.resize(image, (WIDTH, HEIGHT))  # .flatten()\r\n",
        "    X_train.append(image)\r\n",
        "    # extract the class label from the image path and update the\r\n",
        "    # labels list\r\n",
        "    label = imagePath[1]\r\n",
        "    y_train.append(label)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# load test data\r\n",
        "imagePaths = []\r\n",
        "for k, category in enumerate(categories):\r\n",
        "    for f in os.listdir('/content/ML-Final/data/test/' + category):\r\n",
        "        imagePaths.append(['/content/ML-Final/data/test/' + category+'/'+f, k])\r\n",
        "\r\n",
        "# loop over the input images\r\n",
        "for imagePath in tqdm(imagePaths):\r\n",
        "    if 'ds_store' in imagePath[0].lower():\r\n",
        "        continue\r\n",
        "    # load the image, resize the image to be HEIGHT * WIDTH pixels (ignoring\r\n",
        "    # aspect ratio) and store the image in the data list\r\n",
        "    image = cv2.imread(imagePath[0])\r\n",
        "    image = cv2.resize(image, (WIDTH, HEIGHT))  # .flatten()\r\n",
        "    X_test.append(image)\r\n",
        "    # extract the class label from the image path and update the\r\n",
        "    # labels list\r\n",
        "    label = imagePath[1]\r\n",
        "    y_test.append(label)\r\n",
        "\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test  = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\r\n",
        "\r\n",
        "\r\n",
        "############\r\n",
        "# Create here your code. X_train, X_test, and so on is already given and splitted.\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2882/2882 [00:10<00:00, 284.64it/s]\n",
            "100%|██████████| 153/153 [00:00<00:00, 296.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqtXnvwpIbue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1462ca-0604-49b2-a575-0c536cfa75b8"
      },
      "source": [
        "#Make y_train and y_test categorical (three dimensional vector)\r\n",
        "y_train = np_utils.to_categorical(y_train)\r\n",
        "y_test = np_utils.to_categorical(y_test)\r\n",
        "\r\n",
        "#DataGenerator\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "    featurewise_center=False, \r\n",
        "    samplewise_center=False,\r\n",
        "    featurewise_std_normalization=False, \r\n",
        "    samplewise_std_normalization=False,\r\n",
        "    zca_whitening=False, \r\n",
        "    zca_epsilon=1e-06, \r\n",
        "    rotation_range=30, \r\n",
        "    width_shift_range=0.1,\r\n",
        "    height_shift_range=0.1, \r\n",
        "    brightness_range=None, \r\n",
        "    shear_range=0.0, \r\n",
        "    zoom_range=0.2,\r\n",
        "    channel_shift_range=0.0, \r\n",
        "    fill_mode='nearest', \r\n",
        "    cval=0.0,\r\n",
        "    horizontal_flip=True, \r\n",
        "    vertical_flip=True, \r\n",
        "    rescale=1./255,\r\n",
        "    preprocessing_function=None, \r\n",
        "    data_format=None, \r\n",
        "    validation_split=0.0, \r\n",
        "    dtype=None\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "datagen_test = ImageDataGenerator(rescale=1./255, samplewise_center=True)\r\n",
        "\r\n",
        "#Fit datagen to training data\r\n",
        "datagen.fit(X_train)\r\n",
        "\r\n",
        "# Tried to normalize data but no better progress\r\n",
        "#X_train = np.array(X_train)/255\r\n",
        "#X_test = np.array(X_test)/255\r\n",
        "\r\n",
        "#y_train = np.array(y_train)/255\r\n",
        "#y_test = np.array(y_test)/255\r\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2879, 32, 55, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erx4-RneFMcn"
      },
      "source": [
        "#train_flow = datagen.flow_from_dataframe(X_train, x_col ='Filepath', y_col ='Target', target_size=(WIDTH, HEIGHT),interpolation='lanczos', validate_filenames = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2QcMgmOdvl4"
      },
      "source": [
        "# **Self Made Model Start here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G62xoB0keAlB"
      },
      "source": [
        "**Selfmade Model 1**\r\n",
        "\r\n",
        "Good Accuracy/ Bad Val_Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GpK1OwgDI0hF",
        "outputId": "fa400636-d1ce-407d-e852-9a1fcb6461b7"
      },
      "source": [
        "# Define our CNN\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax')) \r\n",
        "\r\n",
        "#apply learning rate to adam optimizer\r\n",
        "opt = optimizers.Adam(learning_rate=0.00001)\r\n",
        "#apply decay rate to optimizer\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=1e-5,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping (not used)\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "#fit call to use the datagen. with 1000 epochs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 35) ,epochs = 1000 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_50 (Conv2D)           (None, 32, 55, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 32, 55, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 16, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 16, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 16, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 8, 14, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 8, 14, 64)         36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 8, 14, 64)         256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 4, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 4, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 4, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 4, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 2, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 2, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 2, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 2, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 1, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 493,571\n",
            "Trainable params: 492,483\n",
            "Non-trainable params: 1,088\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "83/83 [==============================] - 19s 220ms/step - loss: 1.7540 - accuracy: 0.3777 - val_loss: 40.7906 - val_accuracy: 0.3333\n",
            "Epoch 2/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 1.2066 - accuracy: 0.4929 - val_loss: 79.8250 - val_accuracy: 0.3333\n",
            "Epoch 3/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 1.0902 - accuracy: 0.5478 - val_loss: 117.9951 - val_accuracy: 0.3333\n",
            "Epoch 4/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 1.0438 - accuracy: 0.5514 - val_loss: 116.8429 - val_accuracy: 0.3533\n",
            "Epoch 5/1000\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 1.0535 - accuracy: 0.5465 - val_loss: 112.0924 - val_accuracy: 0.4000\n",
            "Epoch 6/1000\n",
            "83/83 [==============================] - 18s 213ms/step - loss: 0.9937 - accuracy: 0.5767 - val_loss: 150.3763 - val_accuracy: 0.3733\n",
            "Epoch 7/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.9794 - accuracy: 0.5810 - val_loss: 152.2687 - val_accuracy: 0.4333\n",
            "Epoch 8/1000\n",
            "83/83 [==============================] - 18s 213ms/step - loss: 0.9356 - accuracy: 0.5891 - val_loss: 172.5931 - val_accuracy: 0.4533\n",
            "Epoch 9/1000\n",
            "83/83 [==============================] - 18s 212ms/step - loss: 0.9638 - accuracy: 0.5897 - val_loss: 163.5648 - val_accuracy: 0.4800\n",
            "Epoch 10/1000\n",
            "83/83 [==============================] - 18s 211ms/step - loss: 0.9070 - accuracy: 0.6062 - val_loss: 177.5105 - val_accuracy: 0.4667\n",
            "Epoch 11/1000\n",
            "83/83 [==============================] - 18s 213ms/step - loss: 0.9227 - accuracy: 0.5938 - val_loss: 185.1959 - val_accuracy: 0.4533\n",
            "Epoch 12/1000\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.8805 - accuracy: 0.6173 - val_loss: 190.8064 - val_accuracy: 0.4800\n",
            "Epoch 13/1000\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.9325 - accuracy: 0.5955 - val_loss: 197.1770 - val_accuracy: 0.4933\n",
            "Epoch 14/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.9061 - accuracy: 0.6163 - val_loss: 186.4022 - val_accuracy: 0.4800\n",
            "Epoch 15/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.9022 - accuracy: 0.6045 - val_loss: 178.6324 - val_accuracy: 0.4933\n",
            "Epoch 16/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.8882 - accuracy: 0.6135 - val_loss: 141.3781 - val_accuracy: 0.5200\n",
            "Epoch 17/1000\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.8462 - accuracy: 0.6343 - val_loss: 144.1576 - val_accuracy: 0.5067\n",
            "Epoch 18/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.8153 - accuracy: 0.6371 - val_loss: 140.7172 - val_accuracy: 0.5133\n",
            "Epoch 19/1000\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.8479 - accuracy: 0.6326 - val_loss: 144.9039 - val_accuracy: 0.4933\n",
            "Epoch 20/1000\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.8171 - accuracy: 0.6455 - val_loss: 138.7038 - val_accuracy: 0.5133\n",
            "Epoch 21/1000\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.8006 - accuracy: 0.6533 - val_loss: 127.2991 - val_accuracy: 0.5333\n",
            "Epoch 22/1000\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.8197 - accuracy: 0.6311 - val_loss: 143.2330 - val_accuracy: 0.5000\n",
            "Epoch 23/1000\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7907 - accuracy: 0.6412 - val_loss: 111.5140 - val_accuracy: 0.5533\n",
            "Epoch 24/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.7673 - accuracy: 0.6865 - val_loss: 134.2541 - val_accuracy: 0.4933\n",
            "Epoch 25/1000\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.8165 - accuracy: 0.6327 - val_loss: 115.9535 - val_accuracy: 0.5067\n",
            "Epoch 26/1000\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.8098 - accuracy: 0.6383 - val_loss: 129.3444 - val_accuracy: 0.5333\n",
            "Epoch 27/1000\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.8051 - accuracy: 0.6403 - val_loss: 131.1736 - val_accuracy: 0.5000\n",
            "Epoch 28/1000\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7919 - accuracy: 0.6515 - val_loss: 178.9824 - val_accuracy: 0.4533\n",
            "Epoch 29/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.7839 - accuracy: 0.6554 - val_loss: 115.2246 - val_accuracy: 0.5333\n",
            "Epoch 30/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7801 - accuracy: 0.6511 - val_loss: 155.4404 - val_accuracy: 0.4667\n",
            "Epoch 31/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7762 - accuracy: 0.6535 - val_loss: 160.2859 - val_accuracy: 0.4667\n",
            "Epoch 32/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.7707 - accuracy: 0.6506 - val_loss: 158.1992 - val_accuracy: 0.4867\n",
            "Epoch 33/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7651 - accuracy: 0.6562 - val_loss: 170.0224 - val_accuracy: 0.5000\n",
            "Epoch 34/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.7729 - accuracy: 0.6651 - val_loss: 151.1046 - val_accuracy: 0.4933\n",
            "Epoch 35/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.7769 - accuracy: 0.6623 - val_loss: 130.3120 - val_accuracy: 0.4933\n",
            "Epoch 36/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.7588 - accuracy: 0.6573 - val_loss: 120.4258 - val_accuracy: 0.5133\n",
            "Epoch 37/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7808 - accuracy: 0.6540 - val_loss: 124.2553 - val_accuracy: 0.5000\n",
            "Epoch 38/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7825 - accuracy: 0.6553 - val_loss: 113.0126 - val_accuracy: 0.5200\n",
            "Epoch 39/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.7561 - accuracy: 0.6653 - val_loss: 96.7616 - val_accuracy: 0.5667\n",
            "Epoch 40/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.7493 - accuracy: 0.6576 - val_loss: 113.7732 - val_accuracy: 0.5200\n",
            "Epoch 41/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.7369 - accuracy: 0.6719 - val_loss: 96.5808 - val_accuracy: 0.5533\n",
            "Epoch 42/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.7598 - accuracy: 0.6729 - val_loss: 114.2317 - val_accuracy: 0.5333\n",
            "Epoch 43/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.7430 - accuracy: 0.6935 - val_loss: 100.4092 - val_accuracy: 0.5267\n",
            "Epoch 44/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.7290 - accuracy: 0.6730 - val_loss: 103.1925 - val_accuracy: 0.5467\n",
            "Epoch 45/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.7514 - accuracy: 0.6782 - val_loss: 105.1116 - val_accuracy: 0.5400\n",
            "Epoch 46/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.7486 - accuracy: 0.6709 - val_loss: 93.5792 - val_accuracy: 0.5733\n",
            "Epoch 47/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7401 - accuracy: 0.6735 - val_loss: 101.1514 - val_accuracy: 0.5333\n",
            "Epoch 48/1000\n",
            "83/83 [==============================] - 18s 224ms/step - loss: 0.7341 - accuracy: 0.6779 - val_loss: 100.2319 - val_accuracy: 0.5600\n",
            "Epoch 49/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.7118 - accuracy: 0.6886 - val_loss: 104.6471 - val_accuracy: 0.5467\n",
            "Epoch 50/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.7589 - accuracy: 0.6468 - val_loss: 98.9406 - val_accuracy: 0.5600\n",
            "Epoch 51/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.6963 - accuracy: 0.6751 - val_loss: 95.4803 - val_accuracy: 0.5733\n",
            "Epoch 52/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.7167 - accuracy: 0.6801 - val_loss: 87.0874 - val_accuracy: 0.5933\n",
            "Epoch 53/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7110 - accuracy: 0.6949 - val_loss: 88.8917 - val_accuracy: 0.5600\n",
            "Epoch 54/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7217 - accuracy: 0.6633 - val_loss: 94.7897 - val_accuracy: 0.5667\n",
            "Epoch 55/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.7240 - accuracy: 0.6773 - val_loss: 116.1068 - val_accuracy: 0.5600\n",
            "Epoch 56/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6886 - accuracy: 0.6948 - val_loss: 95.7890 - val_accuracy: 0.5867\n",
            "Epoch 57/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7028 - accuracy: 0.6931 - val_loss: 85.9319 - val_accuracy: 0.6267\n",
            "Epoch 58/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.7301 - accuracy: 0.6874 - val_loss: 92.7005 - val_accuracy: 0.5867\n",
            "Epoch 59/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6957 - accuracy: 0.6860 - val_loss: 84.8134 - val_accuracy: 0.5933\n",
            "Epoch 60/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.7134 - accuracy: 0.7035 - val_loss: 78.2178 - val_accuracy: 0.6133\n",
            "Epoch 61/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6951 - accuracy: 0.6932 - val_loss: 81.8814 - val_accuracy: 0.6000\n",
            "Epoch 62/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6702 - accuracy: 0.7026 - val_loss: 86.0499 - val_accuracy: 0.6067\n",
            "Epoch 63/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6671 - accuracy: 0.7022 - val_loss: 83.3269 - val_accuracy: 0.6333\n",
            "Epoch 64/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.7027 - accuracy: 0.6923 - val_loss: 79.2209 - val_accuracy: 0.6133\n",
            "Epoch 65/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.7012 - accuracy: 0.6894 - val_loss: 81.8551 - val_accuracy: 0.6267\n",
            "Epoch 66/1000\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.7037 - accuracy: 0.6956 - val_loss: 77.6256 - val_accuracy: 0.5933\n",
            "Epoch 67/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6927 - accuracy: 0.6912 - val_loss: 84.2463 - val_accuracy: 0.5867\n",
            "Epoch 68/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.7089 - accuracy: 0.6868 - val_loss: 78.8559 - val_accuracy: 0.5733\n",
            "Epoch 69/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6764 - accuracy: 0.6980 - val_loss: 84.0006 - val_accuracy: 0.5733\n",
            "Epoch 70/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6846 - accuracy: 0.6921 - val_loss: 99.5886 - val_accuracy: 0.5467\n",
            "Epoch 71/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6806 - accuracy: 0.6981 - val_loss: 93.0391 - val_accuracy: 0.5667\n",
            "Epoch 72/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6589 - accuracy: 0.7186 - val_loss: 89.1943 - val_accuracy: 0.5667\n",
            "Epoch 73/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6871 - accuracy: 0.7026 - val_loss: 89.6684 - val_accuracy: 0.5667\n",
            "Epoch 74/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6591 - accuracy: 0.7126 - val_loss: 96.4837 - val_accuracy: 0.5400\n",
            "Epoch 75/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6951 - accuracy: 0.6988 - val_loss: 89.8244 - val_accuracy: 0.5600\n",
            "Epoch 76/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6798 - accuracy: 0.6935 - val_loss: 91.5044 - val_accuracy: 0.5667\n",
            "Epoch 77/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.7082 - accuracy: 0.6834 - val_loss: 83.4551 - val_accuracy: 0.5733\n",
            "Epoch 78/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6731 - accuracy: 0.7044 - val_loss: 93.7697 - val_accuracy: 0.5600\n",
            "Epoch 79/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6368 - accuracy: 0.7249 - val_loss: 84.7142 - val_accuracy: 0.5267\n",
            "Epoch 80/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6620 - accuracy: 0.7220 - val_loss: 77.3890 - val_accuracy: 0.6133\n",
            "Epoch 81/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6770 - accuracy: 0.7042 - val_loss: 89.7951 - val_accuracy: 0.5667\n",
            "Epoch 82/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6596 - accuracy: 0.7187 - val_loss: 75.5479 - val_accuracy: 0.5733\n",
            "Epoch 83/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6517 - accuracy: 0.7149 - val_loss: 79.8259 - val_accuracy: 0.6133\n",
            "Epoch 84/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6620 - accuracy: 0.7073 - val_loss: 85.2157 - val_accuracy: 0.6133\n",
            "Epoch 85/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6469 - accuracy: 0.7191 - val_loss: 85.4742 - val_accuracy: 0.5867\n",
            "Epoch 86/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6583 - accuracy: 0.7119 - val_loss: 86.7379 - val_accuracy: 0.5800\n",
            "Epoch 87/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6337 - accuracy: 0.7315 - val_loss: 79.7642 - val_accuracy: 0.5867\n",
            "Epoch 88/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6530 - accuracy: 0.7164 - val_loss: 77.5690 - val_accuracy: 0.5867\n",
            "Epoch 89/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6542 - accuracy: 0.6993 - val_loss: 85.8321 - val_accuracy: 0.6133\n",
            "Epoch 90/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6397 - accuracy: 0.7228 - val_loss: 94.2567 - val_accuracy: 0.5867\n",
            "Epoch 91/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6567 - accuracy: 0.7160 - val_loss: 84.7735 - val_accuracy: 0.5667\n",
            "Epoch 92/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6395 - accuracy: 0.7125 - val_loss: 83.2205 - val_accuracy: 0.5733\n",
            "Epoch 93/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6247 - accuracy: 0.7311 - val_loss: 75.8468 - val_accuracy: 0.5533\n",
            "Epoch 94/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6439 - accuracy: 0.7250 - val_loss: 72.0934 - val_accuracy: 0.5800\n",
            "Epoch 95/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6277 - accuracy: 0.7183 - val_loss: 74.5866 - val_accuracy: 0.6000\n",
            "Epoch 96/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6594 - accuracy: 0.7014 - val_loss: 86.9211 - val_accuracy: 0.6000\n",
            "Epoch 97/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6216 - accuracy: 0.7185 - val_loss: 75.0697 - val_accuracy: 0.6333\n",
            "Epoch 98/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6393 - accuracy: 0.7129 - val_loss: 77.9310 - val_accuracy: 0.5800\n",
            "Epoch 99/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6328 - accuracy: 0.7272 - val_loss: 74.6493 - val_accuracy: 0.6133\n",
            "Epoch 100/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6353 - accuracy: 0.7164 - val_loss: 85.6994 - val_accuracy: 0.5933\n",
            "Epoch 101/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6234 - accuracy: 0.7263 - val_loss: 73.3698 - val_accuracy: 0.5800\n",
            "Epoch 102/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6285 - accuracy: 0.7292 - val_loss: 73.2907 - val_accuracy: 0.6267\n",
            "Epoch 103/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6157 - accuracy: 0.7384 - val_loss: 85.7316 - val_accuracy: 0.6333\n",
            "Epoch 104/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.6184 - accuracy: 0.7229 - val_loss: 73.7569 - val_accuracy: 0.6533\n",
            "Epoch 105/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6218 - accuracy: 0.7382 - val_loss: 80.0810 - val_accuracy: 0.5933\n",
            "Epoch 106/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6467 - accuracy: 0.7126 - val_loss: 85.8413 - val_accuracy: 0.6000\n",
            "Epoch 107/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6454 - accuracy: 0.7095 - val_loss: 82.7970 - val_accuracy: 0.5800\n",
            "Epoch 108/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6267 - accuracy: 0.7328 - val_loss: 72.3561 - val_accuracy: 0.6200\n",
            "Epoch 109/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6409 - accuracy: 0.7177 - val_loss: 76.5404 - val_accuracy: 0.5733\n",
            "Epoch 110/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6126 - accuracy: 0.7374 - val_loss: 82.1547 - val_accuracy: 0.5867\n",
            "Epoch 111/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6374 - accuracy: 0.7220 - val_loss: 77.9737 - val_accuracy: 0.6067\n",
            "Epoch 112/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6258 - accuracy: 0.7372 - val_loss: 78.8640 - val_accuracy: 0.5800\n",
            "Epoch 113/1000\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6073 - accuracy: 0.7481 - val_loss: 76.0675 - val_accuracy: 0.5867\n",
            "Epoch 114/1000\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6020 - accuracy: 0.7406 - val_loss: 73.1946 - val_accuracy: 0.5667\n",
            "Epoch 115/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6289 - accuracy: 0.7287 - val_loss: 71.6479 - val_accuracy: 0.5867\n",
            "Epoch 116/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6136 - accuracy: 0.7362 - val_loss: 72.8726 - val_accuracy: 0.6133\n",
            "Epoch 117/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6011 - accuracy: 0.7437 - val_loss: 72.5886 - val_accuracy: 0.6200\n",
            "Epoch 118/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6097 - accuracy: 0.7403 - val_loss: 75.7992 - val_accuracy: 0.5933\n",
            "Epoch 119/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6320 - accuracy: 0.7296 - val_loss: 72.3482 - val_accuracy: 0.6000\n",
            "Epoch 120/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6163 - accuracy: 0.7319 - val_loss: 77.8518 - val_accuracy: 0.6533\n",
            "Epoch 121/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5984 - accuracy: 0.7490 - val_loss: 74.0181 - val_accuracy: 0.6600\n",
            "Epoch 122/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5860 - accuracy: 0.7497 - val_loss: 70.8436 - val_accuracy: 0.6200\n",
            "Epoch 123/1000\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5729 - accuracy: 0.7694 - val_loss: 68.9911 - val_accuracy: 0.6200\n",
            "Epoch 124/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6176 - accuracy: 0.7543 - val_loss: 69.1602 - val_accuracy: 0.5933\n",
            "Epoch 125/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6054 - accuracy: 0.7370 - val_loss: 78.0474 - val_accuracy: 0.6133\n",
            "Epoch 126/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6269 - accuracy: 0.7363 - val_loss: 69.4494 - val_accuracy: 0.6200\n",
            "Epoch 127/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.6081 - accuracy: 0.7375 - val_loss: 73.2828 - val_accuracy: 0.5733\n",
            "Epoch 128/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5976 - accuracy: 0.7345 - val_loss: 68.2697 - val_accuracy: 0.6133\n",
            "Epoch 129/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.6005 - accuracy: 0.7479 - val_loss: 71.9650 - val_accuracy: 0.6067\n",
            "Epoch 130/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.6175 - accuracy: 0.7213 - val_loss: 68.7788 - val_accuracy: 0.6133\n",
            "Epoch 131/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.6020 - accuracy: 0.7336 - val_loss: 68.9337 - val_accuracy: 0.5867\n",
            "Epoch 132/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5813 - accuracy: 0.7529 - val_loss: 69.7410 - val_accuracy: 0.6200\n",
            "Epoch 133/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.6089 - accuracy: 0.7443 - val_loss: 68.7745 - val_accuracy: 0.6200\n",
            "Epoch 134/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.6114 - accuracy: 0.7330 - val_loss: 72.0981 - val_accuracy: 0.5933\n",
            "Epoch 135/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5728 - accuracy: 0.7565 - val_loss: 71.2380 - val_accuracy: 0.5733\n",
            "Epoch 136/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5812 - accuracy: 0.7670 - val_loss: 71.7831 - val_accuracy: 0.6000\n",
            "Epoch 137/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5873 - accuracy: 0.7524 - val_loss: 69.4805 - val_accuracy: 0.6000\n",
            "Epoch 138/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5706 - accuracy: 0.7463 - val_loss: 72.5837 - val_accuracy: 0.5933\n",
            "Epoch 139/1000\n",
            "83/83 [==============================] - 18s 223ms/step - loss: 0.6022 - accuracy: 0.7462 - val_loss: 75.5697 - val_accuracy: 0.5667\n",
            "Epoch 140/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5883 - accuracy: 0.7480 - val_loss: 73.7014 - val_accuracy: 0.6000\n",
            "Epoch 141/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6335 - accuracy: 0.7232 - val_loss: 74.8592 - val_accuracy: 0.6000\n",
            "Epoch 142/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5769 - accuracy: 0.7674 - val_loss: 80.2328 - val_accuracy: 0.6133\n",
            "Epoch 143/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5868 - accuracy: 0.7531 - val_loss: 88.3712 - val_accuracy: 0.5667\n",
            "Epoch 144/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5893 - accuracy: 0.7493 - val_loss: 76.1843 - val_accuracy: 0.5933\n",
            "Epoch 145/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5880 - accuracy: 0.7499 - val_loss: 77.3155 - val_accuracy: 0.6067\n",
            "Epoch 146/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5746 - accuracy: 0.7527 - val_loss: 80.8885 - val_accuracy: 0.6133\n",
            "Epoch 147/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5826 - accuracy: 0.7427 - val_loss: 80.3379 - val_accuracy: 0.6200\n",
            "Epoch 148/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5907 - accuracy: 0.7504 - val_loss: 72.2577 - val_accuracy: 0.5733\n",
            "Epoch 149/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5839 - accuracy: 0.7512 - val_loss: 76.8407 - val_accuracy: 0.5733\n",
            "Epoch 150/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5867 - accuracy: 0.7577 - val_loss: 76.2159 - val_accuracy: 0.5933\n",
            "Epoch 151/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5924 - accuracy: 0.7473 - val_loss: 72.1585 - val_accuracy: 0.6200\n",
            "Epoch 152/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5964 - accuracy: 0.7495 - val_loss: 75.1154 - val_accuracy: 0.6000\n",
            "Epoch 153/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5820 - accuracy: 0.7536 - val_loss: 84.9627 - val_accuracy: 0.5533\n",
            "Epoch 154/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5842 - accuracy: 0.7554 - val_loss: 76.0260 - val_accuracy: 0.5867\n",
            "Epoch 155/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5823 - accuracy: 0.7426 - val_loss: 72.7412 - val_accuracy: 0.6067\n",
            "Epoch 156/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5706 - accuracy: 0.7693 - val_loss: 82.4120 - val_accuracy: 0.6267\n",
            "Epoch 157/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5549 - accuracy: 0.7691 - val_loss: 78.9452 - val_accuracy: 0.6200\n",
            "Epoch 158/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5398 - accuracy: 0.7750 - val_loss: 79.5159 - val_accuracy: 0.6200\n",
            "Epoch 159/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5644 - accuracy: 0.7589 - val_loss: 80.8404 - val_accuracy: 0.6067\n",
            "Epoch 160/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5883 - accuracy: 0.7412 - val_loss: 72.0017 - val_accuracy: 0.6333\n",
            "Epoch 161/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5711 - accuracy: 0.7537 - val_loss: 69.0442 - val_accuracy: 0.6000\n",
            "Epoch 162/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5589 - accuracy: 0.7627 - val_loss: 74.0643 - val_accuracy: 0.6200\n",
            "Epoch 163/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5662 - accuracy: 0.7595 - val_loss: 77.2228 - val_accuracy: 0.5867\n",
            "Epoch 164/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5589 - accuracy: 0.7661 - val_loss: 73.9354 - val_accuracy: 0.6000\n",
            "Epoch 165/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5665 - accuracy: 0.7650 - val_loss: 75.2667 - val_accuracy: 0.6267\n",
            "Epoch 166/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5680 - accuracy: 0.7626 - val_loss: 66.4340 - val_accuracy: 0.6067\n",
            "Epoch 167/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5472 - accuracy: 0.7739 - val_loss: 69.4012 - val_accuracy: 0.6133\n",
            "Epoch 168/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5673 - accuracy: 0.7582 - val_loss: 70.0158 - val_accuracy: 0.6267\n",
            "Epoch 169/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5358 - accuracy: 0.7814 - val_loss: 76.0232 - val_accuracy: 0.6133\n",
            "Epoch 170/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5635 - accuracy: 0.7723 - val_loss: 71.2186 - val_accuracy: 0.6333\n",
            "Epoch 171/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5858 - accuracy: 0.7613 - val_loss: 68.8222 - val_accuracy: 0.6267\n",
            "Epoch 172/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5297 - accuracy: 0.7855 - val_loss: 71.6101 - val_accuracy: 0.6333\n",
            "Epoch 173/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5584 - accuracy: 0.7708 - val_loss: 66.1598 - val_accuracy: 0.6400\n",
            "Epoch 174/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5573 - accuracy: 0.7677 - val_loss: 66.5696 - val_accuracy: 0.6533\n",
            "Epoch 175/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5714 - accuracy: 0.7520 - val_loss: 69.2685 - val_accuracy: 0.6533\n",
            "Epoch 176/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5587 - accuracy: 0.7747 - val_loss: 75.2770 - val_accuracy: 0.6333\n",
            "Epoch 177/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5540 - accuracy: 0.7628 - val_loss: 79.9161 - val_accuracy: 0.6200\n",
            "Epoch 178/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5559 - accuracy: 0.7684 - val_loss: 74.6263 - val_accuracy: 0.6400\n",
            "Epoch 179/1000\n",
            "83/83 [==============================] - 18s 223ms/step - loss: 0.5916 - accuracy: 0.7499 - val_loss: 77.9418 - val_accuracy: 0.6267\n",
            "Epoch 180/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5428 - accuracy: 0.7792 - val_loss: 71.1396 - val_accuracy: 0.6267\n",
            "Epoch 181/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5443 - accuracy: 0.7705 - val_loss: 65.9076 - val_accuracy: 0.6533\n",
            "Epoch 182/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5467 - accuracy: 0.7604 - val_loss: 66.2507 - val_accuracy: 0.6267\n",
            "Epoch 183/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5645 - accuracy: 0.7681 - val_loss: 70.6772 - val_accuracy: 0.6200\n",
            "Epoch 184/1000\n",
            "83/83 [==============================] - 18s 223ms/step - loss: 0.5225 - accuracy: 0.7883 - val_loss: 68.6458 - val_accuracy: 0.6267\n",
            "Epoch 185/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5470 - accuracy: 0.7724 - val_loss: 63.5017 - val_accuracy: 0.6467\n",
            "Epoch 186/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.5412 - accuracy: 0.7705 - val_loss: 59.8984 - val_accuracy: 0.6400\n",
            "Epoch 187/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.5328 - accuracy: 0.7738 - val_loss: 62.9431 - val_accuracy: 0.6267\n",
            "Epoch 188/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.5421 - accuracy: 0.7816 - val_loss: 62.7058 - val_accuracy: 0.6267\n",
            "Epoch 189/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.5553 - accuracy: 0.7736 - val_loss: 65.7238 - val_accuracy: 0.6267\n",
            "Epoch 190/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5174 - accuracy: 0.7801 - val_loss: 67.7134 - val_accuracy: 0.6400\n",
            "Epoch 191/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5286 - accuracy: 0.7884 - val_loss: 64.4062 - val_accuracy: 0.6533\n",
            "Epoch 192/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5326 - accuracy: 0.7699 - val_loss: 68.6914 - val_accuracy: 0.6333\n",
            "Epoch 193/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5324 - accuracy: 0.7634 - val_loss: 81.5135 - val_accuracy: 0.6267\n",
            "Epoch 194/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5226 - accuracy: 0.7891 - val_loss: 81.1541 - val_accuracy: 0.6200\n",
            "Epoch 195/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5473 - accuracy: 0.7702 - val_loss: 77.5066 - val_accuracy: 0.6400\n",
            "Epoch 196/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5416 - accuracy: 0.7853 - val_loss: 95.6050 - val_accuracy: 0.6000\n",
            "Epoch 197/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5294 - accuracy: 0.7731 - val_loss: 71.3451 - val_accuracy: 0.6467\n",
            "Epoch 198/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5218 - accuracy: 0.7896 - val_loss: 79.2861 - val_accuracy: 0.6267\n",
            "Epoch 199/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5349 - accuracy: 0.7751 - val_loss: 69.4464 - val_accuracy: 0.6533\n",
            "Epoch 200/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5353 - accuracy: 0.7695 - val_loss: 69.9264 - val_accuracy: 0.6333\n",
            "Epoch 201/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5381 - accuracy: 0.7701 - val_loss: 70.7056 - val_accuracy: 0.6400\n",
            "Epoch 202/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 69.0861 - val_accuracy: 0.6200\n",
            "Epoch 203/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5323 - accuracy: 0.7763 - val_loss: 67.6770 - val_accuracy: 0.6267\n",
            "Epoch 204/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5120 - accuracy: 0.7848 - val_loss: 68.5516 - val_accuracy: 0.6333\n",
            "Epoch 205/1000\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5368 - accuracy: 0.7702 - val_loss: 63.4568 - val_accuracy: 0.6467\n",
            "Epoch 206/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5334 - accuracy: 0.7773 - val_loss: 69.3982 - val_accuracy: 0.5867\n",
            "Epoch 207/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5481 - accuracy: 0.7608 - val_loss: 62.7596 - val_accuracy: 0.6133\n",
            "Epoch 208/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5310 - accuracy: 0.7829 - val_loss: 65.4140 - val_accuracy: 0.6333\n",
            "Epoch 209/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5406 - accuracy: 0.7759 - val_loss: 62.2306 - val_accuracy: 0.6200\n",
            "Epoch 210/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5473 - accuracy: 0.7786 - val_loss: 65.6681 - val_accuracy: 0.6200\n",
            "Epoch 211/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5385 - accuracy: 0.7822 - val_loss: 65.9551 - val_accuracy: 0.6200\n",
            "Epoch 212/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5286 - accuracy: 0.7823 - val_loss: 63.3617 - val_accuracy: 0.6133\n",
            "Epoch 213/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5403 - accuracy: 0.7768 - val_loss: 64.9870 - val_accuracy: 0.6267\n",
            "Epoch 214/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5187 - accuracy: 0.7913 - val_loss: 69.6531 - val_accuracy: 0.6200\n",
            "Epoch 215/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5320 - accuracy: 0.7763 - val_loss: 75.5800 - val_accuracy: 0.5867\n",
            "Epoch 216/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5313 - accuracy: 0.7769 - val_loss: 69.2863 - val_accuracy: 0.6133\n",
            "Epoch 217/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5049 - accuracy: 0.7954 - val_loss: 78.7343 - val_accuracy: 0.6333\n",
            "Epoch 218/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5191 - accuracy: 0.7651 - val_loss: 80.1901 - val_accuracy: 0.6000\n",
            "Epoch 219/1000\n",
            "83/83 [==============================] - 18s 223ms/step - loss: 0.5125 - accuracy: 0.7830 - val_loss: 71.4067 - val_accuracy: 0.6267\n",
            "Epoch 220/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5154 - accuracy: 0.7852 - val_loss: 70.6088 - val_accuracy: 0.6200\n",
            "Epoch 221/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5086 - accuracy: 0.7862 - val_loss: 71.0965 - val_accuracy: 0.6200\n",
            "Epoch 222/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5201 - accuracy: 0.7713 - val_loss: 72.5277 - val_accuracy: 0.5800\n",
            "Epoch 223/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5272 - accuracy: 0.7973 - val_loss: 78.1627 - val_accuracy: 0.6333\n",
            "Epoch 224/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5262 - accuracy: 0.7802 - val_loss: 70.8669 - val_accuracy: 0.6000\n",
            "Epoch 225/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5317 - accuracy: 0.7755 - val_loss: 86.5001 - val_accuracy: 0.5400\n",
            "Epoch 226/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5152 - accuracy: 0.7910 - val_loss: 69.5918 - val_accuracy: 0.6067\n",
            "Epoch 227/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.5123 - accuracy: 0.7957 - val_loss: 76.5373 - val_accuracy: 0.6133\n",
            "Epoch 228/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5039 - accuracy: 0.8011 - val_loss: 70.7440 - val_accuracy: 0.6267\n",
            "Epoch 229/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5116 - accuracy: 0.7904 - val_loss: 71.3842 - val_accuracy: 0.6200\n",
            "Epoch 230/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5067 - accuracy: 0.7892 - val_loss: 79.1839 - val_accuracy: 0.6200\n",
            "Epoch 231/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5256 - accuracy: 0.7764 - val_loss: 72.9071 - val_accuracy: 0.6133\n",
            "Epoch 232/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5097 - accuracy: 0.7948 - val_loss: 69.4963 - val_accuracy: 0.6067\n",
            "Epoch 233/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5250 - accuracy: 0.7847 - val_loss: 71.3983 - val_accuracy: 0.6067\n",
            "Epoch 234/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5137 - accuracy: 0.7813 - val_loss: 64.6896 - val_accuracy: 0.6000\n",
            "Epoch 235/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.4854 - accuracy: 0.8046 - val_loss: 68.1099 - val_accuracy: 0.5933\n",
            "Epoch 236/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5129 - accuracy: 0.7906 - val_loss: 65.0583 - val_accuracy: 0.5867\n",
            "Epoch 237/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5008 - accuracy: 0.8003 - val_loss: 64.8249 - val_accuracy: 0.6333\n",
            "Epoch 238/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.4997 - accuracy: 0.7828 - val_loss: 68.8429 - val_accuracy: 0.6133\n",
            "Epoch 239/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.4864 - accuracy: 0.7925 - val_loss: 68.4261 - val_accuracy: 0.6200\n",
            "Epoch 240/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5014 - accuracy: 0.7920 - val_loss: 67.1443 - val_accuracy: 0.6133\n",
            "Epoch 241/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4944 - accuracy: 0.8030 - val_loss: 69.5667 - val_accuracy: 0.6200\n",
            "Epoch 242/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5431 - accuracy: 0.7758 - val_loss: 63.9359 - val_accuracy: 0.6133\n",
            "Epoch 243/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5075 - accuracy: 0.7935 - val_loss: 63.1976 - val_accuracy: 0.6200\n",
            "Epoch 244/1000\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.4995 - accuracy: 0.7930 - val_loss: 72.0639 - val_accuracy: 0.6600\n",
            "Epoch 245/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.4979 - accuracy: 0.7980 - val_loss: 81.3538 - val_accuracy: 0.6267\n",
            "Epoch 246/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.4998 - accuracy: 0.8015 - val_loss: 76.8138 - val_accuracy: 0.6333\n",
            "Epoch 247/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5136 - accuracy: 0.7822 - val_loss: 74.9184 - val_accuracy: 0.6267\n",
            "Epoch 248/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5013 - accuracy: 0.7971 - val_loss: 75.7116 - val_accuracy: 0.6267\n",
            "Epoch 249/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.4919 - accuracy: 0.7921 - val_loss: 77.7631 - val_accuracy: 0.6467\n",
            "Epoch 250/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5026 - accuracy: 0.7935 - val_loss: 73.6172 - val_accuracy: 0.6467\n",
            "Epoch 251/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5252 - accuracy: 0.7848 - val_loss: 69.7546 - val_accuracy: 0.6600\n",
            "Epoch 252/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5024 - accuracy: 0.7861 - val_loss: 67.6904 - val_accuracy: 0.6467\n",
            "Epoch 253/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4873 - accuracy: 0.8018 - val_loss: 66.9298 - val_accuracy: 0.6067\n",
            "Epoch 254/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.4971 - accuracy: 0.7875 - val_loss: 72.1854 - val_accuracy: 0.6333\n",
            "Epoch 255/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5016 - accuracy: 0.7955 - val_loss: 75.2523 - val_accuracy: 0.6067\n",
            "Epoch 256/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5082 - accuracy: 0.7830 - val_loss: 69.8631 - val_accuracy: 0.6200\n",
            "Epoch 257/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5240 - accuracy: 0.7925 - val_loss: 71.2813 - val_accuracy: 0.5933\n",
            "Epoch 258/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5058 - accuracy: 0.7867 - val_loss: 70.7959 - val_accuracy: 0.5867\n",
            "Epoch 259/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4652 - accuracy: 0.8088 - val_loss: 66.9884 - val_accuracy: 0.6267\n",
            "Epoch 260/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4787 - accuracy: 0.7986 - val_loss: 70.3281 - val_accuracy: 0.6267\n",
            "Epoch 261/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.4843 - accuracy: 0.7876 - val_loss: 72.0973 - val_accuracy: 0.6000\n",
            "Epoch 262/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4870 - accuracy: 0.8104 - val_loss: 71.7177 - val_accuracy: 0.6133\n",
            "Epoch 263/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4794 - accuracy: 0.8090 - val_loss: 71.7447 - val_accuracy: 0.6200\n",
            "Epoch 264/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4889 - accuracy: 0.8031 - val_loss: 69.8333 - val_accuracy: 0.6333\n",
            "Epoch 265/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5008 - accuracy: 0.7960 - val_loss: 77.2875 - val_accuracy: 0.6000\n",
            "Epoch 266/1000\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.4798 - accuracy: 0.8143 - val_loss: 67.7749 - val_accuracy: 0.6200\n",
            "Epoch 267/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4875 - accuracy: 0.7944 - val_loss: 68.2767 - val_accuracy: 0.6267\n",
            "Epoch 268/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4869 - accuracy: 0.8091 - val_loss: 76.3383 - val_accuracy: 0.6067\n",
            "Epoch 269/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4940 - accuracy: 0.8008 - val_loss: 72.0860 - val_accuracy: 0.5933\n",
            "Epoch 270/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4931 - accuracy: 0.7918 - val_loss: 64.1326 - val_accuracy: 0.6333\n",
            "Epoch 271/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4609 - accuracy: 0.8164 - val_loss: 77.7808 - val_accuracy: 0.5933\n",
            "Epoch 272/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4771 - accuracy: 0.8065 - val_loss: 72.9679 - val_accuracy: 0.5933\n",
            "Epoch 273/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4800 - accuracy: 0.7939 - val_loss: 65.9418 - val_accuracy: 0.6133\n",
            "Epoch 274/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4968 - accuracy: 0.7949 - val_loss: 70.5578 - val_accuracy: 0.6067\n",
            "Epoch 275/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.5048 - accuracy: 0.7899 - val_loss: 62.1807 - val_accuracy: 0.6067\n",
            "Epoch 276/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4968 - accuracy: 0.7861 - val_loss: 63.5216 - val_accuracy: 0.6133\n",
            "Epoch 277/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4821 - accuracy: 0.8120 - val_loss: 67.5374 - val_accuracy: 0.6067\n",
            "Epoch 278/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4692 - accuracy: 0.8201 - val_loss: 62.0970 - val_accuracy: 0.6200\n",
            "Epoch 279/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5079 - accuracy: 0.7918 - val_loss: 65.4076 - val_accuracy: 0.6267\n",
            "Epoch 280/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4581 - accuracy: 0.8032 - val_loss: 67.5624 - val_accuracy: 0.6200\n",
            "Epoch 281/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4888 - accuracy: 0.7885 - val_loss: 68.7187 - val_accuracy: 0.6000\n",
            "Epoch 282/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4888 - accuracy: 0.8013 - val_loss: 60.2531 - val_accuracy: 0.6200\n",
            "Epoch 283/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4849 - accuracy: 0.7917 - val_loss: 67.3943 - val_accuracy: 0.6200\n",
            "Epoch 284/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4884 - accuracy: 0.7962 - val_loss: 72.7710 - val_accuracy: 0.5933\n",
            "Epoch 285/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4684 - accuracy: 0.8061 - val_loss: 88.3956 - val_accuracy: 0.5667\n",
            "Epoch 286/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4665 - accuracy: 0.8194 - val_loss: 87.5248 - val_accuracy: 0.5667\n",
            "Epoch 287/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4660 - accuracy: 0.8149 - val_loss: 71.7881 - val_accuracy: 0.5533\n",
            "Epoch 288/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4840 - accuracy: 0.8077 - val_loss: 67.8211 - val_accuracy: 0.5867\n",
            "Epoch 289/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4833 - accuracy: 0.8023 - val_loss: 63.3791 - val_accuracy: 0.6000\n",
            "Epoch 290/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4727 - accuracy: 0.8046 - val_loss: 66.6359 - val_accuracy: 0.6200\n",
            "Epoch 291/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4730 - accuracy: 0.8134 - val_loss: 65.3928 - val_accuracy: 0.6200\n",
            "Epoch 292/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4812 - accuracy: 0.8083 - val_loss: 76.1502 - val_accuracy: 0.5867\n",
            "Epoch 293/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4820 - accuracy: 0.8038 - val_loss: 67.3188 - val_accuracy: 0.5867\n",
            "Epoch 294/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4656 - accuracy: 0.8096 - val_loss: 60.8032 - val_accuracy: 0.6067\n",
            "Epoch 295/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4977 - accuracy: 0.7945 - val_loss: 59.3316 - val_accuracy: 0.6067\n",
            "Epoch 296/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4771 - accuracy: 0.8066 - val_loss: 59.8116 - val_accuracy: 0.6333\n",
            "Epoch 297/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4809 - accuracy: 0.8031 - val_loss: 70.5124 - val_accuracy: 0.5867\n",
            "Epoch 298/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4551 - accuracy: 0.8148 - val_loss: 68.5005 - val_accuracy: 0.6000\n",
            "Epoch 299/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4554 - accuracy: 0.8215 - val_loss: 66.5115 - val_accuracy: 0.6133\n",
            "Epoch 300/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4694 - accuracy: 0.8097 - val_loss: 89.9634 - val_accuracy: 0.5933\n",
            "Epoch 301/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4646 - accuracy: 0.8198 - val_loss: 80.3519 - val_accuracy: 0.6000\n",
            "Epoch 302/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4799 - accuracy: 0.8058 - val_loss: 68.6109 - val_accuracy: 0.6200\n",
            "Epoch 303/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4843 - accuracy: 0.7974 - val_loss: 74.7516 - val_accuracy: 0.5933\n",
            "Epoch 304/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4812 - accuracy: 0.8079 - val_loss: 75.9380 - val_accuracy: 0.5600\n",
            "Epoch 305/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4432 - accuracy: 0.8341 - val_loss: 64.6295 - val_accuracy: 0.6000\n",
            "Epoch 306/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4673 - accuracy: 0.8043 - val_loss: 78.0723 - val_accuracy: 0.5800\n",
            "Epoch 307/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4566 - accuracy: 0.8065 - val_loss: 78.8884 - val_accuracy: 0.5667\n",
            "Epoch 308/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4562 - accuracy: 0.8168 - val_loss: 93.9182 - val_accuracy: 0.5600\n",
            "Epoch 309/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4523 - accuracy: 0.8287 - val_loss: 83.1812 - val_accuracy: 0.5533\n",
            "Epoch 310/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4693 - accuracy: 0.8127 - val_loss: 79.7158 - val_accuracy: 0.5733\n",
            "Epoch 311/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4756 - accuracy: 0.8170 - val_loss: 72.3863 - val_accuracy: 0.6067\n",
            "Epoch 312/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4492 - accuracy: 0.8320 - val_loss: 66.7640 - val_accuracy: 0.6133\n",
            "Epoch 313/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4612 - accuracy: 0.8050 - val_loss: 65.2522 - val_accuracy: 0.6267\n",
            "Epoch 314/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4816 - accuracy: 0.8015 - val_loss: 69.5901 - val_accuracy: 0.6133\n",
            "Epoch 315/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4799 - accuracy: 0.7959 - val_loss: 63.7936 - val_accuracy: 0.6267\n",
            "Epoch 316/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4819 - accuracy: 0.8048 - val_loss: 73.4567 - val_accuracy: 0.5867\n",
            "Epoch 317/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4534 - accuracy: 0.8172 - val_loss: 81.4331 - val_accuracy: 0.5800\n",
            "Epoch 318/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4472 - accuracy: 0.8106 - val_loss: 83.6387 - val_accuracy: 0.5800\n",
            "Epoch 319/1000\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.4691 - accuracy: 0.8112 - val_loss: 77.1644 - val_accuracy: 0.5867\n",
            "Epoch 320/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4784 - accuracy: 0.8048 - val_loss: 70.6215 - val_accuracy: 0.6067\n",
            "Epoch 321/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4714 - accuracy: 0.8106 - val_loss: 69.5790 - val_accuracy: 0.6133\n",
            "Epoch 322/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4837 - accuracy: 0.8083 - val_loss: 76.3688 - val_accuracy: 0.5933\n",
            "Epoch 323/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4604 - accuracy: 0.8112 - val_loss: 79.1726 - val_accuracy: 0.5667\n",
            "Epoch 324/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4860 - accuracy: 0.8000 - val_loss: 80.0855 - val_accuracy: 0.5733\n",
            "Epoch 325/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4585 - accuracy: 0.8114 - val_loss: 65.0398 - val_accuracy: 0.6267\n",
            "Epoch 326/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4666 - accuracy: 0.8187 - val_loss: 72.6960 - val_accuracy: 0.5933\n",
            "Epoch 327/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4676 - accuracy: 0.8109 - val_loss: 76.8303 - val_accuracy: 0.5933\n",
            "Epoch 328/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4797 - accuracy: 0.8073 - val_loss: 71.5211 - val_accuracy: 0.6000\n",
            "Epoch 329/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4450 - accuracy: 0.8173 - val_loss: 83.4659 - val_accuracy: 0.5933\n",
            "Epoch 330/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4687 - accuracy: 0.7979 - val_loss: 71.8398 - val_accuracy: 0.5933\n",
            "Epoch 331/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4806 - accuracy: 0.8061 - val_loss: 83.8652 - val_accuracy: 0.5667\n",
            "Epoch 332/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4424 - accuracy: 0.8181 - val_loss: 75.5844 - val_accuracy: 0.5667\n",
            "Epoch 333/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4753 - accuracy: 0.7976 - val_loss: 77.6700 - val_accuracy: 0.5533\n",
            "Epoch 334/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4528 - accuracy: 0.8178 - val_loss: 92.2338 - val_accuracy: 0.5400\n",
            "Epoch 335/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4469 - accuracy: 0.8235 - val_loss: 85.3499 - val_accuracy: 0.5533\n",
            "Epoch 336/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4669 - accuracy: 0.8042 - val_loss: 77.7097 - val_accuracy: 0.5667\n",
            "Epoch 337/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4475 - accuracy: 0.8243 - val_loss: 76.4895 - val_accuracy: 0.5467\n",
            "Epoch 338/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4803 - accuracy: 0.8158 - val_loss: 73.6579 - val_accuracy: 0.6000\n",
            "Epoch 339/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4216 - accuracy: 0.8389 - val_loss: 74.7391 - val_accuracy: 0.5667\n",
            "Epoch 340/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4523 - accuracy: 0.8223 - val_loss: 77.4101 - val_accuracy: 0.5933\n",
            "Epoch 341/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4643 - accuracy: 0.8138 - val_loss: 87.6712 - val_accuracy: 0.5333\n",
            "Epoch 342/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4740 - accuracy: 0.8003 - val_loss: 75.8918 - val_accuracy: 0.5667\n",
            "Epoch 343/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4463 - accuracy: 0.8354 - val_loss: 83.1355 - val_accuracy: 0.5667\n",
            "Epoch 344/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4479 - accuracy: 0.8290 - val_loss: 70.6348 - val_accuracy: 0.5867\n",
            "Epoch 345/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4559 - accuracy: 0.8199 - val_loss: 83.4835 - val_accuracy: 0.5867\n",
            "Epoch 346/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4437 - accuracy: 0.8275 - val_loss: 75.4198 - val_accuracy: 0.5733\n",
            "Epoch 347/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4795 - accuracy: 0.8047 - val_loss: 78.8293 - val_accuracy: 0.5533\n",
            "Epoch 348/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4720 - accuracy: 0.8090 - val_loss: 85.8350 - val_accuracy: 0.5400\n",
            "Epoch 349/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4475 - accuracy: 0.8145 - val_loss: 79.6353 - val_accuracy: 0.5467\n",
            "Epoch 350/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4395 - accuracy: 0.8198 - val_loss: 85.7645 - val_accuracy: 0.5667\n",
            "Epoch 351/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4482 - accuracy: 0.8274 - val_loss: 83.0021 - val_accuracy: 0.5733\n",
            "Epoch 352/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4589 - accuracy: 0.8051 - val_loss: 89.3568 - val_accuracy: 0.5600\n",
            "Epoch 353/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4347 - accuracy: 0.8267 - val_loss: 89.3076 - val_accuracy: 0.5733\n",
            "Epoch 354/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4323 - accuracy: 0.8291 - val_loss: 90.7779 - val_accuracy: 0.5667\n",
            "Epoch 355/1000\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4192 - accuracy: 0.8386 - val_loss: 95.8499 - val_accuracy: 0.5533\n",
            "Epoch 356/1000\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4423 - accuracy: 0.8241 - val_loss: 102.7757 - val_accuracy: 0.5533\n",
            "Epoch 357/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4590 - accuracy: 0.8110 - val_loss: 97.5328 - val_accuracy: 0.5667\n",
            "Epoch 358/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4356 - accuracy: 0.8290 - val_loss: 97.7847 - val_accuracy: 0.5467\n",
            "Epoch 359/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4406 - accuracy: 0.8300 - val_loss: 94.3256 - val_accuracy: 0.5533\n",
            "Epoch 360/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4711 - accuracy: 0.8127 - val_loss: 94.6714 - val_accuracy: 0.5733\n",
            "Epoch 361/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4449 - accuracy: 0.8225 - val_loss: 75.4572 - val_accuracy: 0.5933\n",
            "Epoch 362/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4682 - accuracy: 0.8172 - val_loss: 106.6720 - val_accuracy: 0.5733\n",
            "Epoch 363/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4500 - accuracy: 0.8199 - val_loss: 81.9156 - val_accuracy: 0.5800\n",
            "Epoch 364/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4391 - accuracy: 0.8201 - val_loss: 82.8813 - val_accuracy: 0.5800\n",
            "Epoch 365/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4458 - accuracy: 0.8149 - val_loss: 99.6841 - val_accuracy: 0.5800\n",
            "Epoch 366/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4463 - accuracy: 0.8217 - val_loss: 91.1012 - val_accuracy: 0.5933\n",
            "Epoch 367/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4604 - accuracy: 0.8050 - val_loss: 93.3555 - val_accuracy: 0.5867\n",
            "Epoch 368/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4439 - accuracy: 0.8254 - val_loss: 84.0405 - val_accuracy: 0.5867\n",
            "Epoch 369/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4287 - accuracy: 0.8377 - val_loss: 97.9884 - val_accuracy: 0.5667\n",
            "Epoch 370/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4470 - accuracy: 0.8158 - val_loss: 105.9066 - val_accuracy: 0.5933\n",
            "Epoch 371/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4477 - accuracy: 0.8248 - val_loss: 116.4514 - val_accuracy: 0.5733\n",
            "Epoch 372/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4310 - accuracy: 0.8369 - val_loss: 96.8761 - val_accuracy: 0.5667\n",
            "Epoch 373/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4538 - accuracy: 0.8155 - val_loss: 83.1893 - val_accuracy: 0.6067\n",
            "Epoch 374/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4254 - accuracy: 0.8223 - val_loss: 88.7637 - val_accuracy: 0.6067\n",
            "Epoch 375/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4542 - accuracy: 0.8147 - val_loss: 108.6481 - val_accuracy: 0.5933\n",
            "Epoch 376/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4205 - accuracy: 0.8303 - val_loss: 96.8584 - val_accuracy: 0.6133\n",
            "Epoch 377/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4483 - accuracy: 0.8294 - val_loss: 95.0115 - val_accuracy: 0.6000\n",
            "Epoch 378/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4386 - accuracy: 0.8232 - val_loss: 92.3045 - val_accuracy: 0.5800\n",
            "Epoch 379/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4581 - accuracy: 0.8133 - val_loss: 98.5211 - val_accuracy: 0.5733\n",
            "Epoch 380/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4228 - accuracy: 0.8455 - val_loss: 95.4990 - val_accuracy: 0.5800\n",
            "Epoch 381/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4274 - accuracy: 0.8304 - val_loss: 96.1951 - val_accuracy: 0.5867\n",
            "Epoch 382/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4478 - accuracy: 0.8226 - val_loss: 102.0218 - val_accuracy: 0.5667\n",
            "Epoch 383/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4295 - accuracy: 0.8307 - val_loss: 87.2023 - val_accuracy: 0.5933\n",
            "Epoch 384/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4373 - accuracy: 0.8208 - val_loss: 101.7737 - val_accuracy: 0.5733\n",
            "Epoch 385/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4138 - accuracy: 0.8369 - val_loss: 98.4401 - val_accuracy: 0.5667\n",
            "Epoch 386/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4140 - accuracy: 0.8328 - val_loss: 103.2364 - val_accuracy: 0.5667\n",
            "Epoch 387/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4282 - accuracy: 0.8310 - val_loss: 97.5678 - val_accuracy: 0.5733\n",
            "Epoch 388/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4341 - accuracy: 0.8332 - val_loss: 91.9537 - val_accuracy: 0.5600\n",
            "Epoch 389/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4326 - accuracy: 0.8383 - val_loss: 102.0194 - val_accuracy: 0.5400\n",
            "Epoch 390/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4461 - accuracy: 0.8308 - val_loss: 95.4692 - val_accuracy: 0.5600\n",
            "Epoch 391/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4354 - accuracy: 0.8317 - val_loss: 98.8065 - val_accuracy: 0.5400\n",
            "Epoch 392/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4562 - accuracy: 0.8195 - val_loss: 98.4743 - val_accuracy: 0.5733\n",
            "Epoch 393/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4400 - accuracy: 0.8252 - val_loss: 117.6301 - val_accuracy: 0.5267\n",
            "Epoch 394/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4309 - accuracy: 0.8275 - val_loss: 125.2544 - val_accuracy: 0.5267\n",
            "Epoch 395/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4413 - accuracy: 0.8246 - val_loss: 99.0551 - val_accuracy: 0.5667\n",
            "Epoch 396/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4367 - accuracy: 0.8262 - val_loss: 98.1082 - val_accuracy: 0.5600\n",
            "Epoch 397/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4095 - accuracy: 0.8400 - val_loss: 88.8764 - val_accuracy: 0.5667\n",
            "Epoch 398/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4114 - accuracy: 0.8474 - val_loss: 86.8042 - val_accuracy: 0.5400\n",
            "Epoch 399/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4250 - accuracy: 0.8347 - val_loss: 79.5871 - val_accuracy: 0.5733\n",
            "Epoch 400/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4242 - accuracy: 0.8367 - val_loss: 88.1971 - val_accuracy: 0.5600\n",
            "Epoch 401/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4195 - accuracy: 0.8296 - val_loss: 92.0389 - val_accuracy: 0.5600\n",
            "Epoch 402/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4173 - accuracy: 0.8396 - val_loss: 97.7752 - val_accuracy: 0.5667\n",
            "Epoch 403/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4473 - accuracy: 0.8149 - val_loss: 88.4579 - val_accuracy: 0.5800\n",
            "Epoch 404/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4065 - accuracy: 0.8407 - val_loss: 100.1454 - val_accuracy: 0.5667\n",
            "Epoch 405/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4069 - accuracy: 0.8417 - val_loss: 101.2872 - val_accuracy: 0.5867\n",
            "Epoch 406/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4119 - accuracy: 0.8406 - val_loss: 87.4130 - val_accuracy: 0.5800\n",
            "Epoch 407/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4368 - accuracy: 0.8332 - val_loss: 109.8942 - val_accuracy: 0.5267\n",
            "Epoch 408/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4090 - accuracy: 0.8319 - val_loss: 107.9501 - val_accuracy: 0.5533\n",
            "Epoch 409/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4081 - accuracy: 0.8433 - val_loss: 95.3175 - val_accuracy: 0.5733\n",
            "Epoch 410/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4171 - accuracy: 0.8377 - val_loss: 95.8109 - val_accuracy: 0.5533\n",
            "Epoch 411/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.4339 - accuracy: 0.8263 - val_loss: 106.0474 - val_accuracy: 0.5600\n",
            "Epoch 412/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4334 - accuracy: 0.8365 - val_loss: 100.8625 - val_accuracy: 0.5400\n",
            "Epoch 413/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4289 - accuracy: 0.8267 - val_loss: 109.4005 - val_accuracy: 0.5600\n",
            "Epoch 414/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4069 - accuracy: 0.8406 - val_loss: 110.0474 - val_accuracy: 0.5333\n",
            "Epoch 415/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4016 - accuracy: 0.8499 - val_loss: 108.8476 - val_accuracy: 0.5267\n",
            "Epoch 416/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4339 - accuracy: 0.8259 - val_loss: 126.4908 - val_accuracy: 0.5267\n",
            "Epoch 417/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4364 - accuracy: 0.8278 - val_loss: 107.8838 - val_accuracy: 0.5400\n",
            "Epoch 418/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4246 - accuracy: 0.8188 - val_loss: 128.1732 - val_accuracy: 0.5267\n",
            "Epoch 419/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4264 - accuracy: 0.8323 - val_loss: 146.3213 - val_accuracy: 0.4667\n",
            "Epoch 420/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4244 - accuracy: 0.8372 - val_loss: 117.5791 - val_accuracy: 0.5133\n",
            "Epoch 421/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4186 - accuracy: 0.8447 - val_loss: 118.0222 - val_accuracy: 0.5333\n",
            "Epoch 422/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4329 - accuracy: 0.8279 - val_loss: 127.2045 - val_accuracy: 0.5000\n",
            "Epoch 423/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4198 - accuracy: 0.8352 - val_loss: 122.0447 - val_accuracy: 0.5133\n",
            "Epoch 424/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.3995 - accuracy: 0.8478 - val_loss: 139.6039 - val_accuracy: 0.4933\n",
            "Epoch 425/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4152 - accuracy: 0.8318 - val_loss: 125.2537 - val_accuracy: 0.5200\n",
            "Epoch 426/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4120 - accuracy: 0.8462 - val_loss: 141.0019 - val_accuracy: 0.4867\n",
            "Epoch 427/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4163 - accuracy: 0.8310 - val_loss: 133.8486 - val_accuracy: 0.4933\n",
            "Epoch 428/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3902 - accuracy: 0.8465 - val_loss: 119.9024 - val_accuracy: 0.5133\n",
            "Epoch 429/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4219 - accuracy: 0.8258 - val_loss: 129.5455 - val_accuracy: 0.5133\n",
            "Epoch 430/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4425 - accuracy: 0.8127 - val_loss: 115.5811 - val_accuracy: 0.5333\n",
            "Epoch 431/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4305 - accuracy: 0.8318 - val_loss: 127.2281 - val_accuracy: 0.5000\n",
            "Epoch 432/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4104 - accuracy: 0.8372 - val_loss: 116.9072 - val_accuracy: 0.5400\n",
            "Epoch 433/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4179 - accuracy: 0.8329 - val_loss: 107.6740 - val_accuracy: 0.5400\n",
            "Epoch 434/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4142 - accuracy: 0.8385 - val_loss: 107.8169 - val_accuracy: 0.5400\n",
            "Epoch 435/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4093 - accuracy: 0.8391 - val_loss: 110.9277 - val_accuracy: 0.5267\n",
            "Epoch 436/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4226 - accuracy: 0.8400 - val_loss: 130.5233 - val_accuracy: 0.5000\n",
            "Epoch 437/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4111 - accuracy: 0.8427 - val_loss: 111.4751 - val_accuracy: 0.5400\n",
            "Epoch 438/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4115 - accuracy: 0.8418 - val_loss: 119.6956 - val_accuracy: 0.5067\n",
            "Epoch 439/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4013 - accuracy: 0.8437 - val_loss: 113.6031 - val_accuracy: 0.5467\n",
            "Epoch 440/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3864 - accuracy: 0.8527 - val_loss: 106.3041 - val_accuracy: 0.5333\n",
            "Epoch 441/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4248 - accuracy: 0.8301 - val_loss: 129.7826 - val_accuracy: 0.5067\n",
            "Epoch 442/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4268 - accuracy: 0.8455 - val_loss: 132.0742 - val_accuracy: 0.5000\n",
            "Epoch 443/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3962 - accuracy: 0.8462 - val_loss: 140.0152 - val_accuracy: 0.4867\n",
            "Epoch 444/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4301 - accuracy: 0.8366 - val_loss: 144.2339 - val_accuracy: 0.4867\n",
            "Epoch 445/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.4201 - accuracy: 0.8340 - val_loss: 125.0330 - val_accuracy: 0.5067\n",
            "Epoch 446/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4230 - accuracy: 0.8367 - val_loss: 114.4750 - val_accuracy: 0.5267\n",
            "Epoch 447/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3959 - accuracy: 0.8543 - val_loss: 108.4968 - val_accuracy: 0.5467\n",
            "Epoch 448/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4020 - accuracy: 0.8525 - val_loss: 120.1196 - val_accuracy: 0.5133\n",
            "Epoch 449/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4117 - accuracy: 0.8352 - val_loss: 104.0711 - val_accuracy: 0.5467\n",
            "Epoch 450/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3992 - accuracy: 0.8509 - val_loss: 93.8286 - val_accuracy: 0.5333\n",
            "Epoch 451/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4277 - accuracy: 0.8374 - val_loss: 103.2272 - val_accuracy: 0.5467\n",
            "Epoch 452/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4031 - accuracy: 0.8447 - val_loss: 115.7165 - val_accuracy: 0.5333\n",
            "Epoch 453/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4401 - accuracy: 0.8208 - val_loss: 122.6988 - val_accuracy: 0.5000\n",
            "Epoch 454/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4186 - accuracy: 0.8343 - val_loss: 123.5160 - val_accuracy: 0.5200\n",
            "Epoch 455/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3933 - accuracy: 0.8541 - val_loss: 113.1345 - val_accuracy: 0.5133\n",
            "Epoch 456/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3951 - accuracy: 0.8465 - val_loss: 104.8487 - val_accuracy: 0.5400\n",
            "Epoch 457/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4021 - accuracy: 0.8407 - val_loss: 110.6532 - val_accuracy: 0.5200\n",
            "Epoch 458/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4089 - accuracy: 0.8456 - val_loss: 112.4375 - val_accuracy: 0.5200\n",
            "Epoch 459/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3872 - accuracy: 0.8462 - val_loss: 128.4892 - val_accuracy: 0.5133\n",
            "Epoch 460/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4112 - accuracy: 0.8421 - val_loss: 130.8292 - val_accuracy: 0.5067\n",
            "Epoch 461/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4052 - accuracy: 0.8454 - val_loss: 112.3334 - val_accuracy: 0.5333\n",
            "Epoch 462/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3928 - accuracy: 0.8539 - val_loss: 129.1920 - val_accuracy: 0.5267\n",
            "Epoch 463/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4135 - accuracy: 0.8509 - val_loss: 124.2959 - val_accuracy: 0.5067\n",
            "Epoch 464/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4011 - accuracy: 0.8406 - val_loss: 129.8303 - val_accuracy: 0.5133\n",
            "Epoch 465/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3889 - accuracy: 0.8567 - val_loss: 115.9469 - val_accuracy: 0.5267\n",
            "Epoch 466/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4130 - accuracy: 0.8393 - val_loss: 129.7884 - val_accuracy: 0.4933\n",
            "Epoch 467/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4106 - accuracy: 0.8430 - val_loss: 119.4986 - val_accuracy: 0.5200\n",
            "Epoch 468/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4144 - accuracy: 0.8357 - val_loss: 133.5399 - val_accuracy: 0.4933\n",
            "Epoch 469/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3903 - accuracy: 0.8480 - val_loss: 119.0596 - val_accuracy: 0.5000\n",
            "Epoch 470/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.4192 - accuracy: 0.8463 - val_loss: 112.5591 - val_accuracy: 0.5267\n",
            "Epoch 471/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.3914 - accuracy: 0.8484 - val_loss: 103.7834 - val_accuracy: 0.5333\n",
            "Epoch 472/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3962 - accuracy: 0.8470 - val_loss: 120.0168 - val_accuracy: 0.5000\n",
            "Epoch 473/1000\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.3851 - accuracy: 0.8615 - val_loss: 144.9422 - val_accuracy: 0.4867\n",
            "Epoch 474/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.3908 - accuracy: 0.8418 - val_loss: 140.8551 - val_accuracy: 0.4800\n",
            "Epoch 475/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4093 - accuracy: 0.8444 - val_loss: 131.7209 - val_accuracy: 0.4867\n",
            "Epoch 476/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3994 - accuracy: 0.8410 - val_loss: 149.3252 - val_accuracy: 0.4733\n",
            "Epoch 477/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4174 - accuracy: 0.8405 - val_loss: 123.4440 - val_accuracy: 0.5267\n",
            "Epoch 478/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4024 - accuracy: 0.8357 - val_loss: 136.7534 - val_accuracy: 0.5133\n",
            "Epoch 479/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3909 - accuracy: 0.8575 - val_loss: 133.9788 - val_accuracy: 0.5067\n",
            "Epoch 480/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3950 - accuracy: 0.8442 - val_loss: 139.8036 - val_accuracy: 0.4933\n",
            "Epoch 481/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3861 - accuracy: 0.8592 - val_loss: 169.0465 - val_accuracy: 0.4533\n",
            "Epoch 482/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3954 - accuracy: 0.8541 - val_loss: 175.3902 - val_accuracy: 0.4600\n",
            "Epoch 483/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4066 - accuracy: 0.8419 - val_loss: 152.6763 - val_accuracy: 0.4867\n",
            "Epoch 484/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3987 - accuracy: 0.8391 - val_loss: 139.3298 - val_accuracy: 0.4933\n",
            "Epoch 485/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4285 - accuracy: 0.8343 - val_loss: 124.7225 - val_accuracy: 0.5267\n",
            "Epoch 486/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3903 - accuracy: 0.8448 - val_loss: 133.8395 - val_accuracy: 0.5133\n",
            "Epoch 487/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.3889 - accuracy: 0.8583 - val_loss: 132.6511 - val_accuracy: 0.5133\n",
            "Epoch 488/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4106 - accuracy: 0.8400 - val_loss: 135.1600 - val_accuracy: 0.4933\n",
            "Epoch 489/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3888 - accuracy: 0.8496 - val_loss: 125.2031 - val_accuracy: 0.5133\n",
            "Epoch 490/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4096 - accuracy: 0.8389 - val_loss: 131.1822 - val_accuracy: 0.5133\n",
            "Epoch 491/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3949 - accuracy: 0.8604 - val_loss: 129.9361 - val_accuracy: 0.5333\n",
            "Epoch 492/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3933 - accuracy: 0.8483 - val_loss: 133.6852 - val_accuracy: 0.4933\n",
            "Epoch 493/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3998 - accuracy: 0.8421 - val_loss: 124.2535 - val_accuracy: 0.5333\n",
            "Epoch 494/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.4102 - accuracy: 0.8459 - val_loss: 111.5057 - val_accuracy: 0.5267\n",
            "Epoch 495/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3835 - accuracy: 0.8537 - val_loss: 137.6665 - val_accuracy: 0.5067\n",
            "Epoch 496/1000\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.3923 - accuracy: 0.8582 - val_loss: 141.0572 - val_accuracy: 0.4867\n",
            "Epoch 497/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3946 - accuracy: 0.8357 - val_loss: 121.6325 - val_accuracy: 0.5133\n",
            "Epoch 498/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3828 - accuracy: 0.8576 - val_loss: 113.6803 - val_accuracy: 0.5200\n",
            "Epoch 499/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4060 - accuracy: 0.8504 - val_loss: 131.0519 - val_accuracy: 0.5000\n",
            "Epoch 500/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3786 - accuracy: 0.8688 - val_loss: 138.7569 - val_accuracy: 0.4933\n",
            "Epoch 501/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3946 - accuracy: 0.8415 - val_loss: 128.2372 - val_accuracy: 0.5133\n",
            "Epoch 502/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3972 - accuracy: 0.8546 - val_loss: 116.1895 - val_accuracy: 0.5333\n",
            "Epoch 503/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3800 - accuracy: 0.8566 - val_loss: 116.7691 - val_accuracy: 0.5133\n",
            "Epoch 504/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3886 - accuracy: 0.8491 - val_loss: 113.8250 - val_accuracy: 0.5333\n",
            "Epoch 505/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4089 - accuracy: 0.8399 - val_loss: 110.7424 - val_accuracy: 0.5467\n",
            "Epoch 506/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3994 - accuracy: 0.8406 - val_loss: 116.3030 - val_accuracy: 0.5400\n",
            "Epoch 507/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4286 - accuracy: 0.8370 - val_loss: 110.4138 - val_accuracy: 0.5533\n",
            "Epoch 508/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.4086 - accuracy: 0.8426 - val_loss: 114.9131 - val_accuracy: 0.5333\n",
            "Epoch 509/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3956 - accuracy: 0.8473 - val_loss: 124.3084 - val_accuracy: 0.5267\n",
            "Epoch 510/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3883 - accuracy: 0.8530 - val_loss: 136.7360 - val_accuracy: 0.5133\n",
            "Epoch 511/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.4024 - accuracy: 0.8492 - val_loss: 136.7634 - val_accuracy: 0.5000\n",
            "Epoch 512/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3811 - accuracy: 0.8488 - val_loss: 120.3042 - val_accuracy: 0.5267\n",
            "Epoch 513/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3715 - accuracy: 0.8706 - val_loss: 114.5057 - val_accuracy: 0.5400\n",
            "Epoch 514/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3755 - accuracy: 0.8662 - val_loss: 126.5263 - val_accuracy: 0.5200\n",
            "Epoch 515/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4206 - accuracy: 0.8464 - val_loss: 141.5870 - val_accuracy: 0.4800\n",
            "Epoch 516/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4087 - accuracy: 0.8328 - val_loss: 144.5836 - val_accuracy: 0.4800\n",
            "Epoch 517/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.4081 - accuracy: 0.8422 - val_loss: 137.0497 - val_accuracy: 0.4800\n",
            "Epoch 518/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3745 - accuracy: 0.8642 - val_loss: 131.9874 - val_accuracy: 0.5067\n",
            "Epoch 519/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4048 - accuracy: 0.8426 - val_loss: 146.7959 - val_accuracy: 0.4800\n",
            "Epoch 520/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3847 - accuracy: 0.8525 - val_loss: 152.2275 - val_accuracy: 0.4800\n",
            "Epoch 521/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3812 - accuracy: 0.8495 - val_loss: 138.8172 - val_accuracy: 0.4800\n",
            "Epoch 522/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3946 - accuracy: 0.8456 - val_loss: 148.1472 - val_accuracy: 0.4800\n",
            "Epoch 523/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.4002 - accuracy: 0.8399 - val_loss: 126.3089 - val_accuracy: 0.4933\n",
            "Epoch 524/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3814 - accuracy: 0.8609 - val_loss: 142.3889 - val_accuracy: 0.4733\n",
            "Epoch 525/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3988 - accuracy: 0.8478 - val_loss: 137.2015 - val_accuracy: 0.4733\n",
            "Epoch 526/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3825 - accuracy: 0.8573 - val_loss: 154.5576 - val_accuracy: 0.4467\n",
            "Epoch 527/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3894 - accuracy: 0.8462 - val_loss: 149.4152 - val_accuracy: 0.4800\n",
            "Epoch 528/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3711 - accuracy: 0.8598 - val_loss: 148.1425 - val_accuracy: 0.4733\n",
            "Epoch 529/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3920 - accuracy: 0.8520 - val_loss: 146.1587 - val_accuracy: 0.4800\n",
            "Epoch 530/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3764 - accuracy: 0.8609 - val_loss: 140.8780 - val_accuracy: 0.4933\n",
            "Epoch 531/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3906 - accuracy: 0.8474 - val_loss: 148.9680 - val_accuracy: 0.4800\n",
            "Epoch 532/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3843 - accuracy: 0.8530 - val_loss: 170.5399 - val_accuracy: 0.4600\n",
            "Epoch 533/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3702 - accuracy: 0.8467 - val_loss: 170.7962 - val_accuracy: 0.4667\n",
            "Epoch 534/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.4064 - accuracy: 0.8405 - val_loss: 157.8827 - val_accuracy: 0.4800\n",
            "Epoch 535/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.4033 - accuracy: 0.8427 - val_loss: 170.6115 - val_accuracy: 0.4667\n",
            "Epoch 536/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3885 - accuracy: 0.8529 - val_loss: 160.4075 - val_accuracy: 0.4600\n",
            "Epoch 537/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3969 - accuracy: 0.8550 - val_loss: 152.2968 - val_accuracy: 0.4667\n",
            "Epoch 538/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4039 - accuracy: 0.8381 - val_loss: 136.5040 - val_accuracy: 0.4867\n",
            "Epoch 539/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3752 - accuracy: 0.8455 - val_loss: 135.1945 - val_accuracy: 0.4867\n",
            "Epoch 540/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3746 - accuracy: 0.8585 - val_loss: 170.5614 - val_accuracy: 0.4467\n",
            "Epoch 541/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3927 - accuracy: 0.8451 - val_loss: 145.9576 - val_accuracy: 0.4667\n",
            "Epoch 542/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3901 - accuracy: 0.8585 - val_loss: 175.6207 - val_accuracy: 0.4400\n",
            "Epoch 543/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3844 - accuracy: 0.8493 - val_loss: 174.4518 - val_accuracy: 0.4533\n",
            "Epoch 544/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4037 - accuracy: 0.8435 - val_loss: 143.5074 - val_accuracy: 0.4800\n",
            "Epoch 545/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3776 - accuracy: 0.8545 - val_loss: 165.8721 - val_accuracy: 0.4600\n",
            "Epoch 546/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3990 - accuracy: 0.8445 - val_loss: 188.7779 - val_accuracy: 0.4400\n",
            "Epoch 547/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3815 - accuracy: 0.8529 - val_loss: 168.7650 - val_accuracy: 0.4600\n",
            "Epoch 548/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3629 - accuracy: 0.8676 - val_loss: 186.6349 - val_accuracy: 0.4600\n",
            "Epoch 549/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3677 - accuracy: 0.8683 - val_loss: 164.4868 - val_accuracy: 0.4667\n",
            "Epoch 550/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3938 - accuracy: 0.8401 - val_loss: 164.1082 - val_accuracy: 0.4600\n",
            "Epoch 551/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3834 - accuracy: 0.8515 - val_loss: 160.9591 - val_accuracy: 0.4733\n",
            "Epoch 552/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3744 - accuracy: 0.8580 - val_loss: 167.1328 - val_accuracy: 0.4600\n",
            "Epoch 553/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3709 - accuracy: 0.8661 - val_loss: 175.2596 - val_accuracy: 0.4600\n",
            "Epoch 554/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3660 - accuracy: 0.8606 - val_loss: 178.2968 - val_accuracy: 0.4400\n",
            "Epoch 555/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3611 - accuracy: 0.8638 - val_loss: 154.2936 - val_accuracy: 0.4733\n",
            "Epoch 556/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3902 - accuracy: 0.8501 - val_loss: 194.0338 - val_accuracy: 0.4333\n",
            "Epoch 557/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3448 - accuracy: 0.8765 - val_loss: 178.8342 - val_accuracy: 0.4533\n",
            "Epoch 558/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3802 - accuracy: 0.8444 - val_loss: 165.3461 - val_accuracy: 0.4667\n",
            "Epoch 559/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3742 - accuracy: 0.8609 - val_loss: 180.1969 - val_accuracy: 0.4467\n",
            "Epoch 560/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3632 - accuracy: 0.8586 - val_loss: 177.5880 - val_accuracy: 0.4400\n",
            "Epoch 561/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3773 - accuracy: 0.8528 - val_loss: 201.7826 - val_accuracy: 0.4333\n",
            "Epoch 562/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3866 - accuracy: 0.8519 - val_loss: 180.8800 - val_accuracy: 0.4600\n",
            "Epoch 563/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3809 - accuracy: 0.8503 - val_loss: 189.7285 - val_accuracy: 0.4600\n",
            "Epoch 564/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3853 - accuracy: 0.8540 - val_loss: 159.8539 - val_accuracy: 0.4800\n",
            "Epoch 565/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3816 - accuracy: 0.8522 - val_loss: 164.4721 - val_accuracy: 0.4600\n",
            "Epoch 566/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3873 - accuracy: 0.8522 - val_loss: 157.4822 - val_accuracy: 0.4800\n",
            "Epoch 567/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3887 - accuracy: 0.8372 - val_loss: 162.0081 - val_accuracy: 0.4800\n",
            "Epoch 568/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3677 - accuracy: 0.8619 - val_loss: 169.9640 - val_accuracy: 0.4800\n",
            "Epoch 569/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3995 - accuracy: 0.8381 - val_loss: 186.8753 - val_accuracy: 0.4333\n",
            "Epoch 570/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3634 - accuracy: 0.8585 - val_loss: 154.4604 - val_accuracy: 0.4800\n",
            "Epoch 571/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3670 - accuracy: 0.8585 - val_loss: 171.8162 - val_accuracy: 0.4467\n",
            "Epoch 572/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3606 - accuracy: 0.8648 - val_loss: 189.3841 - val_accuracy: 0.4267\n",
            "Epoch 573/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3734 - accuracy: 0.8540 - val_loss: 170.9194 - val_accuracy: 0.4400\n",
            "Epoch 574/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3760 - accuracy: 0.8539 - val_loss: 154.1747 - val_accuracy: 0.4867\n",
            "Epoch 575/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3663 - accuracy: 0.8681 - val_loss: 158.8430 - val_accuracy: 0.4533\n",
            "Epoch 576/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3636 - accuracy: 0.8679 - val_loss: 158.9765 - val_accuracy: 0.4800\n",
            "Epoch 577/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3715 - accuracy: 0.8644 - val_loss: 168.4056 - val_accuracy: 0.4600\n",
            "Epoch 578/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3701 - accuracy: 0.8616 - val_loss: 152.4572 - val_accuracy: 0.4600\n",
            "Epoch 579/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3792 - accuracy: 0.8548 - val_loss: 155.9643 - val_accuracy: 0.4667\n",
            "Epoch 580/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3596 - accuracy: 0.8588 - val_loss: 145.1060 - val_accuracy: 0.4667\n",
            "Epoch 581/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3876 - accuracy: 0.8462 - val_loss: 151.9259 - val_accuracy: 0.4600\n",
            "Epoch 582/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3897 - accuracy: 0.8534 - val_loss: 157.2116 - val_accuracy: 0.4400\n",
            "Epoch 583/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3879 - accuracy: 0.8396 - val_loss: 156.9325 - val_accuracy: 0.4467\n",
            "Epoch 584/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3609 - accuracy: 0.8777 - val_loss: 145.4271 - val_accuracy: 0.4800\n",
            "Epoch 585/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3703 - accuracy: 0.8712 - val_loss: 144.1578 - val_accuracy: 0.4667\n",
            "Epoch 586/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3805 - accuracy: 0.8544 - val_loss: 154.3761 - val_accuracy: 0.4600\n",
            "Epoch 587/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3638 - accuracy: 0.8616 - val_loss: 151.7444 - val_accuracy: 0.4667\n",
            "Epoch 588/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3779 - accuracy: 0.8619 - val_loss: 160.1160 - val_accuracy: 0.4733\n",
            "Epoch 589/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3672 - accuracy: 0.8623 - val_loss: 166.8270 - val_accuracy: 0.4533\n",
            "Epoch 590/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3592 - accuracy: 0.8612 - val_loss: 163.0252 - val_accuracy: 0.4600\n",
            "Epoch 591/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3779 - accuracy: 0.8595 - val_loss: 153.3168 - val_accuracy: 0.4600\n",
            "Epoch 592/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3875 - accuracy: 0.8592 - val_loss: 149.0895 - val_accuracy: 0.4867\n",
            "Epoch 593/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3655 - accuracy: 0.8704 - val_loss: 155.8980 - val_accuracy: 0.4800\n",
            "Epoch 594/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3802 - accuracy: 0.8560 - val_loss: 176.5916 - val_accuracy: 0.4333\n",
            "Epoch 595/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3627 - accuracy: 0.8670 - val_loss: 162.5792 - val_accuracy: 0.4867\n",
            "Epoch 596/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3741 - accuracy: 0.8574 - val_loss: 176.3815 - val_accuracy: 0.4600\n",
            "Epoch 597/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3590 - accuracy: 0.8604 - val_loss: 157.5483 - val_accuracy: 0.4533\n",
            "Epoch 598/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3630 - accuracy: 0.8684 - val_loss: 157.4005 - val_accuracy: 0.4733\n",
            "Epoch 599/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3646 - accuracy: 0.8617 - val_loss: 194.4655 - val_accuracy: 0.4400\n",
            "Epoch 600/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3870 - accuracy: 0.8510 - val_loss: 169.4299 - val_accuracy: 0.4600\n",
            "Epoch 601/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3800 - accuracy: 0.8579 - val_loss: 169.7860 - val_accuracy: 0.4600\n",
            "Epoch 602/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3491 - accuracy: 0.8646 - val_loss: 180.9835 - val_accuracy: 0.4533\n",
            "Epoch 603/1000\n",
            "83/83 [==============================] - 19s 236ms/step - loss: 0.3752 - accuracy: 0.8647 - val_loss: 169.5908 - val_accuracy: 0.4600\n",
            "Epoch 604/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3609 - accuracy: 0.8662 - val_loss: 183.4061 - val_accuracy: 0.4400\n",
            "Epoch 605/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3619 - accuracy: 0.8632 - val_loss: 165.0293 - val_accuracy: 0.4533\n",
            "Epoch 606/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3778 - accuracy: 0.8483 - val_loss: 196.4369 - val_accuracy: 0.4333\n",
            "Epoch 607/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3738 - accuracy: 0.8591 - val_loss: 172.9877 - val_accuracy: 0.4467\n",
            "Epoch 608/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3586 - accuracy: 0.8678 - val_loss: 188.9586 - val_accuracy: 0.4533\n",
            "Epoch 609/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3563 - accuracy: 0.8742 - val_loss: 199.4012 - val_accuracy: 0.4667\n",
            "Epoch 610/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3557 - accuracy: 0.8681 - val_loss: 190.9150 - val_accuracy: 0.4533\n",
            "Epoch 611/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3696 - accuracy: 0.8651 - val_loss: 180.4896 - val_accuracy: 0.4600\n",
            "Epoch 612/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3805 - accuracy: 0.8513 - val_loss: 170.6429 - val_accuracy: 0.4600\n",
            "Epoch 613/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3801 - accuracy: 0.8522 - val_loss: 165.0623 - val_accuracy: 0.4600\n",
            "Epoch 614/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3653 - accuracy: 0.8650 - val_loss: 163.3591 - val_accuracy: 0.4867\n",
            "Epoch 615/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3697 - accuracy: 0.8572 - val_loss: 149.5802 - val_accuracy: 0.4667\n",
            "Epoch 616/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3704 - accuracy: 0.8608 - val_loss: 148.5080 - val_accuracy: 0.5000\n",
            "Epoch 617/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3384 - accuracy: 0.8796 - val_loss: 151.7033 - val_accuracy: 0.4867\n",
            "Epoch 618/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3476 - accuracy: 0.8723 - val_loss: 156.6556 - val_accuracy: 0.4800\n",
            "Epoch 619/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3728 - accuracy: 0.8656 - val_loss: 158.3396 - val_accuracy: 0.4667\n",
            "Epoch 620/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3626 - accuracy: 0.8633 - val_loss: 150.0099 - val_accuracy: 0.4867\n",
            "Epoch 621/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3881 - accuracy: 0.8562 - val_loss: 170.6960 - val_accuracy: 0.4533\n",
            "Epoch 622/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3755 - accuracy: 0.8448 - val_loss: 165.2924 - val_accuracy: 0.4467\n",
            "Epoch 623/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3544 - accuracy: 0.8678 - val_loss: 179.9307 - val_accuracy: 0.4600\n",
            "Epoch 624/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3637 - accuracy: 0.8574 - val_loss: 142.7245 - val_accuracy: 0.5000\n",
            "Epoch 625/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3524 - accuracy: 0.8633 - val_loss: 143.6251 - val_accuracy: 0.5000\n",
            "Epoch 626/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3495 - accuracy: 0.8636 - val_loss: 171.6281 - val_accuracy: 0.4800\n",
            "Epoch 627/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3507 - accuracy: 0.8709 - val_loss: 147.7279 - val_accuracy: 0.5000\n",
            "Epoch 628/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3556 - accuracy: 0.8655 - val_loss: 211.2785 - val_accuracy: 0.4467\n",
            "Epoch 629/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3413 - accuracy: 0.8801 - val_loss: 189.0053 - val_accuracy: 0.4667\n",
            "Epoch 630/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3641 - accuracy: 0.8658 - val_loss: 179.0914 - val_accuracy: 0.4533\n",
            "Epoch 631/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3722 - accuracy: 0.8616 - val_loss: 169.3185 - val_accuracy: 0.4867\n",
            "Epoch 632/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3654 - accuracy: 0.8538 - val_loss: 171.0478 - val_accuracy: 0.4867\n",
            "Epoch 633/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3643 - accuracy: 0.8587 - val_loss: 168.2523 - val_accuracy: 0.4733\n",
            "Epoch 634/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3619 - accuracy: 0.8605 - val_loss: 172.2332 - val_accuracy: 0.4600\n",
            "Epoch 635/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3489 - accuracy: 0.8613 - val_loss: 178.5032 - val_accuracy: 0.4600\n",
            "Epoch 636/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3544 - accuracy: 0.8657 - val_loss: 195.3911 - val_accuracy: 0.4400\n",
            "Epoch 637/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3752 - accuracy: 0.8540 - val_loss: 211.1906 - val_accuracy: 0.4400\n",
            "Epoch 638/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3717 - accuracy: 0.8628 - val_loss: 189.2091 - val_accuracy: 0.4467\n",
            "Epoch 639/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3637 - accuracy: 0.8519 - val_loss: 176.8357 - val_accuracy: 0.4600\n",
            "Epoch 640/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3657 - accuracy: 0.8639 - val_loss: 180.8754 - val_accuracy: 0.4600\n",
            "Epoch 641/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3700 - accuracy: 0.8640 - val_loss: 178.2386 - val_accuracy: 0.4600\n",
            "Epoch 642/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3543 - accuracy: 0.8678 - val_loss: 168.6347 - val_accuracy: 0.4800\n",
            "Epoch 643/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3736 - accuracy: 0.8596 - val_loss: 189.4489 - val_accuracy: 0.4333\n",
            "Epoch 644/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3549 - accuracy: 0.8660 - val_loss: 176.1029 - val_accuracy: 0.4733\n",
            "Epoch 645/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3470 - accuracy: 0.8735 - val_loss: 185.9951 - val_accuracy: 0.4600\n",
            "Epoch 646/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3607 - accuracy: 0.8625 - val_loss: 161.7229 - val_accuracy: 0.4733\n",
            "Epoch 647/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3617 - accuracy: 0.8586 - val_loss: 164.5369 - val_accuracy: 0.4867\n",
            "Epoch 648/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3446 - accuracy: 0.8706 - val_loss: 157.3005 - val_accuracy: 0.4733\n",
            "Epoch 649/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3538 - accuracy: 0.8580 - val_loss: 179.8547 - val_accuracy: 0.4800\n",
            "Epoch 650/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3605 - accuracy: 0.8615 - val_loss: 158.7899 - val_accuracy: 0.5000\n",
            "Epoch 651/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3472 - accuracy: 0.8701 - val_loss: 152.0978 - val_accuracy: 0.4933\n",
            "Epoch 652/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3490 - accuracy: 0.8702 - val_loss: 187.1997 - val_accuracy: 0.4667\n",
            "Epoch 653/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3864 - accuracy: 0.8502 - val_loss: 186.5178 - val_accuracy: 0.4600\n",
            "Epoch 654/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3597 - accuracy: 0.8678 - val_loss: 143.4250 - val_accuracy: 0.4867\n",
            "Epoch 655/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3763 - accuracy: 0.8530 - val_loss: 159.4635 - val_accuracy: 0.4800\n",
            "Epoch 656/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3571 - accuracy: 0.8618 - val_loss: 152.7689 - val_accuracy: 0.4867\n",
            "Epoch 657/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3401 - accuracy: 0.8752 - val_loss: 150.1671 - val_accuracy: 0.5000\n",
            "Epoch 658/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3629 - accuracy: 0.8591 - val_loss: 155.1600 - val_accuracy: 0.4867\n",
            "Epoch 659/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3426 - accuracy: 0.8767 - val_loss: 166.0377 - val_accuracy: 0.4667\n",
            "Epoch 660/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3602 - accuracy: 0.8605 - val_loss: 159.8663 - val_accuracy: 0.4800\n",
            "Epoch 661/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3544 - accuracy: 0.8593 - val_loss: 176.6952 - val_accuracy: 0.4533\n",
            "Epoch 662/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3510 - accuracy: 0.8664 - val_loss: 166.0228 - val_accuracy: 0.4800\n",
            "Epoch 663/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3428 - accuracy: 0.8732 - val_loss: 180.4947 - val_accuracy: 0.4467\n",
            "Epoch 664/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3310 - accuracy: 0.8755 - val_loss: 162.4536 - val_accuracy: 0.4600\n",
            "Epoch 665/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3215 - accuracy: 0.8853 - val_loss: 169.9380 - val_accuracy: 0.4400\n",
            "Epoch 666/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3519 - accuracy: 0.8738 - val_loss: 164.5030 - val_accuracy: 0.4800\n",
            "Epoch 667/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3587 - accuracy: 0.8575 - val_loss: 165.4935 - val_accuracy: 0.4800\n",
            "Epoch 668/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3753 - accuracy: 0.8597 - val_loss: 162.0517 - val_accuracy: 0.4800\n",
            "Epoch 669/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3547 - accuracy: 0.8589 - val_loss: 148.0107 - val_accuracy: 0.4667\n",
            "Epoch 670/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3636 - accuracy: 0.8534 - val_loss: 143.3325 - val_accuracy: 0.4733\n",
            "Epoch 671/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3407 - accuracy: 0.8722 - val_loss: 162.1077 - val_accuracy: 0.4800\n",
            "Epoch 672/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3483 - accuracy: 0.8721 - val_loss: 161.4253 - val_accuracy: 0.4867\n",
            "Epoch 673/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3757 - accuracy: 0.8551 - val_loss: 181.3701 - val_accuracy: 0.4533\n",
            "Epoch 674/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3511 - accuracy: 0.8666 - val_loss: 170.4559 - val_accuracy: 0.4733\n",
            "Epoch 675/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3417 - accuracy: 0.8757 - val_loss: 164.5489 - val_accuracy: 0.4667\n",
            "Epoch 676/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3434 - accuracy: 0.8711 - val_loss: 174.9596 - val_accuracy: 0.4667\n",
            "Epoch 677/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3436 - accuracy: 0.8756 - val_loss: 169.8062 - val_accuracy: 0.4600\n",
            "Epoch 678/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3349 - accuracy: 0.8784 - val_loss: 173.7241 - val_accuracy: 0.4667\n",
            "Epoch 679/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3353 - accuracy: 0.8745 - val_loss: 165.4906 - val_accuracy: 0.4800\n",
            "Epoch 680/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3518 - accuracy: 0.8709 - val_loss: 160.4957 - val_accuracy: 0.4800\n",
            "Epoch 681/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3405 - accuracy: 0.8822 - val_loss: 169.7030 - val_accuracy: 0.4667\n",
            "Epoch 682/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3590 - accuracy: 0.8562 - val_loss: 168.7727 - val_accuracy: 0.4667\n",
            "Epoch 683/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3481 - accuracy: 0.8658 - val_loss: 167.3946 - val_accuracy: 0.4600\n",
            "Epoch 684/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3397 - accuracy: 0.8782 - val_loss: 165.1393 - val_accuracy: 0.4600\n",
            "Epoch 685/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3498 - accuracy: 0.8688 - val_loss: 174.6333 - val_accuracy: 0.4667\n",
            "Epoch 686/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3380 - accuracy: 0.8746 - val_loss: 170.1117 - val_accuracy: 0.4600\n",
            "Epoch 687/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3718 - accuracy: 0.8545 - val_loss: 183.4039 - val_accuracy: 0.4667\n",
            "Epoch 688/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3751 - accuracy: 0.8591 - val_loss: 181.6281 - val_accuracy: 0.4467\n",
            "Epoch 689/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3194 - accuracy: 0.8865 - val_loss: 180.4107 - val_accuracy: 0.4600\n",
            "Epoch 690/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3289 - accuracy: 0.8813 - val_loss: 152.9444 - val_accuracy: 0.4867\n",
            "Epoch 691/1000\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.3399 - accuracy: 0.8704 - val_loss: 171.1933 - val_accuracy: 0.4733\n",
            "Epoch 692/1000\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.3547 - accuracy: 0.8703 - val_loss: 160.7731 - val_accuracy: 0.4533\n",
            "Epoch 693/1000\n",
            "83/83 [==============================] - 20s 242ms/step - loss: 0.3531 - accuracy: 0.8745 - val_loss: 196.7308 - val_accuracy: 0.4533\n",
            "Epoch 694/1000\n",
            "83/83 [==============================] - 20s 244ms/step - loss: 0.3463 - accuracy: 0.8738 - val_loss: 207.3591 - val_accuracy: 0.4467\n",
            "Epoch 695/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3380 - accuracy: 0.8709 - val_loss: 221.0017 - val_accuracy: 0.4267\n",
            "Epoch 696/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3357 - accuracy: 0.8875 - val_loss: 182.4541 - val_accuracy: 0.4800\n",
            "Epoch 697/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3207 - accuracy: 0.8833 - val_loss: 186.4706 - val_accuracy: 0.4533\n",
            "Epoch 698/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3434 - accuracy: 0.8742 - val_loss: 152.3346 - val_accuracy: 0.4733\n",
            "Epoch 699/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3338 - accuracy: 0.8734 - val_loss: 153.8223 - val_accuracy: 0.4733\n",
            "Epoch 700/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3335 - accuracy: 0.8762 - val_loss: 184.1947 - val_accuracy: 0.4600\n",
            "Epoch 701/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3249 - accuracy: 0.8820 - val_loss: 176.2967 - val_accuracy: 0.4667\n",
            "Epoch 702/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3180 - accuracy: 0.8723 - val_loss: 188.6246 - val_accuracy: 0.4733\n",
            "Epoch 703/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3543 - accuracy: 0.8716 - val_loss: 193.0366 - val_accuracy: 0.4600\n",
            "Epoch 704/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3586 - accuracy: 0.8659 - val_loss: 186.8023 - val_accuracy: 0.4667\n",
            "Epoch 705/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3450 - accuracy: 0.8728 - val_loss: 195.4885 - val_accuracy: 0.4533\n",
            "Epoch 706/1000\n",
            "83/83 [==============================] - 20s 242ms/step - loss: 0.3398 - accuracy: 0.8771 - val_loss: 173.5206 - val_accuracy: 0.4800\n",
            "Epoch 707/1000\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.3494 - accuracy: 0.8663 - val_loss: 191.2779 - val_accuracy: 0.4467\n",
            "Epoch 708/1000\n",
            "83/83 [==============================] - 20s 244ms/step - loss: 0.3510 - accuracy: 0.8662 - val_loss: 168.8449 - val_accuracy: 0.4600\n",
            "Epoch 709/1000\n",
            "83/83 [==============================] - 20s 240ms/step - loss: 0.3427 - accuracy: 0.8670 - val_loss: 170.4247 - val_accuracy: 0.4733\n",
            "Epoch 710/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3524 - accuracy: 0.8694 - val_loss: 175.8738 - val_accuracy: 0.4533\n",
            "Epoch 711/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3412 - accuracy: 0.8777 - val_loss: 187.4006 - val_accuracy: 0.4533\n",
            "Epoch 712/1000\n",
            "83/83 [==============================] - 20s 246ms/step - loss: 0.3535 - accuracy: 0.8724 - val_loss: 188.3616 - val_accuracy: 0.4667\n",
            "Epoch 713/1000\n",
            "83/83 [==============================] - 21s 251ms/step - loss: 0.3401 - accuracy: 0.8832 - val_loss: 192.6968 - val_accuracy: 0.4667\n",
            "Epoch 714/1000\n",
            "83/83 [==============================] - 20s 244ms/step - loss: 0.3516 - accuracy: 0.8647 - val_loss: 174.6748 - val_accuracy: 0.4867\n",
            "Epoch 715/1000\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.3435 - accuracy: 0.8730 - val_loss: 204.0912 - val_accuracy: 0.4600\n",
            "Epoch 716/1000\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.3462 - accuracy: 0.8780 - val_loss: 171.8021 - val_accuracy: 0.4400\n",
            "Epoch 717/1000\n",
            "83/83 [==============================] - 20s 241ms/step - loss: 0.3490 - accuracy: 0.8739 - val_loss: 177.3226 - val_accuracy: 0.4533\n",
            "Epoch 718/1000\n",
            "83/83 [==============================] - 20s 241ms/step - loss: 0.3382 - accuracy: 0.8726 - val_loss: 165.1431 - val_accuracy: 0.4800\n",
            "Epoch 719/1000\n",
            "83/83 [==============================] - 20s 241ms/step - loss: 0.3332 - accuracy: 0.8840 - val_loss: 195.4265 - val_accuracy: 0.4533\n",
            "Epoch 720/1000\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.3724 - accuracy: 0.8592 - val_loss: 180.9679 - val_accuracy: 0.4600\n",
            "Epoch 721/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3367 - accuracy: 0.8791 - val_loss: 169.8573 - val_accuracy: 0.4933\n",
            "Epoch 722/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3448 - accuracy: 0.8759 - val_loss: 167.7933 - val_accuracy: 0.4867\n",
            "Epoch 723/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3272 - accuracy: 0.8767 - val_loss: 174.2650 - val_accuracy: 0.4667\n",
            "Epoch 724/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3522 - accuracy: 0.8611 - val_loss: 186.7435 - val_accuracy: 0.4467\n",
            "Epoch 725/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3375 - accuracy: 0.8810 - val_loss: 164.2230 - val_accuracy: 0.4667\n",
            "Epoch 726/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3301 - accuracy: 0.8810 - val_loss: 151.7469 - val_accuracy: 0.5000\n",
            "Epoch 727/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3321 - accuracy: 0.8760 - val_loss: 174.2538 - val_accuracy: 0.4733\n",
            "Epoch 728/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3481 - accuracy: 0.8680 - val_loss: 174.6234 - val_accuracy: 0.4533\n",
            "Epoch 729/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3559 - accuracy: 0.8680 - val_loss: 163.9267 - val_accuracy: 0.5067\n",
            "Epoch 730/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3316 - accuracy: 0.8767 - val_loss: 162.4652 - val_accuracy: 0.4867\n",
            "Epoch 731/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3499 - accuracy: 0.8694 - val_loss: 159.3088 - val_accuracy: 0.4733\n",
            "Epoch 732/1000\n",
            "83/83 [==============================] - 20s 242ms/step - loss: 0.3528 - accuracy: 0.8840 - val_loss: 153.4837 - val_accuracy: 0.4867\n",
            "Epoch 733/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3289 - accuracy: 0.8769 - val_loss: 156.7887 - val_accuracy: 0.5000\n",
            "Epoch 734/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3322 - accuracy: 0.8861 - val_loss: 182.0886 - val_accuracy: 0.4600\n",
            "Epoch 735/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3277 - accuracy: 0.8819 - val_loss: 153.9837 - val_accuracy: 0.4733\n",
            "Epoch 736/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3304 - accuracy: 0.8766 - val_loss: 173.6734 - val_accuracy: 0.4600\n",
            "Epoch 737/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3589 - accuracy: 0.8668 - val_loss: 150.0028 - val_accuracy: 0.4733\n",
            "Epoch 738/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3458 - accuracy: 0.8718 - val_loss: 163.8186 - val_accuracy: 0.4800\n",
            "Epoch 739/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3482 - accuracy: 0.8820 - val_loss: 185.5162 - val_accuracy: 0.4733\n",
            "Epoch 740/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3222 - accuracy: 0.8841 - val_loss: 184.0347 - val_accuracy: 0.4400\n",
            "Epoch 741/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3505 - accuracy: 0.8665 - val_loss: 187.2501 - val_accuracy: 0.4333\n",
            "Epoch 742/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3514 - accuracy: 0.8710 - val_loss: 164.4245 - val_accuracy: 0.4800\n",
            "Epoch 743/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3205 - accuracy: 0.8783 - val_loss: 156.1147 - val_accuracy: 0.4867\n",
            "Epoch 744/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3459 - accuracy: 0.8736 - val_loss: 157.0903 - val_accuracy: 0.4933\n",
            "Epoch 745/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3182 - accuracy: 0.8869 - val_loss: 145.1702 - val_accuracy: 0.5000\n",
            "Epoch 746/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3403 - accuracy: 0.8773 - val_loss: 157.5875 - val_accuracy: 0.4800\n",
            "Epoch 747/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3365 - accuracy: 0.8768 - val_loss: 151.6844 - val_accuracy: 0.5067\n",
            "Epoch 748/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3401 - accuracy: 0.8766 - val_loss: 160.7393 - val_accuracy: 0.4800\n",
            "Epoch 749/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3324 - accuracy: 0.8789 - val_loss: 156.4892 - val_accuracy: 0.4867\n",
            "Epoch 750/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3280 - accuracy: 0.8878 - val_loss: 151.4672 - val_accuracy: 0.5067\n",
            "Epoch 751/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3262 - accuracy: 0.8788 - val_loss: 157.4858 - val_accuracy: 0.4867\n",
            "Epoch 752/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3247 - accuracy: 0.8773 - val_loss: 179.5484 - val_accuracy: 0.4733\n",
            "Epoch 753/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3294 - accuracy: 0.8746 - val_loss: 149.1230 - val_accuracy: 0.4867\n",
            "Epoch 754/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3379 - accuracy: 0.8801 - val_loss: 146.3956 - val_accuracy: 0.5200\n",
            "Epoch 755/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3356 - accuracy: 0.8727 - val_loss: 154.1648 - val_accuracy: 0.5000\n",
            "Epoch 756/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3541 - accuracy: 0.8642 - val_loss: 187.0274 - val_accuracy: 0.4733\n",
            "Epoch 757/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3331 - accuracy: 0.8808 - val_loss: 179.9624 - val_accuracy: 0.4800\n",
            "Epoch 758/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3412 - accuracy: 0.8651 - val_loss: 189.3489 - val_accuracy: 0.4733\n",
            "Epoch 759/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3124 - accuracy: 0.8969 - val_loss: 172.3373 - val_accuracy: 0.4800\n",
            "Epoch 760/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3242 - accuracy: 0.8921 - val_loss: 183.4759 - val_accuracy: 0.4733\n",
            "Epoch 761/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3220 - accuracy: 0.8807 - val_loss: 171.2787 - val_accuracy: 0.5000\n",
            "Epoch 762/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3139 - accuracy: 0.8936 - val_loss: 179.7213 - val_accuracy: 0.4933\n",
            "Epoch 763/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3225 - accuracy: 0.8789 - val_loss: 185.5907 - val_accuracy: 0.4867\n",
            "Epoch 764/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3322 - accuracy: 0.8804 - val_loss: 204.8568 - val_accuracy: 0.4333\n",
            "Epoch 765/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3134 - accuracy: 0.8856 - val_loss: 174.6007 - val_accuracy: 0.4600\n",
            "Epoch 766/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3158 - accuracy: 0.8792 - val_loss: 174.4721 - val_accuracy: 0.4667\n",
            "Epoch 767/1000\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.3269 - accuracy: 0.8916 - val_loss: 171.7976 - val_accuracy: 0.4667\n",
            "Epoch 768/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3519 - accuracy: 0.8658 - val_loss: 189.0941 - val_accuracy: 0.4533\n",
            "Epoch 769/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3216 - accuracy: 0.8734 - val_loss: 186.9462 - val_accuracy: 0.4533\n",
            "Epoch 770/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3073 - accuracy: 0.8859 - val_loss: 196.2827 - val_accuracy: 0.4400\n",
            "Epoch 771/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3506 - accuracy: 0.8591 - val_loss: 204.8383 - val_accuracy: 0.4333\n",
            "Epoch 772/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3314 - accuracy: 0.8787 - val_loss: 225.7605 - val_accuracy: 0.4133\n",
            "Epoch 773/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3013 - accuracy: 0.8908 - val_loss: 211.9060 - val_accuracy: 0.4400\n",
            "Epoch 774/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3231 - accuracy: 0.8827 - val_loss: 189.9355 - val_accuracy: 0.4467\n",
            "Epoch 775/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3400 - accuracy: 0.8813 - val_loss: 204.6052 - val_accuracy: 0.4267\n",
            "Epoch 776/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3163 - accuracy: 0.8857 - val_loss: 190.4684 - val_accuracy: 0.4600\n",
            "Epoch 777/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3265 - accuracy: 0.8817 - val_loss: 212.6291 - val_accuracy: 0.4333\n",
            "Epoch 778/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3318 - accuracy: 0.8788 - val_loss: 206.7822 - val_accuracy: 0.4400\n",
            "Epoch 779/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3301 - accuracy: 0.8814 - val_loss: 189.5606 - val_accuracy: 0.4667\n",
            "Epoch 780/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3477 - accuracy: 0.8615 - val_loss: 191.2349 - val_accuracy: 0.4467\n",
            "Epoch 781/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3225 - accuracy: 0.8783 - val_loss: 188.3519 - val_accuracy: 0.4667\n",
            "Epoch 782/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3105 - accuracy: 0.8808 - val_loss: 213.5576 - val_accuracy: 0.4533\n",
            "Epoch 783/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3203 - accuracy: 0.8891 - val_loss: 192.3453 - val_accuracy: 0.4600\n",
            "Epoch 784/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3361 - accuracy: 0.8817 - val_loss: 197.2124 - val_accuracy: 0.4533\n",
            "Epoch 785/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3269 - accuracy: 0.8760 - val_loss: 204.0501 - val_accuracy: 0.4733\n",
            "Epoch 786/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3550 - accuracy: 0.8591 - val_loss: 199.0723 - val_accuracy: 0.4667\n",
            "Epoch 787/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3281 - accuracy: 0.8786 - val_loss: 192.9114 - val_accuracy: 0.4533\n",
            "Epoch 788/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3353 - accuracy: 0.8637 - val_loss: 232.9914 - val_accuracy: 0.4533\n",
            "Epoch 789/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3321 - accuracy: 0.8747 - val_loss: 199.6901 - val_accuracy: 0.4600\n",
            "Epoch 790/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3377 - accuracy: 0.8748 - val_loss: 184.1708 - val_accuracy: 0.4867\n",
            "Epoch 791/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3294 - accuracy: 0.8806 - val_loss: 181.3325 - val_accuracy: 0.4867\n",
            "Epoch 792/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3401 - accuracy: 0.8757 - val_loss: 214.7907 - val_accuracy: 0.4333\n",
            "Epoch 793/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3283 - accuracy: 0.8748 - val_loss: 192.0321 - val_accuracy: 0.4733\n",
            "Epoch 794/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3258 - accuracy: 0.8851 - val_loss: 226.4228 - val_accuracy: 0.4333\n",
            "Epoch 795/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3262 - accuracy: 0.8779 - val_loss: 205.5379 - val_accuracy: 0.4533\n",
            "Epoch 796/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3278 - accuracy: 0.8801 - val_loss: 222.5804 - val_accuracy: 0.4133\n",
            "Epoch 797/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3326 - accuracy: 0.8731 - val_loss: 193.4201 - val_accuracy: 0.4533\n",
            "Epoch 798/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3262 - accuracy: 0.8840 - val_loss: 182.8351 - val_accuracy: 0.4867\n",
            "Epoch 799/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3514 - accuracy: 0.8676 - val_loss: 190.5943 - val_accuracy: 0.4800\n",
            "Epoch 800/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3229 - accuracy: 0.8866 - val_loss: 195.5090 - val_accuracy: 0.4733\n",
            "Epoch 801/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3435 - accuracy: 0.8711 - val_loss: 217.9974 - val_accuracy: 0.4333\n",
            "Epoch 802/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3446 - accuracy: 0.8741 - val_loss: 226.8650 - val_accuracy: 0.4133\n",
            "Epoch 803/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3248 - accuracy: 0.8864 - val_loss: 220.4521 - val_accuracy: 0.4400\n",
            "Epoch 804/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3064 - accuracy: 0.8908 - val_loss: 199.0810 - val_accuracy: 0.4400\n",
            "Epoch 805/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3119 - accuracy: 0.8934 - val_loss: 181.0712 - val_accuracy: 0.4667\n",
            "Epoch 806/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2852 - accuracy: 0.9031 - val_loss: 196.0994 - val_accuracy: 0.4467\n",
            "Epoch 807/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3357 - accuracy: 0.8804 - val_loss: 210.5095 - val_accuracy: 0.4267\n",
            "Epoch 808/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3277 - accuracy: 0.8825 - val_loss: 206.5322 - val_accuracy: 0.4533\n",
            "Epoch 809/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3209 - accuracy: 0.8915 - val_loss: 213.6192 - val_accuracy: 0.4533\n",
            "Epoch 810/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3137 - accuracy: 0.8862 - val_loss: 210.3864 - val_accuracy: 0.4533\n",
            "Epoch 811/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3131 - accuracy: 0.8861 - val_loss: 197.0639 - val_accuracy: 0.4667\n",
            "Epoch 812/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3214 - accuracy: 0.8835 - val_loss: 207.6924 - val_accuracy: 0.4400\n",
            "Epoch 813/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3133 - accuracy: 0.8927 - val_loss: 209.7209 - val_accuracy: 0.4400\n",
            "Epoch 814/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3146 - accuracy: 0.8860 - val_loss: 199.4488 - val_accuracy: 0.4400\n",
            "Epoch 815/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3216 - accuracy: 0.8758 - val_loss: 197.1121 - val_accuracy: 0.4467\n",
            "Epoch 816/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3102 - accuracy: 0.8823 - val_loss: 206.4638 - val_accuracy: 0.4467\n",
            "Epoch 817/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3278 - accuracy: 0.8793 - val_loss: 187.4397 - val_accuracy: 0.4867\n",
            "Epoch 818/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3094 - accuracy: 0.8818 - val_loss: 166.5514 - val_accuracy: 0.5000\n",
            "Epoch 819/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3098 - accuracy: 0.8857 - val_loss: 171.2630 - val_accuracy: 0.4733\n",
            "Epoch 820/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3081 - accuracy: 0.8937 - val_loss: 167.6024 - val_accuracy: 0.4933\n",
            "Epoch 821/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3027 - accuracy: 0.8856 - val_loss: 201.8648 - val_accuracy: 0.4467\n",
            "Epoch 822/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3166 - accuracy: 0.8841 - val_loss: 157.4228 - val_accuracy: 0.4867\n",
            "Epoch 823/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3104 - accuracy: 0.8933 - val_loss: 177.8852 - val_accuracy: 0.4800\n",
            "Epoch 824/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3475 - accuracy: 0.8744 - val_loss: 183.8327 - val_accuracy: 0.4667\n",
            "Epoch 825/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3069 - accuracy: 0.8948 - val_loss: 194.2953 - val_accuracy: 0.4800\n",
            "Epoch 826/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3151 - accuracy: 0.8902 - val_loss: 193.3400 - val_accuracy: 0.4800\n",
            "Epoch 827/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3283 - accuracy: 0.8899 - val_loss: 206.5621 - val_accuracy: 0.4533\n",
            "Epoch 828/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3086 - accuracy: 0.8939 - val_loss: 184.0121 - val_accuracy: 0.4733\n",
            "Epoch 829/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3267 - accuracy: 0.8781 - val_loss: 188.5193 - val_accuracy: 0.4667\n",
            "Epoch 830/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3158 - accuracy: 0.8831 - val_loss: 193.5785 - val_accuracy: 0.4600\n",
            "Epoch 831/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3030 - accuracy: 0.8865 - val_loss: 174.8604 - val_accuracy: 0.4800\n",
            "Epoch 832/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3114 - accuracy: 0.8852 - val_loss: 198.4719 - val_accuracy: 0.4533\n",
            "Epoch 833/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3245 - accuracy: 0.8781 - val_loss: 205.0811 - val_accuracy: 0.4467\n",
            "Epoch 834/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3254 - accuracy: 0.8751 - val_loss: 187.5758 - val_accuracy: 0.4667\n",
            "Epoch 835/1000\n",
            "83/83 [==============================] - 20s 240ms/step - loss: 0.3114 - accuracy: 0.8970 - val_loss: 214.4520 - val_accuracy: 0.4533\n",
            "Epoch 836/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3276 - accuracy: 0.8801 - val_loss: 196.2168 - val_accuracy: 0.4667\n",
            "Epoch 837/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3343 - accuracy: 0.8838 - val_loss: 210.2746 - val_accuracy: 0.4533\n",
            "Epoch 838/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3062 - accuracy: 0.8916 - val_loss: 223.8479 - val_accuracy: 0.4400\n",
            "Epoch 839/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3195 - accuracy: 0.8790 - val_loss: 230.6497 - val_accuracy: 0.4467\n",
            "Epoch 840/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3037 - accuracy: 0.8937 - val_loss: 203.2228 - val_accuracy: 0.4733\n",
            "Epoch 841/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3238 - accuracy: 0.8769 - val_loss: 176.7499 - val_accuracy: 0.4733\n",
            "Epoch 842/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3127 - accuracy: 0.8856 - val_loss: 177.9481 - val_accuracy: 0.4667\n",
            "Epoch 843/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.2985 - accuracy: 0.9045 - val_loss: 183.9001 - val_accuracy: 0.4800\n",
            "Epoch 844/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3427 - accuracy: 0.8770 - val_loss: 180.9035 - val_accuracy: 0.4800\n",
            "Epoch 845/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3210 - accuracy: 0.8814 - val_loss: 179.6449 - val_accuracy: 0.4733\n",
            "Epoch 846/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3198 - accuracy: 0.8910 - val_loss: 196.6257 - val_accuracy: 0.4733\n",
            "Epoch 847/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3107 - accuracy: 0.8825 - val_loss: 201.4057 - val_accuracy: 0.4533\n",
            "Epoch 848/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3285 - accuracy: 0.8746 - val_loss: 179.5701 - val_accuracy: 0.4667\n",
            "Epoch 849/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3134 - accuracy: 0.8853 - val_loss: 191.1788 - val_accuracy: 0.4600\n",
            "Epoch 850/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3234 - accuracy: 0.8887 - val_loss: 189.4096 - val_accuracy: 0.4600\n",
            "Epoch 851/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3252 - accuracy: 0.8880 - val_loss: 170.5024 - val_accuracy: 0.4800\n",
            "Epoch 852/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3023 - accuracy: 0.8887 - val_loss: 184.8451 - val_accuracy: 0.4733\n",
            "Epoch 853/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.2930 - accuracy: 0.8942 - val_loss: 197.5992 - val_accuracy: 0.4600\n",
            "Epoch 854/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3261 - accuracy: 0.8912 - val_loss: 216.1183 - val_accuracy: 0.4533\n",
            "Epoch 855/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3445 - accuracy: 0.8672 - val_loss: 219.3661 - val_accuracy: 0.4467\n",
            "Epoch 856/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3214 - accuracy: 0.8892 - val_loss: 222.8903 - val_accuracy: 0.4333\n",
            "Epoch 857/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3291 - accuracy: 0.8810 - val_loss: 191.9587 - val_accuracy: 0.4600\n",
            "Epoch 858/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3125 - accuracy: 0.8944 - val_loss: 171.3459 - val_accuracy: 0.4867\n",
            "Epoch 859/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.2966 - accuracy: 0.8973 - val_loss: 181.7504 - val_accuracy: 0.4533\n",
            "Epoch 860/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3215 - accuracy: 0.8866 - val_loss: 189.8618 - val_accuracy: 0.4600\n",
            "Epoch 861/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3278 - accuracy: 0.8702 - val_loss: 190.9915 - val_accuracy: 0.4600\n",
            "Epoch 862/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3283 - accuracy: 0.8720 - val_loss: 194.4382 - val_accuracy: 0.4600\n",
            "Epoch 863/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3212 - accuracy: 0.8809 - val_loss: 183.2534 - val_accuracy: 0.4667\n",
            "Epoch 864/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3171 - accuracy: 0.8808 - val_loss: 196.5686 - val_accuracy: 0.4667\n",
            "Epoch 865/1000\n",
            "83/83 [==============================] - 20s 241ms/step - loss: 0.3327 - accuracy: 0.8814 - val_loss: 196.3301 - val_accuracy: 0.4667\n",
            "Epoch 866/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3304 - accuracy: 0.8796 - val_loss: 182.2800 - val_accuracy: 0.4733\n",
            "Epoch 867/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3002 - accuracy: 0.8987 - val_loss: 170.6847 - val_accuracy: 0.4867\n",
            "Epoch 868/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3010 - accuracy: 0.9018 - val_loss: 162.6896 - val_accuracy: 0.4867\n",
            "Epoch 869/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3273 - accuracy: 0.8837 - val_loss: 173.4153 - val_accuracy: 0.4933\n",
            "Epoch 870/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3086 - accuracy: 0.8861 - val_loss: 169.3036 - val_accuracy: 0.5000\n",
            "Epoch 871/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3276 - accuracy: 0.8779 - val_loss: 180.8875 - val_accuracy: 0.4733\n",
            "Epoch 872/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3122 - accuracy: 0.8850 - val_loss: 177.6336 - val_accuracy: 0.4867\n",
            "Epoch 873/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3314 - accuracy: 0.8797 - val_loss: 178.4524 - val_accuracy: 0.4933\n",
            "Epoch 874/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3245 - accuracy: 0.8779 - val_loss: 169.4819 - val_accuracy: 0.4867\n",
            "Epoch 875/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3169 - accuracy: 0.8827 - val_loss: 182.6778 - val_accuracy: 0.4867\n",
            "Epoch 876/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3079 - accuracy: 0.8965 - val_loss: 178.7546 - val_accuracy: 0.4867\n",
            "Epoch 877/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3221 - accuracy: 0.8888 - val_loss: 185.7965 - val_accuracy: 0.4467\n",
            "Epoch 878/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3039 - accuracy: 0.8853 - val_loss: 173.9070 - val_accuracy: 0.4667\n",
            "Epoch 879/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3075 - accuracy: 0.8885 - val_loss: 187.5101 - val_accuracy: 0.4533\n",
            "Epoch 880/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3093 - accuracy: 0.8885 - val_loss: 205.6900 - val_accuracy: 0.4267\n",
            "Epoch 881/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3038 - accuracy: 0.8953 - val_loss: 205.6013 - val_accuracy: 0.4400\n",
            "Epoch 882/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3102 - accuracy: 0.8902 - val_loss: 218.0915 - val_accuracy: 0.4200\n",
            "Epoch 883/1000\n",
            "83/83 [==============================] - 20s 238ms/step - loss: 0.3131 - accuracy: 0.8855 - val_loss: 190.2285 - val_accuracy: 0.4667\n",
            "Epoch 884/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3014 - accuracy: 0.8819 - val_loss: 193.0544 - val_accuracy: 0.4733\n",
            "Epoch 885/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3040 - accuracy: 0.8914 - val_loss: 214.2008 - val_accuracy: 0.4400\n",
            "Epoch 886/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3286 - accuracy: 0.8822 - val_loss: 234.7310 - val_accuracy: 0.4133\n",
            "Epoch 887/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3243 - accuracy: 0.8913 - val_loss: 204.8428 - val_accuracy: 0.4400\n",
            "Epoch 888/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3010 - accuracy: 0.8937 - val_loss: 214.6077 - val_accuracy: 0.4400\n",
            "Epoch 889/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3175 - accuracy: 0.8876 - val_loss: 220.3978 - val_accuracy: 0.4200\n",
            "Epoch 890/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3370 - accuracy: 0.8732 - val_loss: 209.3457 - val_accuracy: 0.4400\n",
            "Epoch 891/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3198 - accuracy: 0.8892 - val_loss: 209.1616 - val_accuracy: 0.4333\n",
            "Epoch 892/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3158 - accuracy: 0.8827 - val_loss: 209.6919 - val_accuracy: 0.4333\n",
            "Epoch 893/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3006 - accuracy: 0.8964 - val_loss: 220.2042 - val_accuracy: 0.4133\n",
            "Epoch 894/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3044 - accuracy: 0.8861 - val_loss: 190.9548 - val_accuracy: 0.4600\n",
            "Epoch 895/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2899 - accuracy: 0.8962 - val_loss: 224.0120 - val_accuracy: 0.4133\n",
            "Epoch 896/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3348 - accuracy: 0.8755 - val_loss: 229.1094 - val_accuracy: 0.4000\n",
            "Epoch 897/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3149 - accuracy: 0.8868 - val_loss: 215.9106 - val_accuracy: 0.4200\n",
            "Epoch 898/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3172 - accuracy: 0.8742 - val_loss: 202.3134 - val_accuracy: 0.4333\n",
            "Epoch 899/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3000 - accuracy: 0.8871 - val_loss: 211.4184 - val_accuracy: 0.4200\n",
            "Epoch 900/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3001 - accuracy: 0.8963 - val_loss: 216.2886 - val_accuracy: 0.4400\n",
            "Epoch 901/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3187 - accuracy: 0.8926 - val_loss: 226.7482 - val_accuracy: 0.4133\n",
            "Epoch 902/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3098 - accuracy: 0.8941 - val_loss: 228.0651 - val_accuracy: 0.4067\n",
            "Epoch 903/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3182 - accuracy: 0.8862 - val_loss: 221.1500 - val_accuracy: 0.4200\n",
            "Epoch 904/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.3072 - accuracy: 0.8819 - val_loss: 229.1151 - val_accuracy: 0.4267\n",
            "Epoch 905/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3195 - accuracy: 0.8766 - val_loss: 238.1250 - val_accuracy: 0.4067\n",
            "Epoch 906/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3286 - accuracy: 0.8776 - val_loss: 231.3544 - val_accuracy: 0.4200\n",
            "Epoch 907/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3177 - accuracy: 0.8906 - val_loss: 213.1460 - val_accuracy: 0.4333\n",
            "Epoch 908/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2952 - accuracy: 0.8971 - val_loss: 201.3922 - val_accuracy: 0.4267\n",
            "Epoch 909/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3123 - accuracy: 0.8863 - val_loss: 203.8746 - val_accuracy: 0.4333\n",
            "Epoch 910/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3022 - accuracy: 0.8890 - val_loss: 217.7640 - val_accuracy: 0.4267\n",
            "Epoch 911/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.2993 - accuracy: 0.8917 - val_loss: 209.3663 - val_accuracy: 0.4400\n",
            "Epoch 912/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3034 - accuracy: 0.8886 - val_loss: 211.2388 - val_accuracy: 0.4333\n",
            "Epoch 913/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3149 - accuracy: 0.8854 - val_loss: 194.2677 - val_accuracy: 0.4400\n",
            "Epoch 914/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2908 - accuracy: 0.8995 - val_loss: 218.6642 - val_accuracy: 0.4333\n",
            "Epoch 915/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.2986 - accuracy: 0.8978 - val_loss: 212.0470 - val_accuracy: 0.4267\n",
            "Epoch 916/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2739 - accuracy: 0.9076 - val_loss: 206.2125 - val_accuracy: 0.4267\n",
            "Epoch 917/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.3095 - accuracy: 0.8925 - val_loss: 209.3921 - val_accuracy: 0.4333\n",
            "Epoch 918/1000\n",
            "83/83 [==============================] - 20s 242ms/step - loss: 0.2827 - accuracy: 0.8946 - val_loss: 196.5095 - val_accuracy: 0.4467\n",
            "Epoch 919/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3000 - accuracy: 0.8999 - val_loss: 221.6604 - val_accuracy: 0.4267\n",
            "Epoch 920/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3281 - accuracy: 0.8847 - val_loss: 241.0083 - val_accuracy: 0.4267\n",
            "Epoch 921/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3091 - accuracy: 0.8838 - val_loss: 240.0848 - val_accuracy: 0.4667\n",
            "Epoch 922/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2970 - accuracy: 0.8877 - val_loss: 206.8126 - val_accuracy: 0.4667\n",
            "Epoch 923/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2800 - accuracy: 0.9071 - val_loss: 229.5864 - val_accuracy: 0.4400\n",
            "Epoch 924/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3132 - accuracy: 0.8856 - val_loss: 235.7473 - val_accuracy: 0.4467\n",
            "Epoch 925/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3016 - accuracy: 0.8942 - val_loss: 225.5914 - val_accuracy: 0.4267\n",
            "Epoch 926/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.2998 - accuracy: 0.8918 - val_loss: 219.0714 - val_accuracy: 0.4333\n",
            "Epoch 927/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3180 - accuracy: 0.8897 - val_loss: 224.3123 - val_accuracy: 0.4333\n",
            "Epoch 928/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3108 - accuracy: 0.8826 - val_loss: 229.7252 - val_accuracy: 0.4200\n",
            "Epoch 929/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3031 - accuracy: 0.8897 - val_loss: 220.2814 - val_accuracy: 0.4400\n",
            "Epoch 930/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3168 - accuracy: 0.8847 - val_loss: 201.9311 - val_accuracy: 0.4400\n",
            "Epoch 931/1000\n",
            "83/83 [==============================] - 21s 256ms/step - loss: 0.3102 - accuracy: 0.8843 - val_loss: 214.8622 - val_accuracy: 0.4200\n",
            "Epoch 932/1000\n",
            "83/83 [==============================] - 21s 252ms/step - loss: 0.2803 - accuracy: 0.9053 - val_loss: 197.3154 - val_accuracy: 0.4467\n",
            "Epoch 933/1000\n",
            "83/83 [==============================] - 20s 244ms/step - loss: 0.2887 - accuracy: 0.8944 - val_loss: 224.7887 - val_accuracy: 0.4267\n",
            "Epoch 934/1000\n",
            "83/83 [==============================] - 20s 241ms/step - loss: 0.3137 - accuracy: 0.9038 - val_loss: 214.9046 - val_accuracy: 0.4267\n",
            "Epoch 935/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.2617 - accuracy: 0.9181 - val_loss: 246.5044 - val_accuracy: 0.4067\n",
            "Epoch 936/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3014 - accuracy: 0.8939 - val_loss: 226.2388 - val_accuracy: 0.4400\n",
            "Epoch 937/1000\n",
            "83/83 [==============================] - 20s 246ms/step - loss: 0.3177 - accuracy: 0.8865 - val_loss: 207.7979 - val_accuracy: 0.4333\n",
            "Epoch 938/1000\n",
            "83/83 [==============================] - 20s 240ms/step - loss: 0.3009 - accuracy: 0.8952 - val_loss: 209.0477 - val_accuracy: 0.4267\n",
            "Epoch 939/1000\n",
            "83/83 [==============================] - 20s 242ms/step - loss: 0.3103 - accuracy: 0.8944 - val_loss: 212.0503 - val_accuracy: 0.4267\n",
            "Epoch 940/1000\n",
            "83/83 [==============================] - 20s 242ms/step - loss: 0.3088 - accuracy: 0.8834 - val_loss: 209.3105 - val_accuracy: 0.4200\n",
            "Epoch 941/1000\n",
            "83/83 [==============================] - 20s 240ms/step - loss: 0.3144 - accuracy: 0.8858 - val_loss: 212.9438 - val_accuracy: 0.4333\n",
            "Epoch 942/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.2957 - accuracy: 0.8932 - val_loss: 225.5471 - val_accuracy: 0.4533\n",
            "Epoch 943/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3051 - accuracy: 0.8905 - val_loss: 215.1180 - val_accuracy: 0.4333\n",
            "Epoch 944/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3248 - accuracy: 0.8838 - val_loss: 207.5185 - val_accuracy: 0.4400\n",
            "Epoch 945/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3084 - accuracy: 0.8958 - val_loss: 204.1221 - val_accuracy: 0.4400\n",
            "Epoch 946/1000\n",
            "83/83 [==============================] - 20s 239ms/step - loss: 0.2955 - accuracy: 0.8828 - val_loss: 224.0528 - val_accuracy: 0.4333\n",
            "Epoch 947/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3017 - accuracy: 0.8950 - val_loss: 227.5261 - val_accuracy: 0.4267\n",
            "Epoch 948/1000\n",
            "83/83 [==============================] - 20s 244ms/step - loss: 0.2819 - accuracy: 0.8961 - val_loss: 209.6031 - val_accuracy: 0.4333\n",
            "Epoch 949/1000\n",
            "83/83 [==============================] - 21s 251ms/step - loss: 0.3155 - accuracy: 0.8917 - val_loss: 218.1680 - val_accuracy: 0.4400\n",
            "Epoch 950/1000\n",
            "83/83 [==============================] - 20s 245ms/step - loss: 0.3125 - accuracy: 0.8840 - val_loss: 197.6609 - val_accuracy: 0.4467\n",
            "Epoch 951/1000\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.2867 - accuracy: 0.9063 - val_loss: 223.1615 - val_accuracy: 0.4333\n",
            "Epoch 952/1000\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.2974 - accuracy: 0.8928 - val_loss: 212.4412 - val_accuracy: 0.4333\n",
            "Epoch 953/1000\n",
            "83/83 [==============================] - 20s 242ms/step - loss: 0.3125 - accuracy: 0.8852 - val_loss: 214.7579 - val_accuracy: 0.4333\n",
            "Epoch 954/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.2950 - accuracy: 0.8902 - val_loss: 238.5020 - val_accuracy: 0.4133\n",
            "Epoch 955/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.2988 - accuracy: 0.8888 - val_loss: 207.0659 - val_accuracy: 0.4333\n",
            "Epoch 956/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3012 - accuracy: 0.8928 - val_loss: 215.8180 - val_accuracy: 0.4333\n",
            "Epoch 957/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.2822 - accuracy: 0.9017 - val_loss: 222.3675 - val_accuracy: 0.4400\n",
            "Epoch 958/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3022 - accuracy: 0.8910 - val_loss: 220.5775 - val_accuracy: 0.4333\n",
            "Epoch 959/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.2988 - accuracy: 0.8920 - val_loss: 225.1061 - val_accuracy: 0.4400\n",
            "Epoch 960/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3029 - accuracy: 0.8945 - val_loss: 213.5412 - val_accuracy: 0.4333\n",
            "Epoch 961/1000\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.3101 - accuracy: 0.8838 - val_loss: 220.3424 - val_accuracy: 0.4400\n",
            "Epoch 962/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.2955 - accuracy: 0.8929 - val_loss: 240.9430 - val_accuracy: 0.4133\n",
            "Epoch 963/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3025 - accuracy: 0.8856 - val_loss: 235.8680 - val_accuracy: 0.4267\n",
            "Epoch 964/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.2903 - accuracy: 0.8932 - val_loss: 220.0318 - val_accuracy: 0.4467\n",
            "Epoch 965/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3164 - accuracy: 0.8864 - val_loss: 253.4469 - val_accuracy: 0.4000\n",
            "Epoch 966/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3093 - accuracy: 0.8960 - val_loss: 230.3892 - val_accuracy: 0.4400\n",
            "Epoch 967/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2993 - accuracy: 0.8869 - val_loss: 263.1222 - val_accuracy: 0.4133\n",
            "Epoch 968/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2815 - accuracy: 0.9035 - val_loss: 252.0172 - val_accuracy: 0.4267\n",
            "Epoch 969/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.2910 - accuracy: 0.8916 - val_loss: 248.9029 - val_accuracy: 0.4000\n",
            "Epoch 970/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2955 - accuracy: 0.8956 - val_loss: 239.6508 - val_accuracy: 0.4200\n",
            "Epoch 971/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.2887 - accuracy: 0.8924 - val_loss: 216.4050 - val_accuracy: 0.4333\n",
            "Epoch 972/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3068 - accuracy: 0.8864 - val_loss: 224.2928 - val_accuracy: 0.4400\n",
            "Epoch 973/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.2991 - accuracy: 0.8933 - val_loss: 240.0591 - val_accuracy: 0.4267\n",
            "Epoch 974/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.2966 - accuracy: 0.8905 - val_loss: 233.5856 - val_accuracy: 0.4467\n",
            "Epoch 975/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.3072 - accuracy: 0.8899 - val_loss: 246.8746 - val_accuracy: 0.4000\n",
            "Epoch 976/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.2966 - accuracy: 0.9019 - val_loss: 252.4045 - val_accuracy: 0.4000\n",
            "Epoch 977/1000\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.2925 - accuracy: 0.8899 - val_loss: 210.2173 - val_accuracy: 0.4400\n",
            "Epoch 978/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.3023 - accuracy: 0.8947 - val_loss: 199.2638 - val_accuracy: 0.4467\n",
            "Epoch 979/1000\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 0.2894 - accuracy: 0.8957 - val_loss: 193.3418 - val_accuracy: 0.4467\n",
            "Epoch 980/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2962 - accuracy: 0.8995 - val_loss: 228.2453 - val_accuracy: 0.4333\n",
            "Epoch 981/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2789 - accuracy: 0.9016 - val_loss: 203.0738 - val_accuracy: 0.4400\n",
            "Epoch 982/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3094 - accuracy: 0.8873 - val_loss: 184.3413 - val_accuracy: 0.4600\n",
            "Epoch 983/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.3064 - accuracy: 0.8872 - val_loss: 200.7123 - val_accuracy: 0.4533\n",
            "Epoch 984/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2804 - accuracy: 0.8939 - val_loss: 217.2713 - val_accuracy: 0.4533\n",
            "Epoch 985/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.2792 - accuracy: 0.9081 - val_loss: 220.4290 - val_accuracy: 0.4533\n",
            "Epoch 986/1000\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.3106 - accuracy: 0.8900 - val_loss: 236.2439 - val_accuracy: 0.4400\n",
            "Epoch 987/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.2802 - accuracy: 0.8978 - val_loss: 240.7823 - val_accuracy: 0.4200\n",
            "Epoch 988/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3154 - accuracy: 0.8723 - val_loss: 229.2915 - val_accuracy: 0.4333\n",
            "Epoch 989/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2946 - accuracy: 0.8947 - val_loss: 210.8170 - val_accuracy: 0.4467\n",
            "Epoch 990/1000\n",
            "83/83 [==============================] - 20s 237ms/step - loss: 0.3010 - accuracy: 0.8965 - val_loss: 209.0966 - val_accuracy: 0.4600\n",
            "Epoch 991/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2761 - accuracy: 0.9105 - val_loss: 216.1557 - val_accuracy: 0.4667\n",
            "Epoch 992/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2953 - accuracy: 0.8968 - val_loss: 200.5198 - val_accuracy: 0.4467\n",
            "Epoch 993/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2845 - accuracy: 0.8920 - val_loss: 231.1205 - val_accuracy: 0.4400\n",
            "Epoch 994/1000\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.2937 - accuracy: 0.8972 - val_loss: 207.9087 - val_accuracy: 0.4467\n",
            "Epoch 995/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3037 - accuracy: 0.8994 - val_loss: 225.7810 - val_accuracy: 0.4400\n",
            "Epoch 996/1000\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.2980 - accuracy: 0.8869 - val_loss: 209.8847 - val_accuracy: 0.4667\n",
            "Epoch 997/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3066 - accuracy: 0.8903 - val_loss: 205.0915 - val_accuracy: 0.4667\n",
            "Epoch 998/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.2976 - accuracy: 0.8992 - val_loss: 199.1879 - val_accuracy: 0.4600\n",
            "Epoch 999/1000\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.3030 - accuracy: 0.8996 - val_loss: 241.4309 - val_accuracy: 0.4333\n",
            "Epoch 1000/1000\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.2911 - accuracy: 0.9051 - val_loss: 201.6351 - val_accuracy: 0.4600\n",
            "Train Accuracy of the model is 0.5644320944772491\n",
            "Test Accuracy of the model is 0.46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUxd6A30mvJJCETgggvUOoNhBEitgQAXvFem1X78WOXe9VvyvXcsXexYIdCyigIiAgiCC9h55AQoD0zPfH7Nk9u3t29yTZTZ33efLsOXPmzJlNYH5nflVIKdFoNBpNwyWspieg0Wg0mppFCwKNRqNp4GhBoNFoNA0cLQg0Go2mgaMFgUaj0TRwtCDQaDSaBo4WBJoGhRDiDSHEIzb7bhdCjAz1nDSamkYLAo1Go2ngaEGg0dRBhBARNT0HTf1BCwJNrcOhkrlTCLFaCHFMCPGqEKKZEOIbIUS+EGKeEKKxqf9ZQoi1QohcIcQCIURX07W+QojfHffNAmI8nnWmEGKV495fhRC9bM5xnBBipRDiiBBilxBiusf1kxzj5TquX+5ojxVCPC2E2CGEyBNC/OJoGyaEyLL4PYx0HE8XQnwshHhHCHEEuFwIMVAIsdjxjL1CiOeEEFGm+7sLIeYKIQ4JIfYLIe4WQjQXQhwXQqSY+vUTQhwUQkTa+e6a+ocWBJraygTgdKATMB74BrgbSEP9u70ZQAjRCXgfuNVxbQ7wpRAiyrEofga8DTQBPnKMi+PevsBrwLVACvAS8IUQItrG/I4BlwLJwDjgeiHEOY5x2zrm+1/HnPoAqxz3PQX0B4Y65vQPoNzm7+Rs4GPHM98FyoDbgFRgCDACuMExh0RgHvAt0BI4AfhBSrkPWABcYBr3EuADKWWJzXlo6hlaEGhqK/+VUu6XUu4GfgaWSilXSikLgU+Bvo5+k4CvpZRzHQvZU0AsaqEdDEQC/5FSlkgpPwaWmZ4xFXhJSrlUSlkmpXwTKHLc5xcp5QIp5Z9SynIp5WqUMDrVcflCYJ6U8n3Hc3OklKuEEGHAlcAtUsrdjmf+KqUssvk7WSyl/MzxzAIp5Qop5RIpZamUcjtKkBlzOBPYJ6V8WkpZKKXMl1IudVx7E7gYQAgRDkxBCUtNA0ULAk1tZb/puMDiPMFx3BLYYVyQUpYDu4BWjmu7pXtmxR2m47bA3x2qlVwhRC7QxnGfX4QQg4QQ8x0qlTzgOtSbOY4xtljclopSTVlds8Mujzl0EkJ8JYTY51AXPWZjDgCfA92EEO1Qu648KeVvlZyTph6gBYGmrrMHtaADIIQQqEVwN7AXaOVoM0g3He8CHpVSJpt+4qSU79t47nvAF0AbKWUS8D/AeM4uoIPFPdlAoY9rx4A40/cIR6mVzHimCn4RWA90lFI2QqnOzHNobzVxx67qQ9Su4BL0bqDBowWBpq7zITBOCDHCYez8O0q98yuwGCgFbhZCRAohzgMGmu59GbjO8XYvhBDxDiNwoo3nJgKHpJSFQoiBKHWQwbvASCHEBUKICCFEihCij2O38hrwjBCipRAiXAgxxGGT2AjEOJ4fCdwLBLJVJAJHgKNCiC7A9aZrXwEthBC3CiGihRCJQohBputvAZcDZ6EFQYNHCwJNnUZKuQH1Zvtf1Bv3eGC8lLJYSlkMnIda8A6h7AmzTfcuB64BngMOA5sdfe1wA/CQECIfuB8lkIxxdwJjUULpEMpQ3Ntx+Q7gT5St4hDwJBAmpcxzjPkKajdzDHDzIrLgDpQAykcJtVmmOeSj1D7jgX3AJmC46foilJH6dymlWV2maYAIXZhGo2mYCCF+BN6TUr5S03PR1CxaEGg0DRAhxABgLsrGkV/T89HULFo1pNE0MIQQb6JiDG7VQkADekeg0Wg0DR69I9BoNJoGTp1LXJWamiozMjJqehoajUZTp1ixYkW2lNIzNgWog4IgIyOD5cuX1/Q0NBqNpk4hhPDpJqxVQxqNRtPA0YJAo9FoGjhaEGg0Gk0Dp87ZCKwoKSkhKyuLwsLCmp5KSImJiaF169ZERur6IRqNJnjUC0GQlZVFYmIiGRkZuCearD9IKcnJySErK4t27drV9HQ0Gk09ol6ohgoLC0lJSam3QgBACEFKSkq93/VoNJrqp14IAqBeCwGDhvAdNRpN9VNvBIFGo9HUJn7ZlM227GM1PQ1baEEQBHJzc3nhhRcqfN/YsWPJzc0NwYw0Gk1Nc/GrSxn+1IKanoYttCAIAr4EQWlpqd/75syZQ3JycqimpdFoNLYIqSAQQowWQmwQQmwWQkyzuN5WCPGDEGK1EGKBEKJ1KOcTKqZNm8aWLVvo06cPAwYM4OSTT+ass86iW7duAJxzzjn079+f7t27M3PmTOd9GRkZZGdns337drp27co111xD9+7dGTVqFAUFBTX1dTQaTRUpK69bWZ1D5j7qKL79PKpcXhawTAjxhZTyL1O3p4C3pJRvCiFOAx5HFdOuNA9+uZa/9hypyhBedGvZiAfGd/d5/YknnmDNmjWsWrWKBQsWMG7cONasWeN083zttddo0qQJBQUFDBgwgAkTJpCSkuI2xqZNm3j//fd5+eWXueCCC/jkk0+4+OKLg/o9NBpN8NmwL5+jRaX0b9vY2Xas2FobMPev/fRNTyY1wb0c9c6c4/zjkz947sJ+FJeWs3bPEfbmFXDpkIxQTt1JKOMIBgKbpZRbAYQQHwBnA2ZB0A243XE8H/gshPOpNgYOHOjm6z9jxgw+/fRTAHbt2sWmTZu8BEG7du3o06cPAP3792f79u3VNl+NRlN5zvjPTwBsf2Kcs+14UZlXv2NFpVzz1nK6tmjEN7eczKFjxRSVlvH09xv5eIUqT535yDy3e/ILS2ndOJaz+7Ti81W7Ob1bM+Kigr9sh1IQtAJ2mc6zgEEeff5AFRd/FjgXSBRCpEgpc8ydhBBTgakA6enpfh/q7829uoiPj3ceL1iwgHnz5rF48WLi4uIYNmyYZSxAdLTrDSE8PFyrhjSaGqK0rJwwIQgL83bXLi+XlElJZLi3Vv3bNXspKCkjvUkcyXFRzva3l+wg91gxP6w/AMC6vUf4Yd1+rnozcBblf3+3AYDXftnGH1l5TBvThetO7VDZr+aTmo4svgN4TghxOfATsBvwEqVSypnATIDMzMxap3xLTEwkP9+64l9eXh6NGzcmLi6O9evXs2TJkmqenUZTP8k9XszmA0fJzGhSqfvLyyX//XEzZ/VpSavkWH7aeJARXZtywj3fcGqnNJ6d3IcjBaWs3HWYM3u1ZMYPm1iyNYel2w6x8ZExfLt2HyWl5c7xrnvnd+fxmB7Nncf3fbbG69l2hICZP7LyALh8aEYFv6U9QikIdgNtTOetHW1OpJR7UDsChBAJwAQpZZ3zp0xJSeHEE0+kR48exMbG0qxZM+e10aNH87///Y+uXbvSuXNnBg8eXIMz1WjqD5e9vow/duWy8ZExPD13A5My25DeJI4wIcgrKEEChSVlzPxpK/eM60pkeBgH8gtZuvUQf3t/JeN6teDr1XtZvDWblkmxzF65m/P7K3+VhRsP0uehuc5nHcwv4tkfNjnPn/x2Pa/+ss3n3L5Zsy/o3/eZC3oTExke9HEhhDWLhRARwEZgBEoALAMulFKuNfVJBQ5JKcuFEI8CZVLK+/2Nm5mZKT0L06xbt46uXbsG+yvUShrSd9U0LIy16K3FOyguLeeyoRlERVg7NkopaXfXHACuPLEdry3aRrvUeLZlH2Ni/9b8vvMwB/OL6Nk6iUWbc3jryoFM/3ItWw96B3j1bJXEzkPHySsoqfTce7ZK4s/deZW+HyA2MpxJA9rwxq/b3do3PzrGp6qqIgghVkgpM62uhWxHIKUsFULcBHwHhAOvSSnXCiEeApZLKb8AhgGPCyEkSjV0Y6jmo9FoaoYN+/KRSDJS4iksKSM5Lorso0XcNftP/jWhF43jo/h0ZRa3zfrD7b72afGM6NrMre2Z7zfQunEc933uUre8tki9mRtRvB85DK8AizYrc+Olr/3mc35VWcD/dX4vft9xmFtGdmTI4z+6Xfv8xhO5bdYqtjrmFRURxg3DOvCfeZtolRzL7lyXHfDlSzM56YRUYqPCKS0v550lO53XIizsEcEmZDuCUKF3BA3nu2pqHweOFIKAA0eKKCoto3/bJl7Xf9mcTUJ0BM2TYsg5VswVry8DoFfrJFZneS+6953ZjYe/+surHeDZyX14e/EOOjdP5N2lOy37VIbLh2Z4vXl7khAdwdGiUro0T2T9Pm8bYFR4GBsfHePWtuXgUUY8vZDoiDA2PDKGg/lF3PPpn3z/137+fX4vJma2oaSsnLJyydo9R3jl56386/xeJMa4Usu/tXg793++lvvO7MaYHs1pmRwbjK9cMzsCjUZTt9h84CgtkmKIj/a9LEx+eYmbemXNg2fwwW87uWxoBuv2HuGs5xb5vNdKCAA+hQDALR+sAmD5jsOBpl8hEhzfMTkuktzj3iqhBXcMI71JHEeLS4mJCGfx1hx2Hy7g7k//5LQuTflx/QEmZnrHv8Y7XDvDHWqctMRoZl6ayZHCEhIdz4wMDyMyHPq3bUz/tv29xrh4UFvSm8Rxaqe0aks0qQWBRlMPOXSsmHAhSIqzV8RISsnIZxYysF0TPrx2iLN95c7DPPX9BhZtzqFNk1h2HXJ3a+7xwHcAFJWWO10dq5PbT+/EM3M3Os8Ht29CSkI0Fw5Mp1OzRA4fL2bU//3kdV9JufL2ad4oxikIvrzpJF7+eStz/9pPq8axhIUJGjne1E/tlKY+O6fRMimGA/lFpMRHeY0b6zDmhnks4I1i7BeTCgsTDOvc1Hb/YKAFgUZTj9iefYzG8VH0e1h5vJiDnDzJPlpETGQ4y7cfom+6ior9bdshfly/n5M7pjHg0Xlub8ueQsBMKITAB1MHM3mmf3frq05qx0WD0omMCOOvPUcY3N49UDMt0RWfc2qnNF66pD9Squ/+w7oDXDY0g7tm/8mYHs3p2TqJGVP6IqX0+SbeyqGmadYoxvJ6QkwEvdsk87fhJ1Tkq9Y4WhBoNLWEwpKyKrsHDntqAa0bu+uUDx0r5tZZq7hzVGd6tk4i73gJ17y9nN+2HSIpNtLLW+bKN5ZzWpemliqT6mRw+xS2PzGOz1bupn1aPNe+vYK9eYW8fvkA+qYnO4O2DFWWpxAw+PKmkxj/3C/cOPwE5++3TZM45t1+KiVl5azfe4TrhrmCtKqijgkPE3x+44mVvr+m0NlHa4CEhISanoKmlrFgwwG63Pcts3/PoqjUOz2BwScrsliw4QBl5ZJnvt9A1uHjzmsHjqiI9azDrjf3o0Wl9Ht4Lj9tPMj4537hvs/WcMN7K/ht2yEAny6TPzqiYP1xerdmfq+3Mhk5z+rd0nncJD6K3+87nW2Pj2Xb42Pp2qIRAO9d45l4QHFO31b0ap3MS5f058JB6ZzaKc0tcjcQPVsnsf2JcQxs5x14FhkexoNn96BFUnAMsnUVvSPQaGoBxsJ7+4d/sHTrIZ48vxd78wo4XlzGl3/s4Yd1B5h17WD+/pFysXxqYm9m/LiZGT9uBpQK6NwXfvUa19DhG7y9ZEeF5/bHA6Po/eD3AHRt0Yh1e1VSx5cvzeTFBVto1TiWm99fCcC1p7ZnYv82HDpWTMemCby9ZAdTT2nPh8t38cUfe7h0SFtuGdGRJib9+je3nOz1zGtO9q7L3at1Mr1a67TtoUALgiAwbdo02rRpw403qjCI6dOnExERwfz58zl8+DAlJSU88sgjnH322TU8U00wOFZUSlREmGW+GYP9RwpZsjWH9CZxtGkS55Vt0sym/fm8tdi1QC/dpnzfPf3S5/6133l8x0fuPvc9HviOo0X+61/YpWliNAfyiwC4aFA6SbGRPDWxNwfyC7n+1A60u2sOjWLU0nG9Q6UyuH0TGsdFef1Obh7REYCJ/duwI+c4N4/oSFKsb8Pp8xf2IzJcMKp7c599NMGn/sURfDMN9v0Z3Ic27wljnvB5eeXKldx6660sXLgQgG7duvHdd9+RlJREo0aNyM7OZvDgwWzatAkhBAkJCRw9erRSU9FxBNXHwfwikmIjvaJbM6Z9zfDOabx+xUBn27tLdzC8c1Onz/clry7l503ZgFpYn7mgD7NXZjGsc1PG92rB3rxCDuYXkXW4gGmzV5Nf6L6I/+/i/lz3zoqgfZcV945k5DMLOWzS+995RmdLI++Q9iks3prDpMw2PHl+L6/rCzcepH1qPG2axAVtfprQo+MIQkzfvn05cOAAe/bs4eDBgzRu3JjmzZtz22238dNPPxEWFsbu3bvZv38/zZvrN53axtGiUuKjwt2MhOXlkgGPqpTAf9w/yumGWVKm3A7nbzjo7Dt/wwHu+VRFun5x04n0ap1MUYkrGdmB/CIufnUpALN/380fu3L95qkBAgqBT28YaqkKsuKuMV1ISYimV+tkFm48yGVD2nJm75Y0TYzm399tICk2kn+M7sw9n66hbUocz1/Uj//+uIm/j+psOZ7hSqmpP9Q/QeDnzT2UTJw4kY8//ph9+/YxadIk3n33XQ4ePMiKFSuIjIwkIyPDMv20pmY5mF/EgEfn8c/RXZxqDoBCk8H29g9XcenQDPbkFjCss/ciaETOApz13CLWPTSanYeOe/UzCCQErBjRpakzjfFH1w2hb3pjrh/WgXcW7yDfpBJ6/fIBXPHGMrd7jWJZJ52QysKNBxnTswUDMppw+FgxAPFR4Vw0qC3n9Gnl9MCpDencNdVH/RMENcSkSZO45ppryM7OZuHChXz44Yc0bdqUyMhI5s+fz44dFTfSaaqOlJJt2cdon2btqbXf4Wnz+ard7oLA9Ea/O7eAyxy5as7r28rZvvlAPsu3e0e8nvP8IvYdCZ7Qb58az4wpffls1W6+WLWHXq2TAPjn6C78c3QXSsvKGfnMQnKOFtM33WVMnZTZhlnLd1HuUP9efXI7+mc0pp8jZiA5LpJbRnTkzF4tAPxGFGvqN9p9NEh0796d/Px8WrVqRYsWLbjoootYvnw5PXv25K233qJLly41PcUGyeuLtnPa0wtZnWWd3fz3nWohX78vnxPunuPMgGl24cw+Wuw8nr3SlUl95DM/MW22tz1qw37r2hSBmNjflbLg538Mdx4/O7kv8dERXDSoLbOuHUJ0hHusQUR4GN/eegrL7h3pjGCdekp7p7tk2xSlyxdCOIWAcX7b6Z3o2CyxUvPV1B/0K0AQ+fNP16KQmprK4sWLLftV1lCs8U/O0SIiwsOcXimb9ufz2Sq1cO/JLXBzPcwrKOG7Nfu4/3NnVnRKy1VqY8+UwtlHiyo8l+Gd0zhWXOb01zfTKCaCIybjcFR4GO9cPYh+6cnOzJmtkmNplRzLHWd0oqdjB+APcyDa5kfHOHPdZKTGuS3+Go0VWhBo6g39H5lHVEQYGx9RGSFPN+WYKZcqqVpEmGDa7NUs2eq9QBtUNa88QPu0BErKyvlt2yEuGdyWe8/syvbs43RqloAQglccOW2WbjvE0BNSnG/vn1w/FCFUvplF006r1LPNaYs9s4NqNFZoQaCpVxSXllNSVs4Hy3a5td/ywUpKyirvKt2/bWNW2MiAedmQtqQkRHPVSe04WlTKtuxj3DqyI9ER4XRu7lLBXH1ye64+uT1rdufRLtVV47p/W/32rql+6o0g8Jcoqr5Q12I+gk1RaRlbDhyjW8tGfvvd++kaZi13FwRVEQKg3tSvfnMZ89YdYMrAdC4alE5pueTjFbtoEhfFjB83868JvTivXyvnG3l8dARvX2WdNsGgR6vAah+NJtTUC0EQExNDTk4OKSkp9VYYSCnJyckhJsY662F95P3fdrI3r5DbT+8EwKSXlrBqVy5/PDCK2Mhwrn9nBRcPbkv20SK2mHLkewoBX0wb04VXft5Gp2YJ/Lolx+1aSnwUOceKefjs7gzvolICXzIkg3nrDhAe5lrA+7RJprSsnJM7pTGgkkXUNZqapl4IgtatW5OVlcXBgwcDd67DxMTE0Lq1dzGMus5Hy3dxerdmbonEVuw4zF0Oj5zbT+9EXkEJq3Ypz58ZP2yiXWo8P6w/4PStt8slg9s68+1cd2oHrju1A8Wl5XS69xsAZ93bW0d25L7P1zKkQyqtGyuvm1M6pvLwOT3cEqiB0slrIaCpy9QLQRAZGUm7dt5JqjS1n6zDx7nz49UM7ZDC/03qw5GCEjo2S2TCi66o2W3Zx1i+3WXc9ReQ1aNVI9bsVknRosLDuGhwOq8v2g6oHcC1p7T3SrxmpJCICg9j9vVD+XVLDuN6tWBC/9bERbn+iwghuGRw2yp/Z42mtlEvBIGmbnC8uJQX5m/hptNceeG/W6sSqf26JYdBj/1ARJjgq5tPcrtv+FMLbD/j3asHM+fPvdw1+08SYiK484zOTkFwYodUhBBcNqQtcR7BU5/eMJS0xGgax0cxzhFgZRYCGk19RgeUaULO24u3s+XgUV6Yv4Xn5m92+srvOnTcq15tablk9H9+tjXuS5f0Z9vjY+luMh4nxUYy3qG6ufaU9s7SgQDx0er4wbN78M/R7gF+fdMbO1VAGk1DQ7/yaELCb9sO0axRNG8t3sGrv2wjOiKMCUbkrJTM/GkLj81ZX+nxnzivJ6O6NUMIQe82yazdc8SZXiEhOoKtj41FCKXO+enO4bz72w4yUuIDjKrRNEy0INBUGSklT3yznpd+2sq7Vw+ie8tGXPCSe1R1UWk5S7cqz5zn528JmIvn/P6tOa1LU25493e39g+mDubbNfuYPDDd2faPMzqTGh/lzH0PKiDLID0ljrvG6NTdGo0vtCDQVJiC4jJio8LZmXOc5kkx7Dx0jJd+2grAtNmrGdHFuoSh4eIZSAikN4njqYm9ndkxzQxun+JVmzY5LorbfaRM1mg0gdE2Ao1tNh/IZ/bvWXS9/1uembuRU/49n9cXbeOdJTudfXYdKuCNX7dXaNx7xnblhmEdePsqVeilzJE3uXF8FM9f2A+AmMgwvrip7hUF12jqAiHdEQghRgPPAuHAK1LKJzyupwNvAsmOPtOklHNCOSdN5Rn5jCt3z4wfNgGw6cDRgEnZ2qfFs9UU8OVJ91aNGNohlZ05Kod/abkrBfTYns2ZMaUvo7o1c0usptFogkfIdgRCiHDgeWAM0A2YIoTo5tHtXuBDKWVfYDLwQqjmo/HP2j15lDvexI8VlVJYUkZZueSfH69m/b4j3DZrleV927OPsWCDdyDfuJ4tnHlznp7Y2+dzT+/WjKEdUgFoFKveS9qajLpCCM7q3VILAY0mhIRyRzAQ2Cyl3AoghPgAOBsw+wtKwPD9SwL2hHA+Gg9yjhZx6FgxZVIybsYv3DyiI7ef3onuD3xHp2YJvHBRf2Yt38WiLdlkHS6wHGO5j0Rsz13Yl00HjrJ02yH6pjfm9/tOZ1u22hVMePFXUhOiuXxoW646qb3znuS4KGZe0p9MHaWr0VQroRQErQBz0pcswDMD13TgeyHE34B4YKTVQEKIqcBUgPT0dKsumkow8X+L2Zp9jHccidFm/LCJ9XtVVO7G/Uc55DDW+hICZmIjwykoKePZyX3okKZSLXdqlkgnR9GTJvFRNImPorBEFXy5/fROXDjI+285qruu6azRVDc17TU0BXhDSvm0EGII8LYQooeUstzcSUo5E5gJkJmZ2bBTcFaS/MISek7/noToCP54YBThYYKtjjf0nze7VDvf/7XfeezpAuqPSQPaMP2swHVuYyLD2f7EuArMXKPRhJpQeg3tBtqYzls72sxcBXwIIKVcDMQAqSGcU4Plmz/3AXC0qJQOd88hY9rXzmsvLdxqa4yuLRqRGBPhdv7khJ4AZGboPPoaTV0llDuCZUBHIUQ7lACYDFzo0WcnMAJ4QwjRFSUI6ncK0WqmvFwSFibYnRtYvROIz24cipRwML+IfUcK6ZCWQJP4KDIzmtDBR3F4jUZT+wnZjkBKWQrcBHwHrEN5B60VQjwkhDjL0e3vwDVCiD+A94HLZUOvvhIkvlq9hwUbDtD+7jn8tPEgzzrcPX3RqZn7Qv6vCb1Yfq/LZDMgozHREeHERIbTpkkcAzKa0CRepY3WQkCjqduIurbuZmZmyuXLl9f0NGqc7dnH+Pd3G3j6gt4s2HCAlsmx/O39lTx6Tk+iI8OY+D/7+n2AKQPTef83FRgWHxXO2odGA8qzSAjhXPQ1Gk3dRAixQkqZaXWtpo3Fmkry2Jx1fP/Xfsb3bsF177jy8Vz86lLbY4QJ6NQskfX78pk0oA1ndG/G5a8vc/PjT0mIDuq8NRpN7UMLgjpKo9hIADchUFEyM5rQMimG9fvyiYkMY1jnpsyY0pfB7bQfv0bTkNCCoI7SOC6ywvfMmjqYb9bso7CkjA+W7eKM7s2ZPKANo7o3p0tzFdfnWYZRo9HUf7QgqINIKXn5Z9/lGl+4qJ9X+maAQe1TGOTI3DltTBeSYiMRQjC2Z4uQzVWj0dR+tCCoY7yzZIfPJG/PXdiX0d2bExEexutXDOA/8zbxh6Pg+03DT3Dray4Ur9FoGjZaENRS1u87QudmiQihCqy89ss2yqXkka/X+bynQ1oCEeHKI3h456YM79yU33cepmVSLM2TYqpl3hqNpu6hBUEt5JdN2Vz86lKenNCTUzqlsX5vPg951Pb15Jw+LenaopFXe790HfGr0Wj8owVBLWJHzjHm/rWfNbvzAHhv6U7++cmftu7Vhdc1Gk1l0YKgFvHwV+uYt86V9O2PrDzLfpcNact7v+2kpMwVDFhSXm7ZV6PRaAKhS1XWMG/+up1N+/M5dKyY1Vm5tu558OwebHp0LKkJyuDbo1Ujrjbl9ddoNJqKoHcENUje8RIe+GItrZJjSU2I4kC+tTfQ4rtOQ0oY+sSPbu2XDcng6bkb+fDaIcRF6T+lRqOpHHr1qGaOF5c6F+2NB/Kd7VZqoMZxkSyadhpxURHkFZR4Xb/ptBO4YfgJhIeJ0E1Yo9HUe7RqqBpZujWHbvd/x6+bs8k+WsT6fUoQtEqOJSrC+0/x+32nO4VGQrT6nHqKSwUkhNBCQKPRVBm9I6hGjPq+7/22k69W73W2r9h5mLJy71hDBdoAACAASURBVCywRgwBQHiYYPOjY/TCr9Fogo7eEVQj0Y63frMQANyEwHn9Wvm8PyI8zE04aDQaTTDQO4JqJDoy3KstMlxQUiaZ0K81953ZlUYxkTRvFEOqTv+s0WiqCS0IqoEDRwp58Mu/SEv0XtynjenKgg0HePTcHsQ4BMU/Rnep7ilqNJoGjBYE1cA/P1nN/A3WpZivOqkdV53UrppnpNFoNC60IAghP208yLGiUp9C4Me/n1rNM9JoNBpvtCAIMit2HGLptkO0S4nneouaAAA/3TmcMilplxpveV2j0WiqEy0IgkRxaTnlUjLhRf9F41slx5KeohPEaTSa2oMWBEHizP/+zMb9RwP2u+/MbtUwG41Go7GPFgRBwo4Q2PzoGGfhGI1Go6kt6FWpmrh8aIYWAhqNplaidwTVwMI7h9FGF47RaDS1lJC+ogohRgshNgghNgshpllc/z8hxCrHz0YhhL2E/DVMfmEJO3KOAbBmdx4HHemj+7dtzLe3nuzVPyk2kjCdI0ij0dRSQrYjEEKEA88DpwNZwDIhxBdSSmfxXSnlbab+fwP6hmo+weSc5xex5eAxvr75JM787y/O9nE9W9CleSOemtib3q2TOP3/fgIgNso7tYRGo9HUFkK5IxgIbJZSbpVSFgMfAGf76T8FeD+E8wkKhSVlbDmodgPjZvzidu1KR4Tw+f1b07FZIhcOSgcgStsGNBpNLSaUK1QrYJfpPMvR5oUQoi3QDvjRx/WpQojlQojlBw9aR+lWF3fPti4m36V5olfbI2f3YP3Do3XGUI1GU6upLcbiycDHUsoyq4tSypnATIDMzEzvxP3VwFuLt/PkN+s5Vuw+xdSEKD6YOoQ0i2yhYWGCmDCtFtJoNLWbUAqC3UAb03lrR5sVk4EbQziXKnP/52st26MjwjmhaUI1z0aj0WiCRyhVQ8uAjkKIdkKIKNRi/4VnJyFEF6Ax4D83Qw2QV1DCgSOFltfuGqNTRWs0mvpByASBlLIUuAn4DlgHfCilXCuEeEgIcZap62TgAylljah8/DHq/xYy8LEfOJDvLQxO7ZwGYFliUqPRaOoSIbURSCnnAHM82u73OJ8eyjlUhf1HVHzAwEd/8LrWKCYSgLLaJ780Go2mQtjaEQghZgshxgkhGrwfZGS44PbTO9E0MZp+6ck8NbF3TU9Jo9FoqoTdHcELwBXADCHER8DrUsoNoZtWzbNoc7Zl+0Nn92DKQBUfMPuGE6tzShqNRhMSbL3hSynnSSkvAvoB24F5QohfhRBXCCEiQznBmuDXzdlc9MpSANKbuOcIahIfVRNT0mg0mpBhW9UjhEgBLgeuBlYCz6IEw9yQzKwG2Z1b4Dwe2bWZ8/iKEzMY1a2Z1S0ajUZTZ7GlGhJCfAp0Bt4Gxksp9zouzRJCLA/V5GoKs/23b3oyLFLH1w/roKOENRpNvcOujWCGlHK+1QUpZWYQ51PjfLR8F/d9vsZ53sakGkqJ944e1mg0mrqOXUHQTQixUkqZCyCEaAxMkVK+ELqpVS+FJWU8/NVfvLt0p7PthYv60adNMk9O6EnL5FjCdSppjUZTD7FrI7jGEAIAUsrDwDWhmVLN8OnK3W5CAGBszxYATBqQzskd04L/0OlJ8MXNwR+3Kvz2sprX+q/V54F1NT0jjUYTYuwKgnBhUo47ag3UK/eZ6Aj3X8WQ9imhfWCpClbj9zdD+5yKsvQl9bnYsdnb/ovvvhqNpl5gVxB8izIMjxBCjEDVDfg2dNOqXvYfKeSr1Xvd2l67fEDwHlBWCh9fBftMKaxzd/nub5fFL8Csi2Htp/DDw6pt4/fw/X1K0My6BLI3V+0ZOnJao6n32LUR/BO4FrjecT4XeCUkM6oBrnh9GX/tPeLWFtSqYtkbYc3HsH8N3KjiEyh0aNoi4ys/7nd3qc91X6rPEffBexPVcYfTYN0X6jmXfWl/TOfGTwsAjaahYEsQSCnLgRcdP/UOc9xA79ZJRAa7olipI2ldhMnrqLzUcRDEBXfVe67jPb+rz+LjsPx16HcZhNn4XkYWkR0On9nio8Gbn0ajqZXYjSPoCDwOdANijHYpZfsQzataySsocR6/evkAUi2KzFSJsmL1GRHjajMEQTBVL59d7zr+4SH1uXu5+olPg65n2hjEwzOqKD9o09NoNLUTu6++r6N2A6XAcOAt4J1QTao68Uwx7Wk0DgrGjiDcZF8vcwgfWV65McsreJ918TdvPAPmykus+2k0mnqD3VUvVkr5AyCklDscqaPHhW5a1ccfu/LczmMiQ1BastRqR2AszJXcERTmBu5jJtq7prI1HoKgTAsCjaa+Y9dYXORIQb1JCHETquRkna/PWFJWzjVvuWfICLp9AKDkuPq0shFUVjWUu6Ni/cNtevt6Zho31FoajabeYnfVuwWIA24G+gMXA5eFalLVhZFhtMLMfwz+fULgfoe2qqCsbT+pc0tBYFPFU16mxvrtZXU+c5jt6QLwxjgoOAxf3gIvnggzh8Psqa7rC/8FT7T12hCw/DU4fgi2/ayeP/d+eLCJbwE270F4qnPF5qbRaGqUgILAETw2SUp5VEqZJaW8Qko5QUq5pBrmF1J+23YIgEmZbSp248In4djBwP02ORKzLn9Vfcaluq45de82dwQlDs+m7+8zqZUqyP6/YMUbyo11z++wepbr2vxHfaub9q+FJY4As0XPKnuDrzn88gwc3Ve5+Wk0mhohoCCQUpYBJ1XDXKqN8nLJPZ+6grvapsbRLjWeB8Z383/j4R3w7V2u850BdhSei2V4pPc1OzuCoqMuj6DSAnj5tMD3WPHrDO+2L2+F4mOu88I87z6Ln4cNc9zbyoph1fuw+sPAzz20DZ5Ih7WfqfM/P1Y/Go2mVmDXRrBSCPEF8BHgXDWklLNDMqsQs27fEbe8QnGR4cy/Y1jgGz+5GrJ+c52/NgqmWyycBp6eOs7YAY/jQKz+QAWHGexdpT6T2kCeR4Ry25Ngh4+0EBstgsFXvA5pXVznCc0gdyc0ag1Hshz3feN9X3kJfHadOu51gf/5z56qBMxHl0H3PPjkKtXe83z/92k0mmrBro0gBsgBTgPGO37sOKXXSqI8DMKN7VYdq6grpefbftYyOLxdHa//ytW+7ivI2w0r3nT30tn2M2xdCEfc0184OfUf3m1XfF2xOQJsNWUYz1oGLfvC7Wv931NqMiJvmgsFuSpwzeDAOlfCutICNBpN7cVuZPEVoZ5IdVJa7q6XP6t3S3s3VtTDx1M1tHsFPNsbrlvkSgsBMOsiaNZD6e6btIN2p6iF9s0AsrasRAWKtewLm76HkdNVe2JLyN9jf557/3A/37My8D1mO8C756tnz5vuanthsPr0t2PSaDS1AruRxa9jYdWUUl4Z9BlVA8Wlrjf1f4zuHJyqY1IqY2thnlqIy0t86/8LDnm37XcUwyk6qgTIgQBv5KAEwZ0WSeUu/hheHAqNWsGln8NzAWoHHc9xPw+3EVl9YL3HGBbfycDItApQeMR3P7sUHIbYxlUfR6PRAPZtBCY9BjHAuUAFXjlrF8VlrgX6hmE23EANPAWGMAWf/TpDuVaaGX6v9Tj+grRKC1SNglU2ArcbZ1i3GzEDUnrHBVjOxyNWoMvYwPfMvtr93Gxw9sL0e3uigh5anmStgFdOgwvegm5nV20sjUYD2FcNfWI+F0K8D9TZRPXGjuCtKwdWbaBOo13H6y10877SOvgzFJcU2BMCkfHQebT1Nad3koQw05+463h3lZTneCXHYMoH0H5Y4Od74jc5nWMzGZUIxVXMXbRvtfrcNFcLAo0mSFQ2jLYj0DRQJyHEaCHEBiHEZiHENB99LhBC/CWEWCuEeM+qT7AxBEFijN0NkQ/KTCoPqzdvX772S/xU+CyxaVjtOcH3tTCTm6pZELS2qLFgtJUcU8edx0BkrL05mLFyOwW1KznsiIKuqhAoPg5f3aqOdeoLjSZo2BIEQoh8IcQR4wf4ElWjwN894cDzwBhU1tIpQohuHn06AncBJ0opuwO3VuI7VJj1+9SCFFXVBHOlAQSBrx3B1gW+xzTSUXgS5iG0znjM9xiGCkt67Ai8woaB5r1cOZDMAgTgyu99PwMgJtl17GlnMCgtcheYVcFsoNbJ8DSaoGFrJZRSJkopG5l+OnmqiywYCGyWUm6VUhYDHwCee/lrgOcdNZCRUh6o6BeoKEWlZTz5rTJ0VjnTqFm3biUINgVYSK3wtDMYxDYxPSs8QBI5U3EZsyCwEkxhEZDpsPmHewib9EHQ71LrR4RFwjmm8hS+BIE/oWek3lg/B7b86LufgXkXoHMgaTRBw+6O4FwhRJLpPFkIcU6A21oB5minLEebmU5AJyHEIiHEEiGEpdJbCDFVCLFcCLH84EEbqR38kHvctZhER1Qw06jZfbRxRmBBcMzH4lgZRBh0PEMde+4OPIlPgzaD1EIdZvqOVqqqsHCX0bnAIsWE2SBuNk6HR0KGKeD8WLb1XN6f5Hueb45Xnx9MgbfP9d3PwPz7rmyaDY1G44XdV+IHpJROJbCUMhd4IAjPj0DZG4YBU4CXhRDJnp2klDOllJlSysy0tLQqPfDwcddiUiHV0IF17m6fzXq4B1VZCQJfevPKEBEFp92jjqPi/PcNj4CrvocTRrgLAsOdtXkvV5sIcy3weVneYxn3j/kX3GKKNwiPhJhGcMmn6rwogFtolI9ktWXmaGuLxf3wdlXfefsvsMsU1Y1QHkR2bSoajcYndq2lVitmoHt3A2ZfwdaONjNZwFIpZQmwTQixESUYltmcV4Ux7wiS4yL99PTACJAyiIp3r95lJQhK/LlUAqmdIXuDveeHR7v8+ytS59i8ezAW2nCP7924nfq0im8wnlnqXsCH7uepzwibhuWoBGvPIqMkJsCi/8DJf3e//mxv6/Hydik30p4XwISX7c1Bo9FYYveVeLkQ4hkhRAfHzzPAigD3LAM6CiHaCSGigMnAFx59PkPtBhBCpKJURVttz74S5Jp2BBVWDRlExqs8P0d2u/TWYRUcq1EruH4RXGNDNw7u9QQq4tXjZiMo924DSE73fX9ic/WZ7zDU3pcNd2yCcc845hJjfZ+nYIz22BE066E+zTuJfWvcd1n+OOowJ5lzP5mpaAU3jaYBY1cQ/A0oBmahjL6FwI3+bpBSlgI3Ad8B64APpZRrhRAPCSHOcnT7DsgRQvwFzAfulFIGUbHuzcGjaqGZNqZLgJ4mPF0VTxihUkHIMpc6xU7glpnCI+rN3O7bfXikq55Bq/72n2Ms+i36QLJjg+YZiGYs5pEWKqfmPdWnYawOj4SEphDm+L4RPgSBp6uqp2rImIPZ82rtbHhlhPV4ZqKTXB5EVgv+6o/gocZKpaTRaAJiN6DsGGAZBxDgvjnAHI+2+03HErjd8VMt5BxVC8/VJ7Wzf5Nn1Ox5M1UyOFCpFZq0czeq2hrToVbyVNP4IixCPeeyL63jAXwhBFw1F1I7KnfPRi3VXI1aBIYB/LpF1mkbOgxXdoC2PjKRmwVBz4nQe7I6ztsNu0xpuhu3dWVNBZfXk6eO3wgY80dsEhQ57C9WnlB/OdJdZy1zCT+NRuMTu15Dc81GXCFEYyHEd6GbVujIPlpE47hIIipSktLs29/uFKWaiXX8OgoPq8+K5isyFlDjvuS2/vsbOw7j+RWhzUC1yAsBJ4y0Fj7Ne0CSp1OXgw6nKWO1FWZB0Kq/Gv+Ekd47hTSPHZixQ/C0PUDg5H7m+AUrA7OR2dVO8SCNRmNbNZTq8BQCwOH3HzCyuDaSc7SY1AQbSdXMmHcExgJnLEaGy6VZNdRrsuu4RR/ociZc+5PHoKagLwgsSCqqevJH+lDTQl3JmskGZhuB2Y7hKWzaDoW+l0ALh/E32o8gMASvLxfRKJM6zXNHYLYx6FgDjcYWdleXciGE06IohMigyitIzZB9tIiUBJv1BwB2LoHNP7jOjQXU2BFsmqtSH5gLx5xyh+t48A0w+V3XAmjgtfBXoyAIC4PT7gvOWGavIXNNZk/jeXQjOPs5UyyEQ1CUWAiCPz9SxWzMGU2btDeNbdJoHjuo/ka/vawEx8InXNeWznT37NJoNJbYdR+9B/hFCLEQtWKdDEz1f0vtJOdoMV1bNrJ/w2tnuJ8bahmj/vChLfDjw9Z9PI9HPwFzH1ApF4yFvVFLpSY5/UHYs0rV/LUimIIgmJgXf3P6as/5GgLUSA0REaVsFVY7gi9vcYxhEibJbeGQw6Fs6N9g+8+ua8bfaM9KWPWuqz1vJ3w7Dc5+3v730WgaIHZTTHwLZAIbgPeBvwN1MpLn4NEi0uyoho7ssQ4IMxa+8AiVfTRrmXvm0agEd+8b8/Hg6+F2R9UuYwcQGQt371aZNEc+AKmdXP37XKTqCUDFbRCBCNZ45nHc7Age4xvqnPz96jOhmVIfHfjL99jG7/Xcme4Cp0Vva4P5Rguz1VFtJ9BoAmHXWHw18ANKANwBvA1MD920QkNRaRn5haWk2ClN+UxXeGGod/sek+eLYR/I3eFqy7zCXYftadg1rvmq19vFVJWs3SkmG0KIdgQVrbrmD7ONwHO+xvdu41jAW/VX6bg3zMEnhmdQVJwyQBtExKgsqZ4ct0hz4as4kEajcWJXNXQLMABYIqUcLoToAvhJf1k7yXHEEKQm2jQWH7FIuZDrKnpvGTk88iGlg4+IUWoPT0EQGQN3bPZdYeu0+9TOQZarYC7DPhF0QWBKTFdVjEL3dgRB/yug81j13XpMcLmx+iMqHgZcDV3GKXVRbDKcdLsyyr8/Cfb96efmOmnK0miqFburS6GUshBACBEtpVwPdA7dtEJDtiOGwNaOwBepHV3HVsFMRqBVvMOpyipIKyHNO9On+f6Epq6I3lDvCIKBERxmNhDHeqSMMrvLGt/N/Lv0R2S8uq9RS0hs5honqRWkD/F/7+Z5vjO6ajQawL4gyHLEEXwGzBVCfA7sCHBPrSPrsDJrtEyuROEVgKE3wySTMdJXvQFw6c59+d/bxXhGsG0EwcTY9ZijhNMHw4RXXedW84/xyi9oTZSf6GurdNynP+R+vuhZe8/RaBoodo3F50opc6WU04H7gFeBQGmoax3bspUqp12qx8Ky6j3444PAA4x62PVGCv5TIQdKFW2XUO0IgilYjIXaM0rYlx3EwG4Ben/ZVj2L6QB0Pcu7rbo4lg2f3RCghrNGU7uo8GolpVwYiolUB/vyCkmOiyQ+2uNrf3a9+uw92fsmf/jbEUx+D5a9DMkZFRvTkw6nQd+LYdhdVRvHF8EwFo95UqnAOlmUk5gyCw6u824Hb/WRmVGPwPf3quO4lIrNJ6KCAYPB5MdHlAtr+mDfRX00mlpGLVY8B5/Dx4tpHGdDVWN3cfS3I2jaBcY97bIZVJaIKOUHn9S6auN4EcQdQWJzOPdF60yknUfDSbdZ3xfjZ0fQw7SbiEny3c+K8AoIgk1zlYtp7k747h5Y7KeetB2cxv1KZrbVaGqAIOkv6gZ5BSUkxdpI8lZe6t1mjmw1OPnv8OXNVZ9YjVKDXjX+dgQxjVTNgwM+dhP+sGuXKSuBd8+Hpt0gZ4urtnKr/qpMZ2XIc3iVhVfRNqTRVCMNShDkHi8h1U56CStBMPk977b+lykX0W/+UfXJNUT8GYuj4mHi65Ub12pHUJTvblg+tM0V1ewZ1HYkC4p7Bq4E54+yYlWqNL6Cai2NpgZoUKqh/MISEmJs7Ag86w+A7ze8lBOqNqmawnDdNJetrG4MlU8ni+AwuzTr7t1mlV31cZNqLX8fzOjjXXXO4OMr4flK7AjMXlOf3wj/bm+dS0mjqWU0KEFQUiaJspN+2mpH4KsC2Qkj4PpfqzaxmuCEEXDDEmWIrinCI+Bvv8P5r7na7tisKqDZpdtZcL5p53DzKnePKCtBXXA48Lh5OwP38cQtwZ1D5aa9hzR1gAYlCIrLyomK8DCSbjMlL5ueBL/8p2I7ArB+K60LNO1a8/EJKR3cVTAJaSqgriK0O8V13MSj4FDLvq7jZ7orR4CPLrc37uPpqgLdgXXweBv3qHJQ5TKnJ6kfgDfO9B4jUN1qjaYW0KAEQUlZOZGeO4KFT7qfz3vAlSHT4KznVFSrJnRMmQXX/VK5e/3FbCSY4j6OZCkhf3C9vXGL8mDNJ7D4OVVbedNc9+tb5ruOi49Zu8kWH/du02hqGQ1KEJSWSW9BYKUG8twR9LskdJPSKDqPdtVHrij+yn161mcuK7Ls5pO598OuZeq4tAgW/kvtKhbNcC+reXi79f16R6CpAzQor6Fiqx2BlRrILBxOudPe4Gc8plQFmuonMk4ZnM1qoOH3qGjs9sPc+5ZWompZ9gb1+Z0jqK/bOTDXo7CPuSxmcrpLjaRtBJo6QIMRBFJKSsrKiQo36cT3rVE6YE/MwuG0e+09YMiNVZugpvIIARd6pAg51eTSO36GK95jUxBKbVulu97yo+s4ySwItGrILzuXQrNu1jmjNNVGg1ENlZVLpMS9aP3/ToSj+yw661q39QqzDcFIJ1IVjud4t5kT2yW3cR1r1ZBvCvPgtVH2jfeakNFgBEFJmXLn81INWVF0RH1e8mkIZ6SpNny5/lYWK0FgJskkCMosbFAahbHz3r2iZuehaTiCoLhM1Q6IDLfhLvnmePUZlRDCGWmqjWBlgjUwym36wuxhpneXvjF+N1Z1PTTVSoMRBKUOQRAV4fjKdhLL+cuDr6k72N0R9J5ir9+hLb6vnXire3ptLQh8Y/xu/GXx1VQLIRUEQojRQogNQojNQohpFtcvF0IcFEKscvxcHaq5eKmGSm24EVpVF9PUPezuCDqOstfv4Abf19oOdU+m9/Xt8OfH9satjyz5H3x5q3tbQS78+wR4trc695fFV1MthEwQCCHCgeeBMUA3YIoQoptF11lSyj6On1dCNZ8Sp2rIEAQ2csBo1VD9wK4gMP+9r/week607mflaeYcI977380nV9l7fn3k23/CCo/kgRu/c3e31TuCGieUO4KBwGYp5VYpZTHwAXB2CJ/nFy8bgS1BoHcE9QK7tQHMf+/0QTDBx3uJlfuoQWScqz5zTSElLJ2p4lp2LoXXx7rqJHiy7Wd1bd8aWBtk5whzCvFlprKlWzzmUl4Ga2arOVSFgxth9YeVv3/HYtg0r2pzqKOEMo6gFbDLdJ4FWKV0nCCEOAXYCNwmpdzl2UEIMRWYCpCenl6pyZSXK9VQmKiAINCqofqBlY0gOV1VPjthJPz0b9UWFQ/9r6jaG2pUgnIfTWoDeV7/lKuHQ1vhmztVeoyj++HwNtixCKbnefd90yM/UvdzgzcPc3bXr29XJUQT0mD1LPd+sgw+vkIdW83RLs8PUJ+9Lqjc/a+Prvoc6ig1bSz+EsiQUvYC5gJvWnWSUs6UUmZKKTPT0tIq9aAyh3E4PMwhCA5t9X/D6Q/XfEI2TXCwUg3d+idMXQCnmkxXkfEw/j9w1n8r/6yoOIiMhds83m73/6Xe1Pf+Ufmx7WLUt87LgiN7KnZvsDx4LN/uZfV4CBXkVu3+BpghIJSCYDdgcqimtaPNiZQyR0ppWG1fAfqHajJlnjuCtwO8+VQ0A6am9uLPRhBuuhYMLzFfEbIvDoGfnoKXToHNIVY/GClSSo5XvFKaEUNTFfL3qWBNT8pKrAM4g80rIyp+j7luxFMdgzeXOkIoBcEyoKMQop0QIgqYDHxh7iCEaGE6PQuoRF1CexjeomGeL/kXfgj3HnB3HWx7IvSaFKqpaKobQxAEKiJkZRO6ey/c9pd7qmuDW1bDXSbD8T+2+a+vvHOx+szZot6MQ+UtY3jElRS4CzqrvFqe2KnVEPD5PtSuZcWqMpw/3Go6eN5fYs/tO2dz4D6eeKYYb2CETBBIKUuBm4DvUAv8h1LKtUKIh4QQZzm63SyEWCuE+AO4Gbg8VPMxdgThnpIgqQ1ERLv7fjfvpdVC9QlDEBhG3MQW1v0iLXYEUXGQ1AoiYj36xkHjtu47gLgm/udhdll+Yyz81+YG+JHm8Mk17m1/fuyqheApUN4Y53hegfvC/nCqu2rq4yu9n1WY65rr9CRY8qL79bkPuOoveLJvjbq2w0ehprIS31laDXwtyCUF8ERb+PRa+OwGeCKArTDHT6yHwV9fqPke2QO/znC/Nv/xwPfXI0KadE5KOQeY49F2v+n4LuCuUM7BwLARhIUJ97B/w+dbmGSiToBVvwgz/W0v/QLSurhfv2qeUln4K3rvWaPC7Ehw80o4buNNuvio+pTStTuwQ2kB/PkhTHjZ1bbybdP1Qne1VqEfHXn2Jmjh8N9f84nFHB25kXIdhu4lL8BgU36mRf9Rn2Ul3um/N8/1PS6o32EgQeCrtGfBYZW3yWxoLi93/9ua2fANDL3J/7MMt9b9a1XeIzP+ggbrIQ0q+yg4tkCfTnVdMAqom3cAWhDUMxx/WyGg/anel9sMCDyEZ2yA2ROpSXsIsBkAYO8q9fntP11tc+6E3pOhlcfuYPZUb++awjz4/S1o1Mp9V1NSaN++UXBYvV1/8Tfr62+MU9496xxa3Eat1C6gvBTOeNTVb+lLShAMula5fh7ZDdJhCPZlA/n+vsB5hazqg4C1uil/r9qtWT7rHvVZdASG362Ov71L7f47j1O/W2O+QngLzwYWEV7TXkPVhiOMgMiyAtcbS2IL5eEBekdQrzH0ylVQ9432UBUIG/91Rj7oUEv5ee5vM+H1cd7tnkIAYPnr8P29ytXSvPDbcYU2KMyF9V/Dnx/57rPOZMpLbKF2AYufczQ4vsv398A3jlTfH1+h5hVIf7/lB/X88ChrNRx477wMzDuFMMdOJNDu4vt73CsQLnkBfvk/eH8yLHvZ5R0kwr09jezYU+oRDUgQqH+kEdL0D2rUI66dgDnoSAuC+oWxQFXF7pPU2v3cTrTySbfC/Tlw0zL//WS5Knu57ksV1OTLxVKalcQS6wAAE9NJREFU2s0BYhvmePf1RUGuvfQqBubgr7IS72C5n59xHe/+3d6YLfrAPT7cWq12BDlbYOM3rnPDFnM4gOHZzPqvXcdGQKDhQi6EtSA4fsi3mque0WAEgaEaijCXKow0GQD1jqAeE4QdAUAHk1uinR2BQWJz/9dlGbx9Dsy6WAU1lfgoZmMOdDMvgnPusD+XwtyKles0684L85RqxcwPD7qON3yNLQzbQv/Lva9ZCYIXhsAPD7nOjzqyv+bbdEUtL4cPLvRuN3ZS5aUq5UVyW3We1kWpht6dqAzqxwKkHa8HNBhBYBiLI8tN/wnM/6i1IKi/OOVAFQXBJbNhgiNVQkUEQaB/T56Ln68Fbs+qwM/KDRDNXJDrrvboMSHwmAZZy/0bou1i7KbGP6uieKfnwTXzVdvulS5njrJSFYjnS3AVH1MpwYuOqrd3X7u0vSv9z2f3SmWQH/o3NZf4NOXmunu5Yx427QUH1qu5BJPjh5RL7d7VlSuzapMGYyx2uo+WmVRDET52BPE6mKxekeCIRm8/rOpjGQFawS52Y+Y5H26l67/yfY+UsO0neOss333AIQhMC0pF0qi8H6TYGk9vI3At4vMfgfgUyLwS5j1gsk1Y8Msz6ie2CRQc8t3v5dP8z2f+I+oztZP63P6z+3U7NpjcXfDCIOg8Fqa8H7i/Xf7VznV80m0wcnrwxjbRYHYEhpo4oqzA1WjWdxpvix1HQWqAwCNN3SI5HW5eBafdF7hvIAxBYDeRXXVRXgb7VrvOu45X8TCeFHrYCMxqq2STb77d2gyVIcyPIABX4Z+N39obz58QMNNpjO9rGSdbBw2CPZuKsVPaGISa2AaetqJtPwVvbA8ajCBwGovLTdI90iwIHL8Kq/88mrpPk3bBeYs33mZDuSOoDA+nuGcPbdoNmnb17rd/Dfz4sOs83pS7y1xi01xlDdwDLquK1e/OvEsoyoftiyoXIeyPZt19X+t+rm/VYVmRWuCnJ/nOYxTMIju//EcFG+bvdW/fvQJWWKZjqzINRxBIK9WQxY5A6rJ5Gj8YW8tYO4EDFlz4EZz3MqQPDd6cDMw++n0utOfZlHkVXPYlTF3o7v5pdtc8/zW4yEdxnTaDrds9OfkO/yk+zMKhMFe5egYbf+nB/WVdLS2Chf9Sx76KEgXT3XTeA0oIWtW9CNELSIMRBC6vIZNqyGykM3YEWhBo/GF4rPgKZApE60yVJrn7Oe7tJ//d/TyhGTTr4d7mS3VhReMMe7rt8Ag1bss+7u3lHgbl1plwkYUr5ejH7M1nxH0uLyGreAOz0Fr1bmhSvJg1AN3Pcx1HxPpPD2Ln9+jPoLzmE5XOoqJ8/XfvthDVumgwgsAIKAs3PBDaDIImHVwd+l8BHU6DwTdU/+Q0dYeuZyqD4IgHKne/4anm+Qbp6aDg6aYZGedaLE/+O3TxqCNgZvJ7jgOPxTTjZP9zG/8f13FZCYx7WgXFGVilc/ClSjU7X1zsECDhju9k9bLluXvx9L6JqqAn34gHoLeHy2hEDIyfob5T4wxX++V+jPCgvHWEKTrdCn87go+vhA8vCThlJ816qs/9f3pf04KgarhUQ44dwZQP3DMzxjWBSz6FxGY1MDtNnSEmSXmFVHZHYCyGnm+QCR51NjwNquOedi2WjdvB5Hetx49LhS7jXHM1MyRA7p20zq7jshIYcLUKinO2ebi5djlT6fYNI+wk05xGTlefvSar4j/gyuVkpUf3/L5b57uO04fC3VkV8+Y7+XZvD5uIGOh/mfpOhiBI7aR2O/6wsyPYNNd1XF6u8hd51jwpK4ENHgbwrQuh0JH6e/si2PKjtQAwf4cQ0GAEgTPXkGEjqOlygpqGxYmOBdV4+Wg/zP16vIcgKC10V6GERbrepP3lFTKrOIxKXX0uUp+pFcizb6XqMIzPRuyBoSYznmNWL3Uc5d4XAuwI/Oi++13qOLCRgjraJPw8a4pEm/JFGR5SxyzKjva7zP08kCDI3QVLTVla//wIXhwKM/q69/vxYeWCu32ROs/fp9x9P71O2WTeGBu4TkqkFgRVwhlHUOrYEWhBoKlOTn/QvQRiq37u1z2DzoxF1iA8wpUbJ9lPCmazSil9sHrmOS+ozwQbu10jYM5KECS3UeMYgsVYIHucp9rNaTiadlVtnUaZvoPjrd+OashMH4crq51aBHftdP2ehVDHKQ4BaEQOg8sLyso19KwZrntAvdmXmKKQS0x2xoLD3t495tTfxaYo8Z1L1WfJcRUoZuwY9q7yzn7qixCtWw0uoCysrFAZh3ylr9VoqouYJNcC4Kn28Iw2DouE5j1VrIA/QWDlo29gBI+FR/uO1jVUJk27+R7HyMRqFekalwLHfaRkMFK6WOnT7Xg4BXLkaNHHur1Vf8jZ5P57M9LPlxZY35OzyXU835R1ddbF6vtNz1OR3jMtstmas8s+ZsoSu2uJ4/M3ePd8V/uR3aqCnR0qEtFeARqMIHBWKCsrdM8xpNHUFDetUAnQSouUzaFxhntGTbNhMqYRjH0KBl3nrfK4ai4c3gGzr/ZfmjIsDK7+AaIbuQq9e9I6E67+0duLyIxRyc1KmNz4m++320YOu4pVCg2raGNP/AmCSe8oQWnFmf8HQ26A+FRXm5F+vqJegmYhd+Cvit1rsHmud5sv4QnK+P/JNaoeQ4hoMILAWZimtEALAk3tICHN3Ujcsp+7IDAWK+M4Kg5aWHjptBnoqlJmXuysCGQYBWgdoHKaYaOw2hHEp/qeg9lTxxNjR2DeJYF73YW4Jr5zHXUd73vsqDhXMR6D6Ebq07PynF22/QyfXR+4nxV7AuQ+AhXcl+fIG9VlnPq7bVtoT2BWgoYjCJyqoZKKF/TWaKqDsU9B8x6q0E1iC7VwPu3w5IlN9u5/4YcudU+bQTDifuh3ub1nTXzTO7W2XYxaAhXJYgrqO4x9SrlpeyKEenNvdyr812Q/udLkZXPJZ/BskCL/w8KUK2mbQZW7/4sAHlhVoWk35eL63kSXgDzvZVj9gXdsSZBoMILA8BoSssyePlKjqW7iU7wDy8IiVXBXjIUg6HSGqV+Y973+8AxoqwjGjroy2TAHXuP7WqZFDWXzLqJxWxh+rytJXFXpf1ngPr4IVBTHk6bdlCopOV3VZW6V6cpu6snwe1w5oIyX1sRmcOItlZ5uIBqMxdTYEQhZWvvyxGg0vpj4OrQeWLtSo0clQMu+cO7/Qvuc9sMtGj08h+Kbwph/B//ZVrUSrIht4ppn2xPdg1TNnHiLCr4benPgMcOjXOq3EKmCPGkwr8ZlRpGqcr0j0NQhuo73r/+uCcLCYOqC0D9n0jvebZ4upBd/Ym03qSon3wEr3gjc758eVdLy97nUeWZSOsJ1P9vLIBoe6dp1VZMau8HsCNxVQ3pHoNHUeuz4zIcqHshf7iF/WKnwwKXqsTPf8CiXMdsZTBdaGsyrsaEaQtsINJq6QbiN/6ehSE4HSjVz9x54rGXgvmYiY9R9hXnwjCMS+64sk2rPxnzDI1UU9N17Ku/VVEEazI6gS4tGTBmYTpgWBBpN7cZfBLRnnYRQZgjwl8oDfK8jUfHu38Fs3zHyP6V18T2uYReIiq+2wNcGsyKe2imNUzulwRtlta+6lEajcXHtz8qzxoq+F6s4hYyTVA3l5DbW/YLFdYvU23lJoSpFacZv8J6PNSatk7JrpA+FU++EZ3t796kB9/aQihshxGghxAYhxGYhxDQ//SYIIaQQwka0SxUp115DGk2tJrEZtPER+SwEdB6j3rI7WHkVBZnmPZQLa1OLN3jP7K52OWGkCnLzFWBXA4IgZDsCIUQ48DxwOpAFLBNCfCGl/MujXyJwC7A0VHNxo7xMJ5zTaDSVZ+SDyvtn9OP++419yn/OJl/UgOo6lDuCgcBmKeVWKWUx8AFwtkW/h4EnARtJv6tIWSlk/YatdLYajUZjxUm3wiWz3es3WDHwGsg4seLj1zPVUCtgl+k8y9HmRAjRD2gjpfza30BCiKlCiOVCiOUHDx6s/Ix+dxR+3rqg8mNoNJqGSafR0HtKcMfsPFZ9JjSHoX9Tifkq67paBWrMWCyECAOeAS4P1FdKOROYCZCZmVn51/mi/ErfqtFoGjgXzgr+mFPedz8fFaT0GRUklDuC3YDZpN/a0WaQCPQAFgghtgODgS9CajDWRmKNRqPxIpSCYBnQUQjRTggRBUwGvjAuSinzpJSpUsoMKWUGsAQ4S0rpIxNTENDxAxqNRuNFyASBlLL0/9u73xi5qjKO499fu3SxrWm7iqS2hFJpxEqkVIKtaNKIIoIBE2u0IjTYxDcYwZgojX+IvDNRKyYEa/yH2CCCRUlDrLKSJrywpdSKpaV2EYVFsNXUKhhx2318cZ8t09lFdre7c3fm/D7JZOeeezo9zzyz+8y5d+Zc4JPAVmAf8JOIeEzSzZKumKz/9//y9wfMzIaZ1LfIEXE/cH9T25depu+qyRwL4ENDZmYjKGaJCcCHhszMRlBWIZisBarMzNpYWYVg8GjdIzAzm3LKKgTHshCc+8F6x2FmNoWUVQgGB6qfl3+t3nGYmU0hhRWCnBFMa811QM3M2kFZheBYzghadEFoM7N2UFYh8IzAzGyYsgrBsQHQtJZd/s3MrB2U9RdxcMCzATOzJmUVgqMvQld33aMwM5tSyioE/30BZsyqexRmZlNKWYVg4N9wysy6R2FmNqWUVQg8IzAzG8aFwMyscC4EZmaFK6cQ7LoD/rLL5wjMzJqUc6WWmT2w9EpYfk3dIzEzm1LKKQTnXF7dzMzsBOUcGjIzsxG5EJiZFc6FwMyscC4EZmaFcyEwMyucC4GZWeFcCMzMCudCYGZWOEVE3WMYE0mHgD+P85+/FvjbBA6nHTjmMjjmMpxMzGdGxGkj7Wi7QnAyJO2MiAvqHkcrOeYyOOYyTFbMPjRkZlY4FwIzs8KVVgi+XfcAauCYy+CYyzApMRd1jsDMzIYrbUZgZmZNXAjMzApXTCGQdKmk/ZL6JN1Y93gmiqQzJD0oaa+kxyRdn+09kn4l6UD+nJftkvTNfB4elbS83gjGR9J0Sb+VtCW3z5K0PeO6S9KMbO/O7b7cv6jOcY+XpLmS7pH0uKR9klYWkONP52t6j6Q7JZ3aiXmW9D1JByXtaWgbc24lrc3+ByStHcsYiigEkqYDtwLvA5YCayQtrXdUE+Yo8JmIWAqsAK7L2G4EeiNiCdCb21A9B0vy9gngttYPeUJcD+xr2P4KsCEizgYOA+uyfR1wONs3ZL92dAvwi4g4BziPKvaOzbGkBcCngAsi4lxgOvAROjPPPwAubWobU24l9QA3AW8DLgRuGioeoxIRHX8DVgJbG7bXA+vrHtckxfpz4D3AfmB+ts0H9uf9jcCahv7H+7XLDViYvxzvArYAovq2ZVdzvoGtwMq835X9VHcMY4x3DvBk87g7PMcLgKeBnszbFuC9nZpnYBGwZ7y5BdYAGxvaT+j3SrciZgS89KIa0p9tHSWnw+cD24HTI+LZ3PUccHre74Tn4hvAZ4HB3H4N8I+IOJrbjTEdjzf3H8n+7eQs4BDw/Twc9h1Js+jgHEfEM8BXgaeAZ6ny9gidnedGY83tSeW8lELQ8STNBn4K3BAR/2zcF9VbhI74nLCk9wMHI+KRusfSQl3AcuC2iDgfeIGXDhUAnZVjgDyscSVVEXw9MIvhh0+K0IrcllIIngHOaNhemG0dQdIpVEVgU0Rszua/Spqf++cDB7O93Z+Li4ArJP0J+DHV4aFbgLmSurJPY0zH4839c4C/t3LAE6Af6I+I7bl9D1Vh6NQcA7wbeDIiDkXEALCZKvednOdGY83tSeW8lELwMLAkP3Ewg+qk0301j2lCSBLwXWBfRHy9Ydd9wNAnB9ZSnTsYar8mP32wAjjSMAWd8iJifUQsjIhFVHn8dURcBTwIrM5uzfEOPQ+rs39bvXOOiOeApyW9MZsuBvbSoTlOTwErJM3M1/hQzB2b5yZjze1W4BJJ83I2dUm2jU7dJ0laeDLmMuAPwBPA5+sezwTG9Q6qaeOjwO68XUZ1fLQXOAA8APRkf1F9guoJ4PdUn8qoPY5xxr4K2JL3FwM7gD7gbqA720/N7b7cv7jucY8z1mXAzszzz4B5nZ5j4MvA48Ae4A6guxPzDNxJdR5kgGr2t248uQU+nvH3AdeOZQxeYsLMrHClHBoyM7OX4UJgZlY4FwIzs8K5EJiZFc6FwMyscC4EZi0kadXQiqlmU4ULgZlZ4VwIzEYg6WOSdkjaLWljXv/geUkbco38XkmnZd9lkn6T68Pf27B2/NmSHpD0O0m7JL0hH352w7UFNuU3Z81q40Jg1kTSm4APAxdFxDLgGHAV1cJnOyPizcA2qvXfAX4IfC4i3kL1bc+h9k3ArRFxHvB2qm+PQrVC7A1U18ZYTLWGjlltul65i1lxLgbeCjycb9ZfRbXo1yBwV/b5EbBZ0hxgbkRsy/bbgbslvRpYEBH3AkTEfwDy8XZERH9u76Zai/6hyQ/LbGQuBGbDCbg9Itaf0Ch9sanfeNdnebHh/jH8e2g186Ehs+F6gdWSXgfHrx97JtXvy9DKlx8FHoqII8BhSe/M9quBbRHxL6Bf0gfyMbolzWxpFGaj5HciZk0iYq+kLwC/lDSNalXI66guCHNh7jtIdR4BqmWCv5V/6P8IXJvtVwMbJd2cj/GhFoZhNmpefdRslCQ9HxGz6x6H2UTzoSEzs8J5RmBmVjjPCMzMCudCYGZWOBcCM7PCuRCYmRXOhcDMrHD/A+UhuQ6zEoFjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBHfbW_eeOx7"
      },
      "source": [
        "**Selfmade Model 2**\r\n",
        "\r\n",
        "Fewer Neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ8LrmQOTZwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c6192ae-04f8-4f0e-d70d-38834a17886f"
      },
      "source": [
        "# Define our CNN\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "model.add(Conv2D(40 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.6)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(54 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.4)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(40 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(32, activation='relu'))\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax')) \r\n",
        "\r\n",
        "#apply learning rate to adam optimizer\r\n",
        "opt = optimizers.Adam(learning_rate=0.0001)\r\n",
        "#apply decay rate to optimizer\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=1e-5,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "#fit call to use the datagen. Used 300 epochs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 35) ,epochs = 300 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of th9e model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 32, 55, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 55, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 28, 40)        11560     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 28, 40)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 28, 40)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 14, 40)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 14, 128)        46208     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 14, 128)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 14, 128)        512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 7, 54)          62262     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 7, 54)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4, 7, 54)          216       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 4, 54)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 4, 40)          19480     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 2, 4, 40)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 2, 4, 40)          160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 2, 40)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2592      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 144,273\n",
            "Trainable params: 143,685\n",
            "Non-trainable params: 588\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "83/83 [==============================] - 17s 191ms/step - loss: 1.7124 - accuracy: 0.3196 - val_loss: 14.2314 - val_accuracy: 0.3600\n",
            "Epoch 2/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 1.4474 - accuracy: 0.3853 - val_loss: 21.2235 - val_accuracy: 0.3600\n",
            "Epoch 3/300\n",
            "83/83 [==============================] - 15s 182ms/step - loss: 1.4075 - accuracy: 0.4119 - val_loss: 30.0653 - val_accuracy: 0.3800\n",
            "Epoch 4/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 1.2650 - accuracy: 0.4612 - val_loss: 39.4180 - val_accuracy: 0.3933\n",
            "Epoch 5/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 1.2795 - accuracy: 0.4476 - val_loss: 47.6470 - val_accuracy: 0.4067\n",
            "Epoch 6/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 1.1968 - accuracy: 0.4846 - val_loss: 50.6989 - val_accuracy: 0.4400\n",
            "Epoch 7/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 1.1866 - accuracy: 0.4801 - val_loss: 56.6370 - val_accuracy: 0.4533\n",
            "Epoch 8/300\n",
            "83/83 [==============================] - 16s 186ms/step - loss: 1.1780 - accuracy: 0.4808 - val_loss: 54.2560 - val_accuracy: 0.4600\n",
            "Epoch 9/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 1.1300 - accuracy: 0.5090 - val_loss: 59.3163 - val_accuracy: 0.4600\n",
            "Epoch 10/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 1.1327 - accuracy: 0.5040 - val_loss: 60.2494 - val_accuracy: 0.4733\n",
            "Epoch 11/300\n",
            "83/83 [==============================] - 16s 186ms/step - loss: 1.0864 - accuracy: 0.5273 - val_loss: 61.9984 - val_accuracy: 0.4667\n",
            "Epoch 12/300\n",
            "83/83 [==============================] - 16s 186ms/step - loss: 1.0793 - accuracy: 0.5470 - val_loss: 61.8429 - val_accuracy: 0.4733\n",
            "Epoch 13/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 1.0478 - accuracy: 0.5339 - val_loss: 64.9088 - val_accuracy: 0.4667\n",
            "Epoch 14/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 1.0482 - accuracy: 0.5403 - val_loss: 60.7089 - val_accuracy: 0.4733\n",
            "Epoch 15/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 1.0395 - accuracy: 0.5439 - val_loss: 61.5534 - val_accuracy: 0.4800\n",
            "Epoch 16/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 1.0237 - accuracy: 0.5354 - val_loss: 61.1504 - val_accuracy: 0.4933\n",
            "Epoch 17/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 1.0144 - accuracy: 0.5571 - val_loss: 56.9789 - val_accuracy: 0.5133\n",
            "Epoch 18/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 1.0067 - accuracy: 0.5660 - val_loss: 55.5579 - val_accuracy: 0.5067\n",
            "Epoch 19/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 1.0090 - accuracy: 0.5549 - val_loss: 53.5443 - val_accuracy: 0.5067\n",
            "Epoch 20/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.9579 - accuracy: 0.5788 - val_loss: 58.4819 - val_accuracy: 0.4867\n",
            "Epoch 21/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.9991 - accuracy: 0.5595 - val_loss: 56.3352 - val_accuracy: 0.4933\n",
            "Epoch 22/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 1.0024 - accuracy: 0.5427 - val_loss: 55.4920 - val_accuracy: 0.5000\n",
            "Epoch 23/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.9832 - accuracy: 0.5868 - val_loss: 57.4715 - val_accuracy: 0.4867\n",
            "Epoch 24/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.9532 - accuracy: 0.5805 - val_loss: 58.4458 - val_accuracy: 0.4733\n",
            "Epoch 25/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.9496 - accuracy: 0.5616 - val_loss: 61.8791 - val_accuracy: 0.4667\n",
            "Epoch 26/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.9674 - accuracy: 0.5516 - val_loss: 61.1762 - val_accuracy: 0.4733\n",
            "Epoch 27/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.9637 - accuracy: 0.5667 - val_loss: 61.8671 - val_accuracy: 0.4733\n",
            "Epoch 28/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.9590 - accuracy: 0.5724 - val_loss: 60.7698 - val_accuracy: 0.4733\n",
            "Epoch 29/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.9199 - accuracy: 0.5987 - val_loss: 63.2349 - val_accuracy: 0.4600\n",
            "Epoch 30/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.9411 - accuracy: 0.5962 - val_loss: 61.3699 - val_accuracy: 0.4800\n",
            "Epoch 31/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.9339 - accuracy: 0.5947 - val_loss: 64.6344 - val_accuracy: 0.4867\n",
            "Epoch 32/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.9132 - accuracy: 0.5993 - val_loss: 65.8033 - val_accuracy: 0.4933\n",
            "Epoch 33/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.9131 - accuracy: 0.5823 - val_loss: 66.9421 - val_accuracy: 0.4667\n",
            "Epoch 34/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.9239 - accuracy: 0.5845 - val_loss: 66.7377 - val_accuracy: 0.4933\n",
            "Epoch 35/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.9000 - accuracy: 0.5992 - val_loss: 70.0807 - val_accuracy: 0.5000\n",
            "Epoch 36/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.9149 - accuracy: 0.5911 - val_loss: 63.9925 - val_accuracy: 0.4933\n",
            "Epoch 37/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.9024 - accuracy: 0.6002 - val_loss: 60.3320 - val_accuracy: 0.4933\n",
            "Epoch 38/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.8798 - accuracy: 0.6018 - val_loss: 65.7249 - val_accuracy: 0.4933\n",
            "Epoch 39/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.9038 - accuracy: 0.5991 - val_loss: 66.3117 - val_accuracy: 0.5067\n",
            "Epoch 40/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8604 - accuracy: 0.6170 - val_loss: 66.5798 - val_accuracy: 0.5000\n",
            "Epoch 41/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.8786 - accuracy: 0.6196 - val_loss: 66.2253 - val_accuracy: 0.4933\n",
            "Epoch 42/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8850 - accuracy: 0.5940 - val_loss: 67.0884 - val_accuracy: 0.4933\n",
            "Epoch 43/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.8437 - accuracy: 0.6139 - val_loss: 68.1497 - val_accuracy: 0.4933\n",
            "Epoch 44/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8535 - accuracy: 0.6152 - val_loss: 65.4744 - val_accuracy: 0.4933\n",
            "Epoch 45/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8797 - accuracy: 0.5959 - val_loss: 69.0732 - val_accuracy: 0.5133\n",
            "Epoch 46/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.8678 - accuracy: 0.5992 - val_loss: 70.6701 - val_accuracy: 0.5067\n",
            "Epoch 47/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8871 - accuracy: 0.6078 - val_loss: 70.4430 - val_accuracy: 0.4933\n",
            "Epoch 48/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8682 - accuracy: 0.6076 - val_loss: 68.8473 - val_accuracy: 0.5133\n",
            "Epoch 49/300\n",
            "83/83 [==============================] - 16s 186ms/step - loss: 0.8523 - accuracy: 0.6100 - val_loss: 68.6276 - val_accuracy: 0.5133\n",
            "Epoch 50/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8747 - accuracy: 0.6011 - val_loss: 71.7133 - val_accuracy: 0.5133\n",
            "Epoch 51/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8416 - accuracy: 0.6116 - val_loss: 70.8643 - val_accuracy: 0.5133\n",
            "Epoch 52/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.8885 - accuracy: 0.5964 - val_loss: 70.8424 - val_accuracy: 0.5200\n",
            "Epoch 53/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8443 - accuracy: 0.6267 - val_loss: 73.5050 - val_accuracy: 0.5067\n",
            "Epoch 54/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8509 - accuracy: 0.6151 - val_loss: 74.2989 - val_accuracy: 0.5133\n",
            "Epoch 55/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8483 - accuracy: 0.6152 - val_loss: 76.8191 - val_accuracy: 0.5067\n",
            "Epoch 56/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.8414 - accuracy: 0.6102 - val_loss: 82.0599 - val_accuracy: 0.5067\n",
            "Epoch 57/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.8723 - accuracy: 0.6016 - val_loss: 82.4839 - val_accuracy: 0.5067\n",
            "Epoch 58/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.8731 - accuracy: 0.6053 - val_loss: 81.7864 - val_accuracy: 0.5267\n",
            "Epoch 59/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8544 - accuracy: 0.5986 - val_loss: 81.2935 - val_accuracy: 0.5267\n",
            "Epoch 60/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.8364 - accuracy: 0.6131 - val_loss: 81.7145 - val_accuracy: 0.5200\n",
            "Epoch 61/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.8406 - accuracy: 0.6210 - val_loss: 80.3604 - val_accuracy: 0.5200\n",
            "Epoch 62/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.8535 - accuracy: 0.5977 - val_loss: 78.2424 - val_accuracy: 0.5200\n",
            "Epoch 63/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.8127 - accuracy: 0.6333 - val_loss: 74.9620 - val_accuracy: 0.5333\n",
            "Epoch 64/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8166 - accuracy: 0.6235 - val_loss: 77.3665 - val_accuracy: 0.5133\n",
            "Epoch 65/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8168 - accuracy: 0.6235 - val_loss: 78.3533 - val_accuracy: 0.5133\n",
            "Epoch 66/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8161 - accuracy: 0.6219 - val_loss: 78.4046 - val_accuracy: 0.5267\n",
            "Epoch 67/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8064 - accuracy: 0.6337 - val_loss: 83.4623 - val_accuracy: 0.5200\n",
            "Epoch 68/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8443 - accuracy: 0.6196 - val_loss: 86.3922 - val_accuracy: 0.5333\n",
            "Epoch 69/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.8424 - accuracy: 0.6111 - val_loss: 83.9461 - val_accuracy: 0.5267\n",
            "Epoch 70/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8171 - accuracy: 0.6217 - val_loss: 81.9455 - val_accuracy: 0.5200\n",
            "Epoch 71/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8210 - accuracy: 0.6150 - val_loss: 82.8765 - val_accuracy: 0.5333\n",
            "Epoch 72/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8024 - accuracy: 0.6298 - val_loss: 83.0340 - val_accuracy: 0.5333\n",
            "Epoch 73/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8127 - accuracy: 0.6192 - val_loss: 84.3099 - val_accuracy: 0.5267\n",
            "Epoch 74/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.8080 - accuracy: 0.6217 - val_loss: 83.6702 - val_accuracy: 0.5267\n",
            "Epoch 75/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7867 - accuracy: 0.6582 - val_loss: 81.2977 - val_accuracy: 0.5400\n",
            "Epoch 76/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7980 - accuracy: 0.6290 - val_loss: 82.3920 - val_accuracy: 0.5333\n",
            "Epoch 77/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.7885 - accuracy: 0.6336 - val_loss: 83.1100 - val_accuracy: 0.5333\n",
            "Epoch 78/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7821 - accuracy: 0.6432 - val_loss: 78.8005 - val_accuracy: 0.5267\n",
            "Epoch 79/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7904 - accuracy: 0.6464 - val_loss: 80.1174 - val_accuracy: 0.5133\n",
            "Epoch 80/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7949 - accuracy: 0.6300 - val_loss: 76.1871 - val_accuracy: 0.5067\n",
            "Epoch 81/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.8136 - accuracy: 0.6222 - val_loss: 75.2801 - val_accuracy: 0.5133\n",
            "Epoch 82/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.8119 - accuracy: 0.6294 - val_loss: 76.4915 - val_accuracy: 0.5400\n",
            "Epoch 83/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7751 - accuracy: 0.6445 - val_loss: 76.5472 - val_accuracy: 0.5333\n",
            "Epoch 84/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7855 - accuracy: 0.6357 - val_loss: 74.9870 - val_accuracy: 0.5267\n",
            "Epoch 85/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.8000 - accuracy: 0.6283 - val_loss: 77.8299 - val_accuracy: 0.5267\n",
            "Epoch 86/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7786 - accuracy: 0.6477 - val_loss: 79.6398 - val_accuracy: 0.5133\n",
            "Epoch 87/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7875 - accuracy: 0.6326 - val_loss: 77.1306 - val_accuracy: 0.5400\n",
            "Epoch 88/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.8108 - accuracy: 0.6169 - val_loss: 79.2721 - val_accuracy: 0.5267\n",
            "Epoch 89/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7774 - accuracy: 0.6427 - val_loss: 76.0789 - val_accuracy: 0.5400\n",
            "Epoch 90/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.8127 - accuracy: 0.6220 - val_loss: 74.0569 - val_accuracy: 0.5400\n",
            "Epoch 91/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.7848 - accuracy: 0.6513 - val_loss: 77.4562 - val_accuracy: 0.5333\n",
            "Epoch 92/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7859 - accuracy: 0.6511 - val_loss: 79.8181 - val_accuracy: 0.5333\n",
            "Epoch 93/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7513 - accuracy: 0.6479 - val_loss: 77.7581 - val_accuracy: 0.5267\n",
            "Epoch 94/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7734 - accuracy: 0.6533 - val_loss: 77.3095 - val_accuracy: 0.5333\n",
            "Epoch 95/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7743 - accuracy: 0.6502 - val_loss: 78.4845 - val_accuracy: 0.5267\n",
            "Epoch 96/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7597 - accuracy: 0.6480 - val_loss: 78.2108 - val_accuracy: 0.5333\n",
            "Epoch 97/300\n",
            "83/83 [==============================] - 16s 196ms/step - loss: 0.7546 - accuracy: 0.6464 - val_loss: 78.6754 - val_accuracy: 0.5400\n",
            "Epoch 98/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7608 - accuracy: 0.6557 - val_loss: 79.0173 - val_accuracy: 0.5333\n",
            "Epoch 99/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7839 - accuracy: 0.6434 - val_loss: 79.5176 - val_accuracy: 0.5333\n",
            "Epoch 100/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7678 - accuracy: 0.6500 - val_loss: 79.5792 - val_accuracy: 0.5333\n",
            "Epoch 101/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7309 - accuracy: 0.6667 - val_loss: 78.1205 - val_accuracy: 0.5333\n",
            "Epoch 102/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7643 - accuracy: 0.6482 - val_loss: 77.2090 - val_accuracy: 0.5267\n",
            "Epoch 103/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7633 - accuracy: 0.6445 - val_loss: 79.3009 - val_accuracy: 0.5133\n",
            "Epoch 104/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7599 - accuracy: 0.6522 - val_loss: 79.2038 - val_accuracy: 0.5133\n",
            "Epoch 105/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7713 - accuracy: 0.6480 - val_loss: 78.5995 - val_accuracy: 0.5133\n",
            "Epoch 106/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7300 - accuracy: 0.6757 - val_loss: 79.0893 - val_accuracy: 0.5133\n",
            "Epoch 107/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7570 - accuracy: 0.6504 - val_loss: 78.8448 - val_accuracy: 0.5267\n",
            "Epoch 108/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7702 - accuracy: 0.6500 - val_loss: 81.0250 - val_accuracy: 0.5200\n",
            "Epoch 109/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7483 - accuracy: 0.6585 - val_loss: 82.7374 - val_accuracy: 0.5267\n",
            "Epoch 110/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7742 - accuracy: 0.6526 - val_loss: 81.5451 - val_accuracy: 0.5200\n",
            "Epoch 111/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7472 - accuracy: 0.6642 - val_loss: 80.6584 - val_accuracy: 0.5267\n",
            "Epoch 112/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7592 - accuracy: 0.6468 - val_loss: 82.4598 - val_accuracy: 0.5267\n",
            "Epoch 113/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7957 - accuracy: 0.6332 - val_loss: 82.7848 - val_accuracy: 0.5200\n",
            "Epoch 114/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7369 - accuracy: 0.6680 - val_loss: 82.7960 - val_accuracy: 0.5200\n",
            "Epoch 115/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7483 - accuracy: 0.6541 - val_loss: 79.4160 - val_accuracy: 0.5200\n",
            "Epoch 116/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.7421 - accuracy: 0.6537 - val_loss: 82.5456 - val_accuracy: 0.5267\n",
            "Epoch 117/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7394 - accuracy: 0.6520 - val_loss: 81.5949 - val_accuracy: 0.5133\n",
            "Epoch 118/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7800 - accuracy: 0.6322 - val_loss: 82.0323 - val_accuracy: 0.5267\n",
            "Epoch 119/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7567 - accuracy: 0.6480 - val_loss: 82.7898 - val_accuracy: 0.5267\n",
            "Epoch 120/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.7370 - accuracy: 0.6700 - val_loss: 80.1486 - val_accuracy: 0.5200\n",
            "Epoch 121/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7659 - accuracy: 0.6607 - val_loss: 81.0650 - val_accuracy: 0.5200\n",
            "Epoch 122/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7798 - accuracy: 0.6414 - val_loss: 84.0389 - val_accuracy: 0.5200\n",
            "Epoch 123/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7410 - accuracy: 0.6568 - val_loss: 81.7820 - val_accuracy: 0.5133\n",
            "Epoch 124/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7379 - accuracy: 0.6772 - val_loss: 85.1580 - val_accuracy: 0.5267\n",
            "Epoch 125/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7704 - accuracy: 0.6313 - val_loss: 82.9545 - val_accuracy: 0.5200\n",
            "Epoch 126/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7370 - accuracy: 0.6708 - val_loss: 80.8533 - val_accuracy: 0.5133\n",
            "Epoch 127/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7257 - accuracy: 0.6758 - val_loss: 82.1180 - val_accuracy: 0.5133\n",
            "Epoch 128/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7527 - accuracy: 0.6585 - val_loss: 81.6357 - val_accuracy: 0.5200\n",
            "Epoch 129/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7106 - accuracy: 0.6779 - val_loss: 86.1231 - val_accuracy: 0.5133\n",
            "Epoch 130/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7347 - accuracy: 0.6659 - val_loss: 84.7909 - val_accuracy: 0.5200\n",
            "Epoch 131/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7432 - accuracy: 0.6614 - val_loss: 88.5746 - val_accuracy: 0.5333\n",
            "Epoch 132/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7481 - accuracy: 0.6703 - val_loss: 85.4736 - val_accuracy: 0.5133\n",
            "Epoch 133/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7300 - accuracy: 0.6666 - val_loss: 87.0245 - val_accuracy: 0.5067\n",
            "Epoch 134/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7456 - accuracy: 0.6568 - val_loss: 87.5845 - val_accuracy: 0.5200\n",
            "Epoch 135/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7465 - accuracy: 0.6534 - val_loss: 84.1191 - val_accuracy: 0.5200\n",
            "Epoch 136/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7153 - accuracy: 0.6743 - val_loss: 83.7765 - val_accuracy: 0.5067\n",
            "Epoch 137/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7332 - accuracy: 0.6639 - val_loss: 89.6535 - val_accuracy: 0.5133\n",
            "Epoch 138/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6928 - accuracy: 0.6846 - val_loss: 90.1707 - val_accuracy: 0.5133\n",
            "Epoch 139/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7250 - accuracy: 0.6681 - val_loss: 90.5320 - val_accuracy: 0.5133\n",
            "Epoch 140/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7244 - accuracy: 0.6683 - val_loss: 92.0165 - val_accuracy: 0.5133\n",
            "Epoch 141/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.7308 - accuracy: 0.6705 - val_loss: 90.8538 - val_accuracy: 0.5200\n",
            "Epoch 142/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7237 - accuracy: 0.6629 - val_loss: 88.5286 - val_accuracy: 0.5200\n",
            "Epoch 143/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7185 - accuracy: 0.6743 - val_loss: 87.2778 - val_accuracy: 0.5267\n",
            "Epoch 144/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7075 - accuracy: 0.6784 - val_loss: 86.9783 - val_accuracy: 0.5133\n",
            "Epoch 145/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7219 - accuracy: 0.6775 - val_loss: 89.1974 - val_accuracy: 0.5200\n",
            "Epoch 146/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7283 - accuracy: 0.6842 - val_loss: 89.5679 - val_accuracy: 0.5200\n",
            "Epoch 147/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7211 - accuracy: 0.6785 - val_loss: 90.0441 - val_accuracy: 0.5133\n",
            "Epoch 148/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.7252 - accuracy: 0.6675 - val_loss: 87.9826 - val_accuracy: 0.5200\n",
            "Epoch 149/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6920 - accuracy: 0.6859 - val_loss: 87.5848 - val_accuracy: 0.5133\n",
            "Epoch 150/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7125 - accuracy: 0.6876 - val_loss: 87.9132 - val_accuracy: 0.5067\n",
            "Epoch 151/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7317 - accuracy: 0.6721 - val_loss: 88.7400 - val_accuracy: 0.5133\n",
            "Epoch 152/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7121 - accuracy: 0.6761 - val_loss: 91.6564 - val_accuracy: 0.5333\n",
            "Epoch 153/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7370 - accuracy: 0.6632 - val_loss: 88.4993 - val_accuracy: 0.5133\n",
            "Epoch 154/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7189 - accuracy: 0.6796 - val_loss: 86.8084 - val_accuracy: 0.5133\n",
            "Epoch 155/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7092 - accuracy: 0.6736 - val_loss: 90.9516 - val_accuracy: 0.5133\n",
            "Epoch 156/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.7195 - accuracy: 0.6731 - val_loss: 87.6445 - val_accuracy: 0.5133\n",
            "Epoch 157/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7056 - accuracy: 0.6718 - val_loss: 84.6424 - val_accuracy: 0.5200\n",
            "Epoch 158/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7091 - accuracy: 0.6707 - val_loss: 86.2929 - val_accuracy: 0.5200\n",
            "Epoch 159/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7062 - accuracy: 0.6878 - val_loss: 87.6361 - val_accuracy: 0.5200\n",
            "Epoch 160/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7346 - accuracy: 0.6539 - val_loss: 89.9706 - val_accuracy: 0.5200\n",
            "Epoch 161/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6928 - accuracy: 0.6768 - val_loss: 90.0337 - val_accuracy: 0.5333\n",
            "Epoch 162/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7289 - accuracy: 0.6696 - val_loss: 87.1371 - val_accuracy: 0.5200\n",
            "Epoch 163/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7077 - accuracy: 0.6840 - val_loss: 88.3103 - val_accuracy: 0.5267\n",
            "Epoch 164/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7082 - accuracy: 0.6762 - val_loss: 87.6126 - val_accuracy: 0.5267\n",
            "Epoch 165/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6978 - accuracy: 0.6827 - val_loss: 86.7882 - val_accuracy: 0.5333\n",
            "Epoch 166/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7179 - accuracy: 0.6615 - val_loss: 88.2548 - val_accuracy: 0.5333\n",
            "Epoch 167/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6883 - accuracy: 0.6931 - val_loss: 89.5605 - val_accuracy: 0.5267\n",
            "Epoch 168/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7052 - accuracy: 0.6691 - val_loss: 89.9544 - val_accuracy: 0.5333\n",
            "Epoch 169/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7263 - accuracy: 0.6795 - val_loss: 87.7362 - val_accuracy: 0.5467\n",
            "Epoch 170/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6914 - accuracy: 0.6954 - val_loss: 88.3842 - val_accuracy: 0.5400\n",
            "Epoch 171/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6931 - accuracy: 0.6917 - val_loss: 88.9629 - val_accuracy: 0.5400\n",
            "Epoch 172/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7140 - accuracy: 0.6809 - val_loss: 90.8309 - val_accuracy: 0.5400\n",
            "Epoch 173/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7070 - accuracy: 0.6736 - val_loss: 91.2553 - val_accuracy: 0.5333\n",
            "Epoch 174/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6976 - accuracy: 0.6944 - val_loss: 91.4687 - val_accuracy: 0.5200\n",
            "Epoch 175/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7015 - accuracy: 0.7033 - val_loss: 88.5947 - val_accuracy: 0.5067\n",
            "Epoch 176/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6870 - accuracy: 0.6843 - val_loss: 88.4550 - val_accuracy: 0.5467\n",
            "Epoch 177/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7058 - accuracy: 0.6736 - val_loss: 85.5256 - val_accuracy: 0.5267\n",
            "Epoch 178/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6921 - accuracy: 0.6860 - val_loss: 86.1548 - val_accuracy: 0.5400\n",
            "Epoch 179/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.7023 - accuracy: 0.6927 - val_loss: 87.2796 - val_accuracy: 0.5067\n",
            "Epoch 180/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6868 - accuracy: 0.6916 - val_loss: 86.1165 - val_accuracy: 0.5200\n",
            "Epoch 181/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7142 - accuracy: 0.6772 - val_loss: 87.1758 - val_accuracy: 0.5267\n",
            "Epoch 182/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6943 - accuracy: 0.6848 - val_loss: 88.9429 - val_accuracy: 0.5467\n",
            "Epoch 183/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7027 - accuracy: 0.6795 - val_loss: 86.5230 - val_accuracy: 0.5467\n",
            "Epoch 184/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6880 - accuracy: 0.7009 - val_loss: 89.1782 - val_accuracy: 0.5267\n",
            "Epoch 185/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6994 - accuracy: 0.6935 - val_loss: 87.9668 - val_accuracy: 0.5333\n",
            "Epoch 186/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6844 - accuracy: 0.7007 - val_loss: 90.2604 - val_accuracy: 0.5467\n",
            "Epoch 187/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6916 - accuracy: 0.6975 - val_loss: 88.0330 - val_accuracy: 0.5333\n",
            "Epoch 188/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.7095 - accuracy: 0.6728 - val_loss: 88.6819 - val_accuracy: 0.5200\n",
            "Epoch 189/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6914 - accuracy: 0.6896 - val_loss: 83.3542 - val_accuracy: 0.5200\n",
            "Epoch 190/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.7126 - accuracy: 0.6829 - val_loss: 84.6145 - val_accuracy: 0.5200\n",
            "Epoch 191/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7117 - accuracy: 0.6783 - val_loss: 87.5993 - val_accuracy: 0.5200\n",
            "Epoch 192/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.7052 - accuracy: 0.6839 - val_loss: 83.0272 - val_accuracy: 0.5133\n",
            "Epoch 193/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6953 - accuracy: 0.6735 - val_loss: 82.6845 - val_accuracy: 0.5200\n",
            "Epoch 194/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6720 - accuracy: 0.6947 - val_loss: 85.7076 - val_accuracy: 0.5333\n",
            "Epoch 195/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6771 - accuracy: 0.6884 - val_loss: 82.2927 - val_accuracy: 0.5333\n",
            "Epoch 196/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.6938 - accuracy: 0.6692 - val_loss: 88.7142 - val_accuracy: 0.5267\n",
            "Epoch 197/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.7031 - accuracy: 0.6894 - val_loss: 85.2513 - val_accuracy: 0.5467\n",
            "Epoch 198/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6734 - accuracy: 0.6983 - val_loss: 85.1090 - val_accuracy: 0.5467\n",
            "Epoch 199/300\n",
            "83/83 [==============================] - 16s 194ms/step - loss: 0.6884 - accuracy: 0.6888 - val_loss: 85.8205 - val_accuracy: 0.5133\n",
            "Epoch 200/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6695 - accuracy: 0.6909 - val_loss: 85.9067 - val_accuracy: 0.5133\n",
            "Epoch 201/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.7156 - accuracy: 0.6817 - val_loss: 84.4980 - val_accuracy: 0.5133\n",
            "Epoch 202/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6945 - accuracy: 0.6934 - val_loss: 84.9815 - val_accuracy: 0.5333\n",
            "Epoch 203/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.6985 - accuracy: 0.6676 - val_loss: 85.5502 - val_accuracy: 0.5200\n",
            "Epoch 204/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6871 - accuracy: 0.7041 - val_loss: 89.5392 - val_accuracy: 0.5133\n",
            "Epoch 205/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.6757 - accuracy: 0.6921 - val_loss: 85.9250 - val_accuracy: 0.5200\n",
            "Epoch 206/300\n",
            "83/83 [==============================] - 17s 199ms/step - loss: 0.6826 - accuracy: 0.6877 - val_loss: 85.3312 - val_accuracy: 0.5200\n",
            "Epoch 207/300\n",
            "83/83 [==============================] - 16s 194ms/step - loss: 0.6866 - accuracy: 0.7022 - val_loss: 87.1916 - val_accuracy: 0.5467\n",
            "Epoch 208/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6809 - accuracy: 0.6780 - val_loss: 84.6474 - val_accuracy: 0.5533\n",
            "Epoch 209/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6705 - accuracy: 0.7059 - val_loss: 90.2485 - val_accuracy: 0.5533\n",
            "Epoch 210/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6847 - accuracy: 0.6974 - val_loss: 89.7423 - val_accuracy: 0.5333\n",
            "Epoch 211/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6645 - accuracy: 0.6994 - val_loss: 83.8829 - val_accuracy: 0.5467\n",
            "Epoch 212/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.6693 - accuracy: 0.6990 - val_loss: 82.4835 - val_accuracy: 0.5467\n",
            "Epoch 213/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6452 - accuracy: 0.7031 - val_loss: 83.1010 - val_accuracy: 0.5467\n",
            "Epoch 214/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6962 - accuracy: 0.6818 - val_loss: 83.1717 - val_accuracy: 0.5533\n",
            "Epoch 215/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6735 - accuracy: 0.6974 - val_loss: 84.6101 - val_accuracy: 0.5533\n",
            "Epoch 216/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6802 - accuracy: 0.6932 - val_loss: 88.1936 - val_accuracy: 0.5533\n",
            "Epoch 217/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6673 - accuracy: 0.6995 - val_loss: 84.2549 - val_accuracy: 0.5600\n",
            "Epoch 218/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6797 - accuracy: 0.6923 - val_loss: 83.6723 - val_accuracy: 0.5467\n",
            "Epoch 219/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6708 - accuracy: 0.7010 - val_loss: 84.0210 - val_accuracy: 0.5467\n",
            "Epoch 220/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6783 - accuracy: 0.6861 - val_loss: 84.5809 - val_accuracy: 0.5333\n",
            "Epoch 221/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.7170 - accuracy: 0.6871 - val_loss: 86.2190 - val_accuracy: 0.5333\n",
            "Epoch 222/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6599 - accuracy: 0.7059 - val_loss: 81.2931 - val_accuracy: 0.5200\n",
            "Epoch 223/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6685 - accuracy: 0.7022 - val_loss: 84.1896 - val_accuracy: 0.5267\n",
            "Epoch 224/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6631 - accuracy: 0.6933 - val_loss: 79.1651 - val_accuracy: 0.5467\n",
            "Epoch 225/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6605 - accuracy: 0.6946 - val_loss: 80.8353 - val_accuracy: 0.5400\n",
            "Epoch 226/300\n",
            "83/83 [==============================] - 15s 185ms/step - loss: 0.6746 - accuracy: 0.6838 - val_loss: 77.4517 - val_accuracy: 0.5467\n",
            "Epoch 227/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6553 - accuracy: 0.7016 - val_loss: 74.5485 - val_accuracy: 0.5467\n",
            "Epoch 228/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6468 - accuracy: 0.7076 - val_loss: 77.0211 - val_accuracy: 0.5333\n",
            "Epoch 229/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6501 - accuracy: 0.7132 - val_loss: 76.2209 - val_accuracy: 0.5267\n",
            "Epoch 230/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6687 - accuracy: 0.6963 - val_loss: 80.9151 - val_accuracy: 0.5267\n",
            "Epoch 231/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6784 - accuracy: 0.6961 - val_loss: 78.3177 - val_accuracy: 0.5267\n",
            "Epoch 232/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6698 - accuracy: 0.6934 - val_loss: 76.6806 - val_accuracy: 0.5333\n",
            "Epoch 233/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6829 - accuracy: 0.6962 - val_loss: 76.8046 - val_accuracy: 0.5333\n",
            "Epoch 234/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6790 - accuracy: 0.6953 - val_loss: 77.8596 - val_accuracy: 0.5333\n",
            "Epoch 235/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6741 - accuracy: 0.6800 - val_loss: 79.1032 - val_accuracy: 0.5267\n",
            "Epoch 236/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6707 - accuracy: 0.7093 - val_loss: 76.1203 - val_accuracy: 0.5333\n",
            "Epoch 237/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6732 - accuracy: 0.6961 - val_loss: 74.4234 - val_accuracy: 0.5333\n",
            "Epoch 238/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6702 - accuracy: 0.7007 - val_loss: 78.6601 - val_accuracy: 0.5333\n",
            "Epoch 239/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6387 - accuracy: 0.7170 - val_loss: 77.1899 - val_accuracy: 0.5333\n",
            "Epoch 240/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6875 - accuracy: 0.7004 - val_loss: 73.2916 - val_accuracy: 0.5333\n",
            "Epoch 241/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6572 - accuracy: 0.7030 - val_loss: 74.0851 - val_accuracy: 0.5400\n",
            "Epoch 242/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6784 - accuracy: 0.6945 - val_loss: 79.8881 - val_accuracy: 0.5467\n",
            "Epoch 243/300\n",
            "83/83 [==============================] - 18s 213ms/step - loss: 0.6561 - accuracy: 0.6956 - val_loss: 81.3853 - val_accuracy: 0.5467\n",
            "Epoch 244/300\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.6843 - accuracy: 0.6948 - val_loss: 78.0014 - val_accuracy: 0.5400\n",
            "Epoch 245/300\n",
            "83/83 [==============================] - 16s 188ms/step - loss: 0.6503 - accuracy: 0.7034 - val_loss: 77.9174 - val_accuracy: 0.5400\n",
            "Epoch 246/300\n",
            "83/83 [==============================] - 16s 190ms/step - loss: 0.6481 - accuracy: 0.7149 - val_loss: 75.9485 - val_accuracy: 0.5400\n",
            "Epoch 247/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6563 - accuracy: 0.7139 - val_loss: 78.2897 - val_accuracy: 0.5467\n",
            "Epoch 248/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6740 - accuracy: 0.6930 - val_loss: 79.7499 - val_accuracy: 0.5333\n",
            "Epoch 249/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6611 - accuracy: 0.7114 - val_loss: 83.0082 - val_accuracy: 0.5467\n",
            "Epoch 250/300\n",
            "83/83 [==============================] - 15s 186ms/step - loss: 0.6473 - accuracy: 0.7144 - val_loss: 81.1479 - val_accuracy: 0.5467\n",
            "Epoch 251/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6337 - accuracy: 0.7180 - val_loss: 78.1182 - val_accuracy: 0.5400\n",
            "Epoch 252/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.6323 - accuracy: 0.7188 - val_loss: 74.8876 - val_accuracy: 0.5533\n",
            "Epoch 253/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.6784 - accuracy: 0.6890 - val_loss: 73.5003 - val_accuracy: 0.5600\n",
            "Epoch 254/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.6651 - accuracy: 0.6970 - val_loss: 71.5423 - val_accuracy: 0.5533\n",
            "Epoch 255/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6621 - accuracy: 0.6974 - val_loss: 71.2119 - val_accuracy: 0.5467\n",
            "Epoch 256/300\n",
            "83/83 [==============================] - 17s 199ms/step - loss: 0.6671 - accuracy: 0.6913 - val_loss: 74.7138 - val_accuracy: 0.5467\n",
            "Epoch 257/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6433 - accuracy: 0.7268 - val_loss: 73.5004 - val_accuracy: 0.5533\n",
            "Epoch 258/300\n",
            "83/83 [==============================] - 16s 196ms/step - loss: 0.6572 - accuracy: 0.7081 - val_loss: 72.4697 - val_accuracy: 0.5467\n",
            "Epoch 259/300\n",
            "83/83 [==============================] - 16s 194ms/step - loss: 0.6605 - accuracy: 0.6995 - val_loss: 74.7639 - val_accuracy: 0.5533\n",
            "Epoch 260/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6584 - accuracy: 0.7000 - val_loss: 76.9713 - val_accuracy: 0.5533\n",
            "Epoch 261/300\n",
            "83/83 [==============================] - 16s 194ms/step - loss: 0.6598 - accuracy: 0.7071 - val_loss: 72.2153 - val_accuracy: 0.5533\n",
            "Epoch 262/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6547 - accuracy: 0.6922 - val_loss: 71.9655 - val_accuracy: 0.5600\n",
            "Epoch 263/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6300 - accuracy: 0.7246 - val_loss: 74.7682 - val_accuracy: 0.5467\n",
            "Epoch 264/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6566 - accuracy: 0.7037 - val_loss: 75.3506 - val_accuracy: 0.5533\n",
            "Epoch 265/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6394 - accuracy: 0.7223 - val_loss: 72.0871 - val_accuracy: 0.5400\n",
            "Epoch 266/300\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.6478 - accuracy: 0.7042 - val_loss: 72.9601 - val_accuracy: 0.5533\n",
            "Epoch 267/300\n",
            "83/83 [==============================] - 17s 199ms/step - loss: 0.6562 - accuracy: 0.7027 - val_loss: 73.9366 - val_accuracy: 0.5600\n",
            "Epoch 268/300\n",
            "83/83 [==============================] - 16s 198ms/step - loss: 0.6508 - accuracy: 0.7129 - val_loss: 74.1722 - val_accuracy: 0.5600\n",
            "Epoch 269/300\n",
            "83/83 [==============================] - 17s 200ms/step - loss: 0.6420 - accuracy: 0.7016 - val_loss: 74.1835 - val_accuracy: 0.5600\n",
            "Epoch 270/300\n",
            "83/83 [==============================] - 16s 198ms/step - loss: 0.6244 - accuracy: 0.7233 - val_loss: 71.0089 - val_accuracy: 0.5600\n",
            "Epoch 271/300\n",
            "83/83 [==============================] - 17s 202ms/step - loss: 0.6612 - accuracy: 0.7071 - val_loss: 75.0140 - val_accuracy: 0.5600\n",
            "Epoch 272/300\n",
            "83/83 [==============================] - 17s 205ms/step - loss: 0.6632 - accuracy: 0.7124 - val_loss: 75.8235 - val_accuracy: 0.5600\n",
            "Epoch 273/300\n",
            "83/83 [==============================] - 17s 199ms/step - loss: 0.6710 - accuracy: 0.7055 - val_loss: 71.9310 - val_accuracy: 0.5600\n",
            "Epoch 274/300\n",
            "83/83 [==============================] - 17s 203ms/step - loss: 0.6503 - accuracy: 0.6983 - val_loss: 68.9255 - val_accuracy: 0.5600\n",
            "Epoch 275/300\n",
            "83/83 [==============================] - 17s 200ms/step - loss: 0.6825 - accuracy: 0.6909 - val_loss: 69.0981 - val_accuracy: 0.5600\n",
            "Epoch 276/300\n",
            "83/83 [==============================] - 16s 196ms/step - loss: 0.6585 - accuracy: 0.7089 - val_loss: 70.2347 - val_accuracy: 0.5533\n",
            "Epoch 277/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6360 - accuracy: 0.7210 - val_loss: 69.6976 - val_accuracy: 0.5667\n",
            "Epoch 278/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6199 - accuracy: 0.7196 - val_loss: 65.7570 - val_accuracy: 0.5533\n",
            "Epoch 279/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6505 - accuracy: 0.7124 - val_loss: 67.9673 - val_accuracy: 0.5600\n",
            "Epoch 280/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6422 - accuracy: 0.7140 - val_loss: 68.7391 - val_accuracy: 0.5533\n",
            "Epoch 281/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.6511 - accuracy: 0.7249 - val_loss: 70.6797 - val_accuracy: 0.5600\n",
            "Epoch 282/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.6557 - accuracy: 0.7165 - val_loss: 73.0708 - val_accuracy: 0.5600\n",
            "Epoch 283/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6572 - accuracy: 0.7166 - val_loss: 74.0650 - val_accuracy: 0.5600\n",
            "Epoch 284/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6328 - accuracy: 0.7241 - val_loss: 73.5426 - val_accuracy: 0.5600\n",
            "Epoch 285/300\n",
            "83/83 [==============================] - 17s 201ms/step - loss: 0.6306 - accuracy: 0.7191 - val_loss: 72.7617 - val_accuracy: 0.5533\n",
            "Epoch 286/300\n",
            "83/83 [==============================] - 16s 194ms/step - loss: 0.6339 - accuracy: 0.7188 - val_loss: 75.0807 - val_accuracy: 0.5533\n",
            "Epoch 287/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6528 - accuracy: 0.7239 - val_loss: 76.2818 - val_accuracy: 0.5600\n",
            "Epoch 288/300\n",
            "83/83 [==============================] - 16s 194ms/step - loss: 0.6378 - accuracy: 0.7064 - val_loss: 73.9846 - val_accuracy: 0.5600\n",
            "Epoch 289/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6303 - accuracy: 0.7169 - val_loss: 76.7717 - val_accuracy: 0.5667\n",
            "Epoch 290/300\n",
            "83/83 [==============================] - 16s 193ms/step - loss: 0.6535 - accuracy: 0.7013 - val_loss: 76.6800 - val_accuracy: 0.5667\n",
            "Epoch 291/300\n",
            "83/83 [==============================] - 16s 195ms/step - loss: 0.6553 - accuracy: 0.7110 - val_loss: 69.5164 - val_accuracy: 0.5600\n",
            "Epoch 292/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6384 - accuracy: 0.7145 - val_loss: 74.1320 - val_accuracy: 0.5467\n",
            "Epoch 293/300\n",
            "83/83 [==============================] - 16s 194ms/step - loss: 0.6001 - accuracy: 0.7426 - val_loss: 75.0756 - val_accuracy: 0.5533\n",
            "Epoch 294/300\n",
            "83/83 [==============================] - 16s 192ms/step - loss: 0.6329 - accuracy: 0.7336 - val_loss: 75.5060 - val_accuracy: 0.5467\n",
            "Epoch 295/300\n",
            "83/83 [==============================] - 16s 191ms/step - loss: 0.6595 - accuracy: 0.7072 - val_loss: 75.0576 - val_accuracy: 0.5533\n",
            "Epoch 296/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6479 - accuracy: 0.7128 - val_loss: 72.9988 - val_accuracy: 0.5600\n",
            "Epoch 297/300\n",
            "83/83 [==============================] - 16s 187ms/step - loss: 0.6410 - accuracy: 0.7285 - val_loss: 71.9994 - val_accuracy: 0.5533\n",
            "Epoch 298/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6445 - accuracy: 0.7219 - val_loss: 69.3213 - val_accuracy: 0.5600\n",
            "Epoch 299/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6326 - accuracy: 0.7208 - val_loss: 69.8453 - val_accuracy: 0.5600\n",
            "Epoch 300/300\n",
            "83/83 [==============================] - 16s 189ms/step - loss: 0.6208 - accuracy: 0.7210 - val_loss: 70.7246 - val_accuracy: 0.5600\n",
            "Train Accuracy of the model is 0.5946509204584925\n",
            "Test Accuracy of the model is 0.56\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPS84tBxfF3O"
      },
      "source": [
        "**Selfmade Model 3**\r\n",
        "\r\n",
        "Best Validation Accu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o5qpD3FO-qdz",
        "outputId": "79ddb48f-93af-4b3e-b0d4-c614372242e8"
      },
      "source": [
        "# Define our CNN\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(40 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(32, activation='relu'))\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax')) \r\n",
        "\r\n",
        "#apply learning rate to adam optimizer\r\n",
        "opt = optimizers.Adam(learning_rate=0.0001)\r\n",
        "#apply decay rate\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=1e-5,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping (Not used)\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "#fit call to use the datagen. Used 300 epochs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 35) ,epochs = 300 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of th9e model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 32, 55, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 32, 55, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 16, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 16, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 16, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 8, 14, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 8, 14, 128)        73856     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 8, 14, 128)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 8, 14, 128)        512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 4, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 4, 7, 40)          46120     \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 4, 7, 40)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 4, 7, 40)          160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 2, 4, 40)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 32)                10272     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 150,795\n",
            "Trainable params: 150,267\n",
            "Non-trainable params: 528\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "83/83 [==============================] - 19s 217ms/step - loss: 1.6466 - accuracy: 0.3544 - val_loss: 14.9501 - val_accuracy: 0.3600\n",
            "Epoch 2/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 1.2453 - accuracy: 0.4457 - val_loss: 21.7864 - val_accuracy: 0.4067\n",
            "Epoch 3/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 1.0951 - accuracy: 0.5185 - val_loss: 35.8539 - val_accuracy: 0.4200\n",
            "Epoch 4/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 1.0867 - accuracy: 0.5238 - val_loss: 54.3448 - val_accuracy: 0.4200\n",
            "Epoch 5/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.9802 - accuracy: 0.5513 - val_loss: 73.3467 - val_accuracy: 0.4667\n",
            "Epoch 6/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 1.0165 - accuracy: 0.5442 - val_loss: 102.1934 - val_accuracy: 0.4467\n",
            "Epoch 7/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.9734 - accuracy: 0.5554 - val_loss: 131.7388 - val_accuracy: 0.4800\n",
            "Epoch 8/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.9593 - accuracy: 0.5579 - val_loss: 153.5498 - val_accuracy: 0.4800\n",
            "Epoch 9/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.9368 - accuracy: 0.5655 - val_loss: 190.3758 - val_accuracy: 0.4867\n",
            "Epoch 10/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.9368 - accuracy: 0.5710 - val_loss: 200.1084 - val_accuracy: 0.4667\n",
            "Epoch 11/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.8691 - accuracy: 0.6031 - val_loss: 225.7328 - val_accuracy: 0.4533\n",
            "Epoch 12/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.9036 - accuracy: 0.5730 - val_loss: 236.9403 - val_accuracy: 0.4533\n",
            "Epoch 13/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.9169 - accuracy: 0.5960 - val_loss: 242.0470 - val_accuracy: 0.4400\n",
            "Epoch 14/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.8707 - accuracy: 0.5949 - val_loss: 234.6502 - val_accuracy: 0.4600\n",
            "Epoch 15/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.8592 - accuracy: 0.6003 - val_loss: 229.7722 - val_accuracy: 0.4800\n",
            "Epoch 16/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.8602 - accuracy: 0.6016 - val_loss: 241.4906 - val_accuracy: 0.4667\n",
            "Epoch 17/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.8552 - accuracy: 0.6083 - val_loss: 248.4699 - val_accuracy: 0.4600\n",
            "Epoch 18/300\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.8351 - accuracy: 0.6155 - val_loss: 226.8458 - val_accuracy: 0.4800\n",
            "Epoch 19/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.8110 - accuracy: 0.6340 - val_loss: 220.8914 - val_accuracy: 0.4800\n",
            "Epoch 20/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.8393 - accuracy: 0.6241 - val_loss: 228.2939 - val_accuracy: 0.4800\n",
            "Epoch 21/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.8348 - accuracy: 0.6139 - val_loss: 200.2039 - val_accuracy: 0.5133\n",
            "Epoch 22/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.8039 - accuracy: 0.6500 - val_loss: 187.4554 - val_accuracy: 0.5000\n",
            "Epoch 23/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.8397 - accuracy: 0.6123 - val_loss: 197.3657 - val_accuracy: 0.5067\n",
            "Epoch 24/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.7972 - accuracy: 0.6555 - val_loss: 198.4954 - val_accuracy: 0.5133\n",
            "Epoch 25/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.8288 - accuracy: 0.6361 - val_loss: 221.3369 - val_accuracy: 0.4800\n",
            "Epoch 26/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.7649 - accuracy: 0.6535 - val_loss: 230.9600 - val_accuracy: 0.4667\n",
            "Epoch 27/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.8037 - accuracy: 0.6405 - val_loss: 198.7122 - val_accuracy: 0.4800\n",
            "Epoch 28/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.8068 - accuracy: 0.6395 - val_loss: 200.1001 - val_accuracy: 0.5067\n",
            "Epoch 29/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7887 - accuracy: 0.6333 - val_loss: 173.4469 - val_accuracy: 0.5200\n",
            "Epoch 30/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.7572 - accuracy: 0.6534 - val_loss: 174.7098 - val_accuracy: 0.5200\n",
            "Epoch 31/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7985 - accuracy: 0.6492 - val_loss: 170.0147 - val_accuracy: 0.5200\n",
            "Epoch 32/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7591 - accuracy: 0.6694 - val_loss: 160.9517 - val_accuracy: 0.5333\n",
            "Epoch 33/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7365 - accuracy: 0.6658 - val_loss: 165.3816 - val_accuracy: 0.5267\n",
            "Epoch 34/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.7876 - accuracy: 0.6454 - val_loss: 174.8141 - val_accuracy: 0.5333\n",
            "Epoch 35/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.7605 - accuracy: 0.6627 - val_loss: 181.2952 - val_accuracy: 0.5333\n",
            "Epoch 36/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.7555 - accuracy: 0.6642 - val_loss: 187.4248 - val_accuracy: 0.5200\n",
            "Epoch 37/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.7393 - accuracy: 0.6638 - val_loss: 192.0583 - val_accuracy: 0.5200\n",
            "Epoch 38/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.7756 - accuracy: 0.6532 - val_loss: 199.1726 - val_accuracy: 0.5067\n",
            "Epoch 39/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.7390 - accuracy: 0.6747 - val_loss: 189.4371 - val_accuracy: 0.5200\n",
            "Epoch 40/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.7593 - accuracy: 0.6642 - val_loss: 194.5348 - val_accuracy: 0.5067\n",
            "Epoch 41/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.7513 - accuracy: 0.6582 - val_loss: 167.9547 - val_accuracy: 0.5467\n",
            "Epoch 42/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.7368 - accuracy: 0.6707 - val_loss: 174.7278 - val_accuracy: 0.5467\n",
            "Epoch 43/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.7458 - accuracy: 0.6594 - val_loss: 182.6676 - val_accuracy: 0.5400\n",
            "Epoch 44/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.7412 - accuracy: 0.6785 - val_loss: 159.8789 - val_accuracy: 0.5533\n",
            "Epoch 45/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7382 - accuracy: 0.6729 - val_loss: 156.1992 - val_accuracy: 0.5467\n",
            "Epoch 46/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7044 - accuracy: 0.6965 - val_loss: 152.0954 - val_accuracy: 0.5467\n",
            "Epoch 47/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.7295 - accuracy: 0.6769 - val_loss: 146.3476 - val_accuracy: 0.5467\n",
            "Epoch 48/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.7124 - accuracy: 0.6831 - val_loss: 153.5912 - val_accuracy: 0.5400\n",
            "Epoch 49/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.7253 - accuracy: 0.6742 - val_loss: 167.7354 - val_accuracy: 0.5333\n",
            "Epoch 50/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.7218 - accuracy: 0.6839 - val_loss: 165.0458 - val_accuracy: 0.5400\n",
            "Epoch 51/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.7121 - accuracy: 0.6846 - val_loss: 147.6803 - val_accuracy: 0.5600\n",
            "Epoch 52/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.7220 - accuracy: 0.6761 - val_loss: 157.5740 - val_accuracy: 0.5400\n",
            "Epoch 53/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7032 - accuracy: 0.6698 - val_loss: 144.4204 - val_accuracy: 0.5400\n",
            "Epoch 54/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6806 - accuracy: 0.7126 - val_loss: 149.7213 - val_accuracy: 0.5400\n",
            "Epoch 55/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.7198 - accuracy: 0.6874 - val_loss: 154.9397 - val_accuracy: 0.5333\n",
            "Epoch 56/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6815 - accuracy: 0.6967 - val_loss: 174.1558 - val_accuracy: 0.5200\n",
            "Epoch 57/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6970 - accuracy: 0.6948 - val_loss: 160.1091 - val_accuracy: 0.5333\n",
            "Epoch 58/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.7031 - accuracy: 0.6998 - val_loss: 175.3895 - val_accuracy: 0.5200\n",
            "Epoch 59/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6930 - accuracy: 0.6959 - val_loss: 157.9671 - val_accuracy: 0.5467\n",
            "Epoch 60/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6795 - accuracy: 0.7061 - val_loss: 160.8160 - val_accuracy: 0.5333\n",
            "Epoch 61/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6986 - accuracy: 0.6855 - val_loss: 148.2419 - val_accuracy: 0.5400\n",
            "Epoch 62/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6954 - accuracy: 0.6997 - val_loss: 157.8695 - val_accuracy: 0.5400\n",
            "Epoch 63/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6872 - accuracy: 0.7110 - val_loss: 145.8658 - val_accuracy: 0.5400\n",
            "Epoch 64/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6648 - accuracy: 0.7123 - val_loss: 137.9193 - val_accuracy: 0.5600\n",
            "Epoch 65/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6475 - accuracy: 0.7239 - val_loss: 137.0755 - val_accuracy: 0.5800\n",
            "Epoch 66/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6753 - accuracy: 0.6994 - val_loss: 131.8239 - val_accuracy: 0.5933\n",
            "Epoch 67/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6959 - accuracy: 0.6902 - val_loss: 134.5013 - val_accuracy: 0.5800\n",
            "Epoch 68/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6894 - accuracy: 0.7096 - val_loss: 128.5948 - val_accuracy: 0.5867\n",
            "Epoch 69/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6725 - accuracy: 0.6965 - val_loss: 137.9666 - val_accuracy: 0.5667\n",
            "Epoch 70/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6759 - accuracy: 0.7035 - val_loss: 133.8721 - val_accuracy: 0.5467\n",
            "Epoch 71/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6578 - accuracy: 0.7065 - val_loss: 139.6945 - val_accuracy: 0.5600\n",
            "Epoch 72/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6708 - accuracy: 0.6974 - val_loss: 130.3408 - val_accuracy: 0.5667\n",
            "Epoch 73/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.6686 - accuracy: 0.7268 - val_loss: 131.8527 - val_accuracy: 0.5600\n",
            "Epoch 74/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.6818 - accuracy: 0.7084 - val_loss: 123.5635 - val_accuracy: 0.5867\n",
            "Epoch 75/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6714 - accuracy: 0.7103 - val_loss: 131.8241 - val_accuracy: 0.5667\n",
            "Epoch 76/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.7023 - accuracy: 0.6948 - val_loss: 136.8669 - val_accuracy: 0.5600\n",
            "Epoch 77/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.6612 - accuracy: 0.7167 - val_loss: 123.7501 - val_accuracy: 0.5867\n",
            "Epoch 78/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6558 - accuracy: 0.7142 - val_loss: 120.5653 - val_accuracy: 0.5933\n",
            "Epoch 79/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.6726 - accuracy: 0.6958 - val_loss: 128.4743 - val_accuracy: 0.5733\n",
            "Epoch 80/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6536 - accuracy: 0.7095 - val_loss: 135.7358 - val_accuracy: 0.5600\n",
            "Epoch 81/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6939 - accuracy: 0.6899 - val_loss: 126.0226 - val_accuracy: 0.5600\n",
            "Epoch 82/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.7177 - accuracy: 0.6978 - val_loss: 119.1394 - val_accuracy: 0.6067\n",
            "Epoch 83/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6642 - accuracy: 0.7138 - val_loss: 127.0376 - val_accuracy: 0.5733\n",
            "Epoch 84/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6578 - accuracy: 0.7145 - val_loss: 115.0454 - val_accuracy: 0.5733\n",
            "Epoch 85/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6275 - accuracy: 0.7237 - val_loss: 118.0394 - val_accuracy: 0.5933\n",
            "Epoch 86/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6599 - accuracy: 0.7160 - val_loss: 127.6047 - val_accuracy: 0.5867\n",
            "Epoch 87/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6520 - accuracy: 0.7198 - val_loss: 130.1175 - val_accuracy: 0.5867\n",
            "Epoch 88/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6475 - accuracy: 0.7354 - val_loss: 119.3950 - val_accuracy: 0.5733\n",
            "Epoch 89/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6651 - accuracy: 0.7108 - val_loss: 110.2270 - val_accuracy: 0.6000\n",
            "Epoch 90/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6311 - accuracy: 0.7352 - val_loss: 119.1475 - val_accuracy: 0.5800\n",
            "Epoch 91/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6352 - accuracy: 0.7322 - val_loss: 124.2453 - val_accuracy: 0.5733\n",
            "Epoch 92/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6407 - accuracy: 0.7192 - val_loss: 121.4619 - val_accuracy: 0.5867\n",
            "Epoch 93/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6236 - accuracy: 0.7319 - val_loss: 117.7296 - val_accuracy: 0.6000\n",
            "Epoch 94/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6427 - accuracy: 0.7128 - val_loss: 113.2097 - val_accuracy: 0.6000\n",
            "Epoch 95/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6422 - accuracy: 0.7185 - val_loss: 115.8731 - val_accuracy: 0.5867\n",
            "Epoch 96/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6484 - accuracy: 0.7161 - val_loss: 119.2094 - val_accuracy: 0.6067\n",
            "Epoch 97/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6523 - accuracy: 0.7143 - val_loss: 118.0018 - val_accuracy: 0.6000\n",
            "Epoch 98/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6208 - accuracy: 0.7385 - val_loss: 112.0382 - val_accuracy: 0.6133\n",
            "Epoch 99/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6466 - accuracy: 0.7231 - val_loss: 113.2723 - val_accuracy: 0.5933\n",
            "Epoch 100/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6316 - accuracy: 0.7146 - val_loss: 117.7925 - val_accuracy: 0.5867\n",
            "Epoch 101/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.6119 - accuracy: 0.7300 - val_loss: 117.0980 - val_accuracy: 0.6067\n",
            "Epoch 102/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6288 - accuracy: 0.7334 - val_loss: 114.6320 - val_accuracy: 0.6133\n",
            "Epoch 103/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6262 - accuracy: 0.7266 - val_loss: 113.1996 - val_accuracy: 0.6267\n",
            "Epoch 104/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.6120 - accuracy: 0.7380 - val_loss: 113.8708 - val_accuracy: 0.6200\n",
            "Epoch 105/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6432 - accuracy: 0.7217 - val_loss: 116.2106 - val_accuracy: 0.6000\n",
            "Epoch 106/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.6358 - accuracy: 0.7278 - val_loss: 112.3499 - val_accuracy: 0.6267\n",
            "Epoch 107/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6445 - accuracy: 0.7338 - val_loss: 114.0422 - val_accuracy: 0.6200\n",
            "Epoch 108/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6600 - accuracy: 0.7103 - val_loss: 113.6802 - val_accuracy: 0.6133\n",
            "Epoch 109/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6038 - accuracy: 0.7452 - val_loss: 115.8432 - val_accuracy: 0.6067\n",
            "Epoch 110/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.6307 - accuracy: 0.7316 - val_loss: 113.3950 - val_accuracy: 0.6200\n",
            "Epoch 111/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6166 - accuracy: 0.7373 - val_loss: 118.3971 - val_accuracy: 0.5933\n",
            "Epoch 112/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6018 - accuracy: 0.7559 - val_loss: 116.1899 - val_accuracy: 0.5733\n",
            "Epoch 113/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.6211 - accuracy: 0.7328 - val_loss: 111.5441 - val_accuracy: 0.6000\n",
            "Epoch 114/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.6027 - accuracy: 0.7372 - val_loss: 112.6886 - val_accuracy: 0.6267\n",
            "Epoch 115/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6095 - accuracy: 0.7519 - val_loss: 111.7993 - val_accuracy: 0.6200\n",
            "Epoch 116/300\n",
            "83/83 [==============================] - 18s 213ms/step - loss: 0.6204 - accuracy: 0.7319 - val_loss: 109.3322 - val_accuracy: 0.6067\n",
            "Epoch 117/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6046 - accuracy: 0.7367 - val_loss: 112.4618 - val_accuracy: 0.6133\n",
            "Epoch 118/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6116 - accuracy: 0.7390 - val_loss: 116.3050 - val_accuracy: 0.6067\n",
            "Epoch 119/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6277 - accuracy: 0.7480 - val_loss: 110.5898 - val_accuracy: 0.6267\n",
            "Epoch 120/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.6200 - accuracy: 0.7329 - val_loss: 104.9550 - val_accuracy: 0.5933\n",
            "Epoch 121/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6092 - accuracy: 0.7301 - val_loss: 109.2093 - val_accuracy: 0.6000\n",
            "Epoch 122/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.6029 - accuracy: 0.7466 - val_loss: 108.6541 - val_accuracy: 0.6000\n",
            "Epoch 123/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.6019 - accuracy: 0.7514 - val_loss: 109.0105 - val_accuracy: 0.6133\n",
            "Epoch 124/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6162 - accuracy: 0.7480 - val_loss: 111.0544 - val_accuracy: 0.6200\n",
            "Epoch 125/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6134 - accuracy: 0.7380 - val_loss: 117.4167 - val_accuracy: 0.5867\n",
            "Epoch 126/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.5892 - accuracy: 0.7498 - val_loss: 118.2811 - val_accuracy: 0.5800\n",
            "Epoch 127/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.5970 - accuracy: 0.7440 - val_loss: 113.6207 - val_accuracy: 0.5867\n",
            "Epoch 128/300\n",
            "83/83 [==============================] - 18s 214ms/step - loss: 0.6118 - accuracy: 0.7296 - val_loss: 110.5074 - val_accuracy: 0.6000\n",
            "Epoch 129/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5915 - accuracy: 0.7596 - val_loss: 107.1487 - val_accuracy: 0.6133\n",
            "Epoch 130/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5985 - accuracy: 0.7539 - val_loss: 102.6743 - val_accuracy: 0.6133\n",
            "Epoch 131/300\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.5975 - accuracy: 0.7550 - val_loss: 107.9169 - val_accuracy: 0.5933\n",
            "Epoch 132/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5902 - accuracy: 0.7400 - val_loss: 118.5053 - val_accuracy: 0.5733\n",
            "Epoch 133/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6050 - accuracy: 0.7514 - val_loss: 111.0864 - val_accuracy: 0.5933\n",
            "Epoch 134/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5858 - accuracy: 0.7500 - val_loss: 107.3952 - val_accuracy: 0.5867\n",
            "Epoch 135/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.5976 - accuracy: 0.7510 - val_loss: 108.8992 - val_accuracy: 0.5933\n",
            "Epoch 136/300\n",
            "83/83 [==============================] - 18s 216ms/step - loss: 0.5972 - accuracy: 0.7411 - val_loss: 106.7528 - val_accuracy: 0.5933\n",
            "Epoch 137/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.6047 - accuracy: 0.7427 - val_loss: 106.3711 - val_accuracy: 0.6200\n",
            "Epoch 138/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.5930 - accuracy: 0.7493 - val_loss: 101.3399 - val_accuracy: 0.6267\n",
            "Epoch 139/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.5871 - accuracy: 0.7479 - val_loss: 100.0905 - val_accuracy: 0.6333\n",
            "Epoch 140/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.6030 - accuracy: 0.7301 - val_loss: 98.2458 - val_accuracy: 0.6400\n",
            "Epoch 141/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5972 - accuracy: 0.7389 - val_loss: 96.6034 - val_accuracy: 0.6467\n",
            "Epoch 142/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5821 - accuracy: 0.7581 - val_loss: 101.3441 - val_accuracy: 0.6267\n",
            "Epoch 143/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.6099 - accuracy: 0.7319 - val_loss: 103.2392 - val_accuracy: 0.6133\n",
            "Epoch 144/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5823 - accuracy: 0.7532 - val_loss: 101.2790 - val_accuracy: 0.6467\n",
            "Epoch 145/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5666 - accuracy: 0.7676 - val_loss: 101.7268 - val_accuracy: 0.6067\n",
            "Epoch 146/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5793 - accuracy: 0.7556 - val_loss: 95.9257 - val_accuracy: 0.6600\n",
            "Epoch 147/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5795 - accuracy: 0.7461 - val_loss: 94.5430 - val_accuracy: 0.6533\n",
            "Epoch 148/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5774 - accuracy: 0.7553 - val_loss: 94.8823 - val_accuracy: 0.6467\n",
            "Epoch 149/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6171 - accuracy: 0.7407 - val_loss: 94.5861 - val_accuracy: 0.6533\n",
            "Epoch 150/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5792 - accuracy: 0.7431 - val_loss: 94.3044 - val_accuracy: 0.6600\n",
            "Epoch 151/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6077 - accuracy: 0.7392 - val_loss: 95.1458 - val_accuracy: 0.6533\n",
            "Epoch 152/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.5940 - accuracy: 0.7467 - val_loss: 97.8904 - val_accuracy: 0.6667\n",
            "Epoch 153/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.6053 - accuracy: 0.7299 - val_loss: 98.7130 - val_accuracy: 0.6467\n",
            "Epoch 154/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5574 - accuracy: 0.7749 - val_loss: 99.3846 - val_accuracy: 0.6600\n",
            "Epoch 155/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.5639 - accuracy: 0.7597 - val_loss: 97.5445 - val_accuracy: 0.6667\n",
            "Epoch 156/300\n",
            "83/83 [==============================] - 18s 217ms/step - loss: 0.5897 - accuracy: 0.7424 - val_loss: 99.5133 - val_accuracy: 0.6600\n",
            "Epoch 157/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5813 - accuracy: 0.7519 - val_loss: 98.5795 - val_accuracy: 0.6600\n",
            "Epoch 158/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5837 - accuracy: 0.7420 - val_loss: 98.9887 - val_accuracy: 0.6467\n",
            "Epoch 159/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5814 - accuracy: 0.7579 - val_loss: 98.5617 - val_accuracy: 0.6600\n",
            "Epoch 160/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5729 - accuracy: 0.7580 - val_loss: 96.7449 - val_accuracy: 0.6467\n",
            "Epoch 161/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5721 - accuracy: 0.7568 - val_loss: 96.3601 - val_accuracy: 0.6467\n",
            "Epoch 162/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5919 - accuracy: 0.7484 - val_loss: 97.6338 - val_accuracy: 0.6533\n",
            "Epoch 163/300\n",
            "83/83 [==============================] - 18s 215ms/step - loss: 0.5742 - accuracy: 0.7461 - val_loss: 99.5702 - val_accuracy: 0.6400\n",
            "Epoch 164/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5893 - accuracy: 0.7591 - val_loss: 103.2847 - val_accuracy: 0.6267\n",
            "Epoch 165/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5740 - accuracy: 0.7560 - val_loss: 99.1933 - val_accuracy: 0.6600\n",
            "Epoch 166/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.6074 - accuracy: 0.7396 - val_loss: 101.9700 - val_accuracy: 0.6533\n",
            "Epoch 167/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5780 - accuracy: 0.7674 - val_loss: 103.1997 - val_accuracy: 0.6333\n",
            "Epoch 168/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5878 - accuracy: 0.7558 - val_loss: 99.6762 - val_accuracy: 0.6600\n",
            "Epoch 169/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5545 - accuracy: 0.7733 - val_loss: 96.9844 - val_accuracy: 0.6733\n",
            "Epoch 170/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5578 - accuracy: 0.7709 - val_loss: 97.1003 - val_accuracy: 0.6667\n",
            "Epoch 171/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5484 - accuracy: 0.7653 - val_loss: 94.7729 - val_accuracy: 0.6600\n",
            "Epoch 172/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5630 - accuracy: 0.7579 - val_loss: 94.1814 - val_accuracy: 0.6600\n",
            "Epoch 173/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5629 - accuracy: 0.7620 - val_loss: 95.9297 - val_accuracy: 0.6467\n",
            "Epoch 174/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5673 - accuracy: 0.7526 - val_loss: 97.5999 - val_accuracy: 0.6600\n",
            "Epoch 175/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5799 - accuracy: 0.7677 - val_loss: 98.3489 - val_accuracy: 0.6600\n",
            "Epoch 176/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5692 - accuracy: 0.7700 - val_loss: 100.6393 - val_accuracy: 0.6600\n",
            "Epoch 177/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5935 - accuracy: 0.7387 - val_loss: 101.6166 - val_accuracy: 0.6667\n",
            "Epoch 178/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5618 - accuracy: 0.7567 - val_loss: 100.2593 - val_accuracy: 0.6600\n",
            "Epoch 179/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5601 - accuracy: 0.7642 - val_loss: 98.8789 - val_accuracy: 0.6600\n",
            "Epoch 180/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5862 - accuracy: 0.7586 - val_loss: 98.5519 - val_accuracy: 0.6667\n",
            "Epoch 181/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5607 - accuracy: 0.7675 - val_loss: 104.5410 - val_accuracy: 0.6400\n",
            "Epoch 182/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5405 - accuracy: 0.7749 - val_loss: 102.5889 - val_accuracy: 0.6733\n",
            "Epoch 183/300\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.5965 - accuracy: 0.7361 - val_loss: 96.1006 - val_accuracy: 0.6733\n",
            "Epoch 184/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5539 - accuracy: 0.7780 - val_loss: 100.7625 - val_accuracy: 0.6533\n",
            "Epoch 185/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5507 - accuracy: 0.7677 - val_loss: 98.0385 - val_accuracy: 0.6533\n",
            "Epoch 186/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5562 - accuracy: 0.7686 - val_loss: 100.5493 - val_accuracy: 0.6667\n",
            "Epoch 187/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5810 - accuracy: 0.7597 - val_loss: 97.8973 - val_accuracy: 0.6667\n",
            "Epoch 188/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5770 - accuracy: 0.7615 - val_loss: 99.4536 - val_accuracy: 0.6733\n",
            "Epoch 189/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5593 - accuracy: 0.7567 - val_loss: 98.8519 - val_accuracy: 0.6667\n",
            "Epoch 190/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5509 - accuracy: 0.7661 - val_loss: 98.7051 - val_accuracy: 0.6667\n",
            "Epoch 191/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5342 - accuracy: 0.7832 - val_loss: 104.3126 - val_accuracy: 0.6533\n",
            "Epoch 192/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5654 - accuracy: 0.7713 - val_loss: 99.5881 - val_accuracy: 0.6533\n",
            "Epoch 193/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5467 - accuracy: 0.7727 - val_loss: 99.5506 - val_accuracy: 0.6733\n",
            "Epoch 194/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5579 - accuracy: 0.7731 - val_loss: 101.2523 - val_accuracy: 0.6533\n",
            "Epoch 195/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5652 - accuracy: 0.7656 - val_loss: 98.5123 - val_accuracy: 0.6600\n",
            "Epoch 196/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5580 - accuracy: 0.7593 - val_loss: 99.9222 - val_accuracy: 0.6733\n",
            "Epoch 197/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5399 - accuracy: 0.7745 - val_loss: 98.5056 - val_accuracy: 0.6667\n",
            "Epoch 198/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5638 - accuracy: 0.7629 - val_loss: 96.5543 - val_accuracy: 0.6467\n",
            "Epoch 199/300\n",
            "83/83 [==============================] - 18s 218ms/step - loss: 0.5480 - accuracy: 0.7664 - val_loss: 95.7568 - val_accuracy: 0.6533\n",
            "Epoch 200/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5457 - accuracy: 0.7623 - val_loss: 95.0184 - val_accuracy: 0.6867\n",
            "Epoch 201/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5589 - accuracy: 0.7638 - val_loss: 94.0797 - val_accuracy: 0.6600\n",
            "Epoch 202/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5508 - accuracy: 0.7786 - val_loss: 93.3627 - val_accuracy: 0.6600\n",
            "Epoch 203/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5599 - accuracy: 0.7756 - val_loss: 94.4668 - val_accuracy: 0.6600\n",
            "Epoch 204/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5425 - accuracy: 0.7795 - val_loss: 94.3629 - val_accuracy: 0.6467\n",
            "Epoch 205/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5404 - accuracy: 0.7754 - val_loss: 96.3956 - val_accuracy: 0.6400\n",
            "Epoch 206/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5407 - accuracy: 0.7774 - val_loss: 96.8212 - val_accuracy: 0.6667\n",
            "Epoch 207/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5356 - accuracy: 0.7810 - val_loss: 95.4444 - val_accuracy: 0.6533\n",
            "Epoch 208/300\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.5566 - accuracy: 0.7579 - val_loss: 95.6455 - val_accuracy: 0.6533\n",
            "Epoch 209/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5333 - accuracy: 0.7716 - val_loss: 97.1580 - val_accuracy: 0.6600\n",
            "Epoch 210/300\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.5461 - accuracy: 0.7700 - val_loss: 94.4147 - val_accuracy: 0.6600\n",
            "Epoch 211/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5562 - accuracy: 0.7571 - val_loss: 95.6677 - val_accuracy: 0.6667\n",
            "Epoch 212/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5403 - accuracy: 0.7711 - val_loss: 95.1988 - val_accuracy: 0.6533\n",
            "Epoch 213/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5568 - accuracy: 0.7705 - val_loss: 95.6418 - val_accuracy: 0.6733\n",
            "Epoch 214/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5619 - accuracy: 0.7621 - val_loss: 95.3640 - val_accuracy: 0.6800\n",
            "Epoch 215/300\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.5231 - accuracy: 0.7820 - val_loss: 95.5250 - val_accuracy: 0.6800\n",
            "Epoch 216/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5373 - accuracy: 0.7729 - val_loss: 95.7335 - val_accuracy: 0.6933\n",
            "Epoch 217/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5476 - accuracy: 0.7675 - val_loss: 94.8114 - val_accuracy: 0.6733\n",
            "Epoch 218/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5413 - accuracy: 0.7696 - val_loss: 96.1118 - val_accuracy: 0.6800\n",
            "Epoch 219/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5283 - accuracy: 0.7799 - val_loss: 100.0493 - val_accuracy: 0.6533\n",
            "Epoch 220/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5558 - accuracy: 0.7569 - val_loss: 100.7174 - val_accuracy: 0.6533\n",
            "Epoch 221/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5460 - accuracy: 0.7744 - val_loss: 90.8588 - val_accuracy: 0.6867\n",
            "Epoch 222/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5290 - accuracy: 0.7701 - val_loss: 95.0651 - val_accuracy: 0.6533\n",
            "Epoch 223/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5639 - accuracy: 0.7593 - val_loss: 95.1217 - val_accuracy: 0.6733\n",
            "Epoch 224/300\n",
            "83/83 [==============================] - 18s 223ms/step - loss: 0.5560 - accuracy: 0.7695 - val_loss: 95.4658 - val_accuracy: 0.6533\n",
            "Epoch 225/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5417 - accuracy: 0.7733 - val_loss: 95.3412 - val_accuracy: 0.6533\n",
            "Epoch 226/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5497 - accuracy: 0.7670 - val_loss: 92.9419 - val_accuracy: 0.6733\n",
            "Epoch 227/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5543 - accuracy: 0.7754 - val_loss: 92.3944 - val_accuracy: 0.6600\n",
            "Epoch 228/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5219 - accuracy: 0.7786 - val_loss: 95.1547 - val_accuracy: 0.6533\n",
            "Epoch 229/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5378 - accuracy: 0.7743 - val_loss: 98.1902 - val_accuracy: 0.6467\n",
            "Epoch 230/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5338 - accuracy: 0.7797 - val_loss: 95.3665 - val_accuracy: 0.6600\n",
            "Epoch 231/300\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.5046 - accuracy: 0.8094 - val_loss: 95.1977 - val_accuracy: 0.6533\n",
            "Epoch 232/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5311 - accuracy: 0.7792 - val_loss: 94.5280 - val_accuracy: 0.6467\n",
            "Epoch 233/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5109 - accuracy: 0.7744 - val_loss: 94.2012 - val_accuracy: 0.6800\n",
            "Epoch 234/300\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.5329 - accuracy: 0.7840 - val_loss: 94.4210 - val_accuracy: 0.6867\n",
            "Epoch 235/300\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.5212 - accuracy: 0.7847 - val_loss: 94.4568 - val_accuracy: 0.6533\n",
            "Epoch 236/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5192 - accuracy: 0.7780 - val_loss: 96.8884 - val_accuracy: 0.6533\n",
            "Epoch 237/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5091 - accuracy: 0.7873 - val_loss: 95.3100 - val_accuracy: 0.6600\n",
            "Epoch 238/300\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.5318 - accuracy: 0.7758 - val_loss: 96.4738 - val_accuracy: 0.6667\n",
            "Epoch 239/300\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.5026 - accuracy: 0.8090 - val_loss: 95.6384 - val_accuracy: 0.6800\n",
            "Epoch 240/300\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.5255 - accuracy: 0.7824 - val_loss: 103.4631 - val_accuracy: 0.6533\n",
            "Epoch 241/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5411 - accuracy: 0.7695 - val_loss: 93.0222 - val_accuracy: 0.6800\n",
            "Epoch 242/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5313 - accuracy: 0.7781 - val_loss: 96.8933 - val_accuracy: 0.6600\n",
            "Epoch 243/300\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.5134 - accuracy: 0.7980 - val_loss: 92.8572 - val_accuracy: 0.6800\n",
            "Epoch 244/300\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.5198 - accuracy: 0.7857 - val_loss: 94.6710 - val_accuracy: 0.6800\n",
            "Epoch 245/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5296 - accuracy: 0.7826 - val_loss: 94.0846 - val_accuracy: 0.6667\n",
            "Epoch 246/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.4984 - accuracy: 0.7923 - val_loss: 92.5672 - val_accuracy: 0.6600\n",
            "Epoch 247/300\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.5209 - accuracy: 0.7853 - val_loss: 93.2719 - val_accuracy: 0.6867\n",
            "Epoch 248/300\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.5166 - accuracy: 0.7923 - val_loss: 92.1714 - val_accuracy: 0.6667\n",
            "Epoch 249/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5303 - accuracy: 0.7669 - val_loss: 92.3978 - val_accuracy: 0.6800\n",
            "Epoch 250/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5185 - accuracy: 0.7953 - val_loss: 93.2469 - val_accuracy: 0.6867\n",
            "Epoch 251/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5052 - accuracy: 0.7962 - val_loss: 96.4186 - val_accuracy: 0.6667\n",
            "Epoch 252/300\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.5073 - accuracy: 0.7851 - val_loss: 94.0810 - val_accuracy: 0.6800\n",
            "Epoch 253/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5379 - accuracy: 0.7866 - val_loss: 95.5347 - val_accuracy: 0.6467\n",
            "Epoch 254/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5306 - accuracy: 0.7830 - val_loss: 96.4957 - val_accuracy: 0.6600\n",
            "Epoch 255/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5267 - accuracy: 0.7742 - val_loss: 96.5109 - val_accuracy: 0.6667\n",
            "Epoch 256/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5324 - accuracy: 0.7765 - val_loss: 98.3803 - val_accuracy: 0.6400\n",
            "Epoch 257/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5066 - accuracy: 0.7960 - val_loss: 95.0804 - val_accuracy: 0.6667\n",
            "Epoch 258/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.4933 - accuracy: 0.7988 - val_loss: 93.1945 - val_accuracy: 0.6800\n",
            "Epoch 259/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5348 - accuracy: 0.7851 - val_loss: 95.0108 - val_accuracy: 0.6733\n",
            "Epoch 260/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5028 - accuracy: 0.7886 - val_loss: 95.4084 - val_accuracy: 0.6600\n",
            "Epoch 261/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5118 - accuracy: 0.7912 - val_loss: 95.5519 - val_accuracy: 0.6600\n",
            "Epoch 262/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5048 - accuracy: 0.7953 - val_loss: 94.0775 - val_accuracy: 0.6600\n",
            "Epoch 263/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5326 - accuracy: 0.7896 - val_loss: 92.7467 - val_accuracy: 0.6667\n",
            "Epoch 264/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5110 - accuracy: 0.7965 - val_loss: 93.5254 - val_accuracy: 0.6467\n",
            "Epoch 265/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5393 - accuracy: 0.7839 - val_loss: 94.8517 - val_accuracy: 0.6333\n",
            "Epoch 266/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5185 - accuracy: 0.7877 - val_loss: 96.0137 - val_accuracy: 0.6667\n",
            "Epoch 267/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.5068 - accuracy: 0.8008 - val_loss: 93.9772 - val_accuracy: 0.6533\n",
            "Epoch 268/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5280 - accuracy: 0.7831 - val_loss: 96.5060 - val_accuracy: 0.6733\n",
            "Epoch 269/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5163 - accuracy: 0.7936 - val_loss: 98.3186 - val_accuracy: 0.6600\n",
            "Epoch 270/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5215 - accuracy: 0.7821 - val_loss: 96.4237 - val_accuracy: 0.6600\n",
            "Epoch 271/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5110 - accuracy: 0.7903 - val_loss: 98.2878 - val_accuracy: 0.6667\n",
            "Epoch 272/300\n",
            "83/83 [==============================] - 18s 220ms/step - loss: 0.5172 - accuracy: 0.7876 - val_loss: 97.9069 - val_accuracy: 0.6533\n",
            "Epoch 273/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5142 - accuracy: 0.7893 - val_loss: 95.4259 - val_accuracy: 0.6600\n",
            "Epoch 274/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.5064 - accuracy: 0.7839 - val_loss: 97.6619 - val_accuracy: 0.6333\n",
            "Epoch 275/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5151 - accuracy: 0.7852 - val_loss: 94.5324 - val_accuracy: 0.6733\n",
            "Epoch 276/300\n",
            "83/83 [==============================] - 18s 221ms/step - loss: 0.4953 - accuracy: 0.7895 - val_loss: 95.4258 - val_accuracy: 0.6667\n",
            "Epoch 277/300\n",
            "83/83 [==============================] - 18s 219ms/step - loss: 0.5182 - accuracy: 0.7941 - val_loss: 94.6365 - val_accuracy: 0.6533\n",
            "Epoch 278/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.4882 - accuracy: 0.7949 - val_loss: 94.2782 - val_accuracy: 0.6733\n",
            "Epoch 279/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5110 - accuracy: 0.7877 - val_loss: 93.6609 - val_accuracy: 0.6733\n",
            "Epoch 280/300\n",
            "83/83 [==============================] - 19s 227ms/step - loss: 0.5151 - accuracy: 0.7830 - val_loss: 93.3750 - val_accuracy: 0.6800\n",
            "Epoch 281/300\n",
            "83/83 [==============================] - 20s 235ms/step - loss: 0.5065 - accuracy: 0.7948 - val_loss: 94.5253 - val_accuracy: 0.6467\n",
            "Epoch 282/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5373 - accuracy: 0.7855 - val_loss: 96.6678 - val_accuracy: 0.6400\n",
            "Epoch 283/300\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 0.4903 - accuracy: 0.7960 - val_loss: 97.4604 - val_accuracy: 0.6533\n",
            "Epoch 284/300\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4982 - accuracy: 0.8117 - val_loss: 95.4534 - val_accuracy: 0.6667\n",
            "Epoch 285/300\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.5026 - accuracy: 0.7843 - val_loss: 99.0678 - val_accuracy: 0.6333\n",
            "Epoch 286/300\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4937 - accuracy: 0.7978 - val_loss: 94.7844 - val_accuracy: 0.6600\n",
            "Epoch 287/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5047 - accuracy: 0.8021 - val_loss: 96.2021 - val_accuracy: 0.6400\n",
            "Epoch 288/300\n",
            "83/83 [==============================] - 19s 225ms/step - loss: 0.5102 - accuracy: 0.7925 - val_loss: 93.6273 - val_accuracy: 0.6600\n",
            "Epoch 289/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5085 - accuracy: 0.7770 - val_loss: 94.2996 - val_accuracy: 0.6533\n",
            "Epoch 290/300\n",
            "83/83 [==============================] - 19s 230ms/step - loss: 0.4963 - accuracy: 0.7984 - val_loss: 94.4561 - val_accuracy: 0.6667\n",
            "Epoch 291/300\n",
            "83/83 [==============================] - 19s 229ms/step - loss: 0.4906 - accuracy: 0.7909 - val_loss: 92.5900 - val_accuracy: 0.6733\n",
            "Epoch 292/300\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.5147 - accuracy: 0.7888 - val_loss: 93.4523 - val_accuracy: 0.6467\n",
            "Epoch 293/300\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.5279 - accuracy: 0.7833 - val_loss: 96.3845 - val_accuracy: 0.6400\n",
            "Epoch 294/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5076 - accuracy: 0.7821 - val_loss: 102.8035 - val_accuracy: 0.6467\n",
            "Epoch 295/300\n",
            "83/83 [==============================] - 18s 222ms/step - loss: 0.5090 - accuracy: 0.7939 - val_loss: 94.2746 - val_accuracy: 0.6467\n",
            "Epoch 296/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5154 - accuracy: 0.7845 - val_loss: 96.5833 - val_accuracy: 0.6400\n",
            "Epoch 297/300\n",
            "83/83 [==============================] - 19s 223ms/step - loss: 0.5001 - accuracy: 0.7929 - val_loss: 97.7461 - val_accuracy: 0.6333\n",
            "Epoch 298/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.4957 - accuracy: 0.7927 - val_loss: 95.9955 - val_accuracy: 0.6267\n",
            "Epoch 299/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5144 - accuracy: 0.7886 - val_loss: 96.6207 - val_accuracy: 0.6533\n",
            "Epoch 300/300\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.5135 - accuracy: 0.7932 - val_loss: 94.3011 - val_accuracy: 0.6600\n",
            "Train Accuracy of th9e model is 0.6498784300104203\n",
            "Test Accuracy of the model is 0.66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlJ2wswFfbEW"
      },
      "source": [
        "**Selfmade Model 4**\r\n",
        "\r\n",
        "Very Unstable/ Reaches test Accu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XaSFu_uWMJBG",
        "outputId": "a5b60bf7-23fd-4c71-acfb-149ffc03d807"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((3,3) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(32, activation='relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax')) \r\n",
        "\r\n",
        "#apply learning rate\r\n",
        "opt = optimizers.Adam(learning_rate=0.0001)\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=0.0001,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "#fit call to use the datagen. 100 epichs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 35) ,epochs = 100 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of th9e model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 55, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 55, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 14, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 14, 256)        147712    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 14, 256)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 14, 256)        1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 7, 64)          147520    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 332,931\n",
            "Trainable params: 332,035\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "83/83 [==============================] - 24s 278ms/step - loss: 1.1595 - accuracy: 0.5086 - val_loss: 18.9698 - val_accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.9248 - accuracy: 0.6077 - val_loss: 13.2105 - val_accuracy: 0.5067\n",
            "Epoch 3/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.8394 - accuracy: 0.6397 - val_loss: 17.9669 - val_accuracy: 0.5400\n",
            "Epoch 4/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.8414 - accuracy: 0.6406 - val_loss: 23.8053 - val_accuracy: 0.5600\n",
            "Epoch 5/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.7890 - accuracy: 0.6618 - val_loss: 65.8766 - val_accuracy: 0.5200\n",
            "Epoch 6/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.7407 - accuracy: 0.6681 - val_loss: 109.2531 - val_accuracy: 0.6200\n",
            "Epoch 7/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.7295 - accuracy: 0.6900 - val_loss: 99.7202 - val_accuracy: 0.6067\n",
            "Epoch 8/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.7404 - accuracy: 0.6914 - val_loss: 102.9182 - val_accuracy: 0.5867\n",
            "Epoch 9/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.7088 - accuracy: 0.6908 - val_loss: 89.7212 - val_accuracy: 0.6133\n",
            "Epoch 10/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.7121 - accuracy: 0.6873 - val_loss: 96.2666 - val_accuracy: 0.6200\n",
            "Epoch 11/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.6457 - accuracy: 0.7245 - val_loss: 148.5520 - val_accuracy: 0.5067\n",
            "Epoch 12/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.6601 - accuracy: 0.7143 - val_loss: 136.5076 - val_accuracy: 0.5533\n",
            "Epoch 13/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.6528 - accuracy: 0.7259 - val_loss: 85.7898 - val_accuracy: 0.5933\n",
            "Epoch 14/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.6552 - accuracy: 0.7085 - val_loss: 93.6339 - val_accuracy: 0.6133\n",
            "Epoch 15/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.6448 - accuracy: 0.7223 - val_loss: 64.8637 - val_accuracy: 0.6733\n",
            "Epoch 16/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.6330 - accuracy: 0.7286 - val_loss: 116.9502 - val_accuracy: 0.5800\n",
            "Epoch 17/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.6391 - accuracy: 0.7321 - val_loss: 76.7139 - val_accuracy: 0.6200\n",
            "Epoch 18/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.6238 - accuracy: 0.7294 - val_loss: 94.7399 - val_accuracy: 0.5667\n",
            "Epoch 19/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.6219 - accuracy: 0.7276 - val_loss: 61.9018 - val_accuracy: 0.6467\n",
            "Epoch 20/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.5989 - accuracy: 0.7529 - val_loss: 120.4649 - val_accuracy: 0.6133\n",
            "Epoch 21/100\n",
            "83/83 [==============================] - 29s 346ms/step - loss: 0.5884 - accuracy: 0.7552 - val_loss: 92.5756 - val_accuracy: 0.5800\n",
            "Epoch 22/100\n",
            "83/83 [==============================] - 26s 315ms/step - loss: 0.5761 - accuracy: 0.7585 - val_loss: 86.1801 - val_accuracy: 0.5800\n",
            "Epoch 23/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5780 - accuracy: 0.7520 - val_loss: 65.3962 - val_accuracy: 0.6333\n",
            "Epoch 24/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5968 - accuracy: 0.7532 - val_loss: 85.0652 - val_accuracy: 0.5733\n",
            "Epoch 25/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.5631 - accuracy: 0.7745 - val_loss: 89.0682 - val_accuracy: 0.5800\n",
            "Epoch 26/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5350 - accuracy: 0.7840 - val_loss: 124.6607 - val_accuracy: 0.4467\n",
            "Epoch 27/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5570 - accuracy: 0.7688 - val_loss: 106.2864 - val_accuracy: 0.5600\n",
            "Epoch 28/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5797 - accuracy: 0.7471 - val_loss: 100.4533 - val_accuracy: 0.5667\n",
            "Epoch 29/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5399 - accuracy: 0.7775 - val_loss: 67.7662 - val_accuracy: 0.6267\n",
            "Epoch 30/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.5593 - accuracy: 0.7588 - val_loss: 70.6791 - val_accuracy: 0.5600\n",
            "Epoch 31/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.5545 - accuracy: 0.7682 - val_loss: 147.5534 - val_accuracy: 0.4933\n",
            "Epoch 32/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5554 - accuracy: 0.7637 - val_loss: 67.7467 - val_accuracy: 0.6200\n",
            "Epoch 33/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.5147 - accuracy: 0.7825 - val_loss: 217.5703 - val_accuracy: 0.4933\n",
            "Epoch 34/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.5155 - accuracy: 0.7984 - val_loss: 221.5025 - val_accuracy: 0.4733\n",
            "Epoch 35/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5122 - accuracy: 0.7769 - val_loss: 158.4983 - val_accuracy: 0.5467\n",
            "Epoch 36/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.5286 - accuracy: 0.7813 - val_loss: 289.4769 - val_accuracy: 0.4267\n",
            "Epoch 37/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5156 - accuracy: 0.7862 - val_loss: 95.4817 - val_accuracy: 0.5667\n",
            "Epoch 38/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.5132 - accuracy: 0.7872 - val_loss: 120.8906 - val_accuracy: 0.6000\n",
            "Epoch 39/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.4946 - accuracy: 0.8012 - val_loss: 184.1179 - val_accuracy: 0.4733\n",
            "Epoch 40/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4960 - accuracy: 0.7879 - val_loss: 212.0605 - val_accuracy: 0.5133\n",
            "Epoch 41/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.5099 - accuracy: 0.7887 - val_loss: 127.2745 - val_accuracy: 0.5733\n",
            "Epoch 42/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4893 - accuracy: 0.8030 - val_loss: 159.5540 - val_accuracy: 0.5067\n",
            "Epoch 43/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.5131 - accuracy: 0.7806 - val_loss: 81.8907 - val_accuracy: 0.5933\n",
            "Epoch 44/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.4620 - accuracy: 0.8069 - val_loss: 106.9176 - val_accuracy: 0.5333\n",
            "Epoch 45/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4987 - accuracy: 0.7935 - val_loss: 109.3940 - val_accuracy: 0.5533\n",
            "Epoch 46/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4833 - accuracy: 0.8125 - val_loss: 60.8017 - val_accuracy: 0.6867\n",
            "Epoch 47/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4721 - accuracy: 0.8127 - val_loss: 107.6841 - val_accuracy: 0.5933\n",
            "Epoch 48/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.4736 - accuracy: 0.8076 - val_loss: 92.0108 - val_accuracy: 0.6000\n",
            "Epoch 49/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.4618 - accuracy: 0.8192 - val_loss: 90.6312 - val_accuracy: 0.5933\n",
            "Epoch 50/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.4774 - accuracy: 0.8129 - val_loss: 175.5494 - val_accuracy: 0.5133\n",
            "Epoch 51/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4366 - accuracy: 0.8301 - val_loss: 110.7870 - val_accuracy: 0.5333\n",
            "Epoch 52/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.4833 - accuracy: 0.8003 - val_loss: 116.7065 - val_accuracy: 0.5600\n",
            "Epoch 53/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4982 - accuracy: 0.7988 - val_loss: 70.4426 - val_accuracy: 0.6533\n",
            "Epoch 54/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.4674 - accuracy: 0.8090 - val_loss: 90.4030 - val_accuracy: 0.6267\n",
            "Epoch 55/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.4370 - accuracy: 0.8293 - val_loss: 104.7488 - val_accuracy: 0.5933\n",
            "Epoch 56/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.4578 - accuracy: 0.8186 - val_loss: 80.6356 - val_accuracy: 0.6733\n",
            "Epoch 57/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.4646 - accuracy: 0.8145 - val_loss: 73.1219 - val_accuracy: 0.6067\n",
            "Epoch 58/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.4407 - accuracy: 0.8196 - val_loss: 104.0719 - val_accuracy: 0.5800\n",
            "Epoch 59/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4239 - accuracy: 0.8353 - val_loss: 131.8362 - val_accuracy: 0.5667\n",
            "Epoch 60/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.4328 - accuracy: 0.8388 - val_loss: 90.5940 - val_accuracy: 0.6267\n",
            "Epoch 61/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.4401 - accuracy: 0.8233 - val_loss: 96.2807 - val_accuracy: 0.6200\n",
            "Epoch 62/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.4287 - accuracy: 0.8292 - val_loss: 65.2812 - val_accuracy: 0.6467\n",
            "Epoch 63/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.4286 - accuracy: 0.8267 - val_loss: 85.9010 - val_accuracy: 0.6133\n",
            "Epoch 64/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.4401 - accuracy: 0.8269 - val_loss: 67.0429 - val_accuracy: 0.6867\n",
            "Epoch 65/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.4550 - accuracy: 0.8247 - val_loss: 97.5988 - val_accuracy: 0.6133\n",
            "Epoch 66/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.4446 - accuracy: 0.8170 - val_loss: 71.1994 - val_accuracy: 0.6533\n",
            "Epoch 67/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.4067 - accuracy: 0.8494 - val_loss: 91.4707 - val_accuracy: 0.5867\n",
            "Epoch 68/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.4038 - accuracy: 0.8487 - val_loss: 120.2566 - val_accuracy: 0.5600\n",
            "Epoch 69/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.4270 - accuracy: 0.8310 - val_loss: 235.8524 - val_accuracy: 0.4400\n",
            "Epoch 70/100\n",
            "83/83 [==============================] - 23s 281ms/step - loss: 0.4321 - accuracy: 0.8187 - val_loss: 78.9607 - val_accuracy: 0.6533\n",
            "Epoch 71/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.3901 - accuracy: 0.8494 - val_loss: 81.6358 - val_accuracy: 0.6200\n",
            "Epoch 72/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.4295 - accuracy: 0.8218 - val_loss: 87.9422 - val_accuracy: 0.5600\n",
            "Epoch 73/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.4144 - accuracy: 0.8363 - val_loss: 171.4229 - val_accuracy: 0.5400\n",
            "Epoch 74/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.4043 - accuracy: 0.8485 - val_loss: 148.3781 - val_accuracy: 0.5267\n",
            "Epoch 75/100\n",
            "83/83 [==============================] - 23s 273ms/step - loss: 0.3841 - accuracy: 0.8526 - val_loss: 175.1647 - val_accuracy: 0.4933\n",
            "Epoch 76/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.3971 - accuracy: 0.8506 - val_loss: 380.2657 - val_accuracy: 0.3533\n",
            "Epoch 77/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.4017 - accuracy: 0.8472 - val_loss: 373.8857 - val_accuracy: 0.3533\n",
            "Epoch 78/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.4062 - accuracy: 0.8398 - val_loss: 257.4394 - val_accuracy: 0.4200\n",
            "Epoch 79/100\n",
            "83/83 [==============================] - 23s 279ms/step - loss: 0.3914 - accuracy: 0.8468 - val_loss: 186.7549 - val_accuracy: 0.4933\n",
            "Epoch 80/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.3745 - accuracy: 0.8536 - val_loss: 215.1149 - val_accuracy: 0.4533\n",
            "Epoch 81/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.3896 - accuracy: 0.8451 - val_loss: 188.4995 - val_accuracy: 0.4533\n",
            "Epoch 82/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.3707 - accuracy: 0.8611 - val_loss: 229.3611 - val_accuracy: 0.4333\n",
            "Epoch 83/100\n",
            "83/83 [==============================] - 23s 274ms/step - loss: 0.3722 - accuracy: 0.8620 - val_loss: 140.9548 - val_accuracy: 0.5133\n",
            "Epoch 84/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.3627 - accuracy: 0.8666 - val_loss: 71.4560 - val_accuracy: 0.6400\n",
            "Epoch 85/100\n",
            "83/83 [==============================] - 23s 278ms/step - loss: 0.3695 - accuracy: 0.8645 - val_loss: 133.1943 - val_accuracy: 0.5200\n",
            "Epoch 86/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.3532 - accuracy: 0.8680 - val_loss: 141.0554 - val_accuracy: 0.5200\n",
            "Epoch 87/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.3827 - accuracy: 0.8582 - val_loss: 147.5123 - val_accuracy: 0.5133\n",
            "Epoch 88/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.3581 - accuracy: 0.8606 - val_loss: 172.4088 - val_accuracy: 0.4933\n",
            "Epoch 89/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.3870 - accuracy: 0.8410 - val_loss: 73.6545 - val_accuracy: 0.6267\n",
            "Epoch 90/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.3430 - accuracy: 0.8719 - val_loss: 177.3842 - val_accuracy: 0.4600\n",
            "Epoch 91/100\n",
            "83/83 [==============================] - 23s 275ms/step - loss: 0.3642 - accuracy: 0.8607 - val_loss: 93.0662 - val_accuracy: 0.6467\n",
            "Epoch 92/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.3422 - accuracy: 0.8739 - val_loss: 221.7780 - val_accuracy: 0.4467\n",
            "Epoch 93/100\n",
            "83/83 [==============================] - 23s 278ms/step - loss: 0.3452 - accuracy: 0.8782 - val_loss: 140.5968 - val_accuracy: 0.5400\n",
            "Epoch 94/100\n",
            "83/83 [==============================] - 24s 284ms/step - loss: 0.3377 - accuracy: 0.8718 - val_loss: 265.6121 - val_accuracy: 0.4200\n",
            "Epoch 95/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.3653 - accuracy: 0.8648 - val_loss: 125.7804 - val_accuracy: 0.5733\n",
            "Epoch 96/100\n",
            "83/83 [==============================] - 23s 278ms/step - loss: 0.3531 - accuracy: 0.8688 - val_loss: 123.5851 - val_accuracy: 0.5733\n",
            "Epoch 97/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.3574 - accuracy: 0.8659 - val_loss: 105.3446 - val_accuracy: 0.6000\n",
            "Epoch 98/100\n",
            "83/83 [==============================] - 23s 276ms/step - loss: 0.3643 - accuracy: 0.8519 - val_loss: 335.7040 - val_accuracy: 0.3733\n",
            "Epoch 99/100\n",
            "83/83 [==============================] - 23s 279ms/step - loss: 0.3465 - accuracy: 0.8787 - val_loss: 90.6787 - val_accuracy: 0.6067\n",
            "Epoch 100/100\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.3239 - accuracy: 0.8805 - val_loss: 76.3917 - val_accuracy: 0.6800\n",
            "Train Accuracy of th9e model is 0.653699201111497\n",
            "Test Accuracy of the model is 0.68\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B909AxKgAXp"
      },
      "source": [
        "**Selfmade Model 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70N2txZvWtuH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1cd1d2e6-055b-427f-9c0a-08d70f24763e"
      },
      "source": [
        "# Define our CNN\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(40 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(32, activation='relu'))\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax')) \r\n",
        "\r\n",
        "#apply learning rate\r\n",
        "opt = optimizers.Adam(learning_rate=0.0001)\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=1e-5,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "#fit call to use the datagen. 300 epochs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 35) ,epochs = 300 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of th9e model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 32, 55, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 32, 55, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 32, 55, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 16, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 16, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 8, 14, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 14, 256)        147712    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 8, 14, 256)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 14, 256)        1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 4, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 7, 64)          147520    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 4, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 2, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                8208      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 324,611\n",
            "Trainable params: 323,747\n",
            "Non-trainable params: 864\n",
            "_________________________________________________________________\n",
            "Epoch 1/55\n",
            "90/90 [==============================] - 25s 272ms/step - loss: 1.4180 - accuracy: 0.4348 - val_loss: 11.4708 - val_accuracy: 0.3667\n",
            "Epoch 2/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 1.0691 - accuracy: 0.5484 - val_loss: 30.7662 - val_accuracy: 0.3467\n",
            "Epoch 3/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.9935 - accuracy: 0.5841 - val_loss: 131.9057 - val_accuracy: 0.3333\n",
            "Epoch 4/55\n",
            "90/90 [==============================] - 24s 269ms/step - loss: 0.9369 - accuracy: 0.6084 - val_loss: 44.7045 - val_accuracy: 0.3067\n",
            "Epoch 5/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.9351 - accuracy: 0.5946 - val_loss: 45.8829 - val_accuracy: 0.4067\n",
            "Epoch 6/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.8912 - accuracy: 0.6192 - val_loss: 67.3308 - val_accuracy: 0.3467\n",
            "Epoch 7/55\n",
            "90/90 [==============================] - 24s 269ms/step - loss: 0.8765 - accuracy: 0.6169 - val_loss: 69.5885 - val_accuracy: 0.4067\n",
            "Epoch 8/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.8782 - accuracy: 0.6173 - val_loss: 67.9148 - val_accuracy: 0.4667\n",
            "Epoch 9/55\n",
            "90/90 [==============================] - 24s 272ms/step - loss: 0.8691 - accuracy: 0.6289 - val_loss: 76.8612 - val_accuracy: 0.4867\n",
            "Epoch 10/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.8542 - accuracy: 0.6425 - val_loss: 81.2949 - val_accuracy: 0.4933\n",
            "Epoch 11/55\n",
            "90/90 [==============================] - 24s 269ms/step - loss: 0.8338 - accuracy: 0.6511 - val_loss: 58.8283 - val_accuracy: 0.5333\n",
            "Epoch 12/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.8574 - accuracy: 0.6299 - val_loss: 66.9334 - val_accuracy: 0.5267\n",
            "Epoch 13/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.8198 - accuracy: 0.6613 - val_loss: 55.8317 - val_accuracy: 0.5467\n",
            "Epoch 14/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.7958 - accuracy: 0.6640 - val_loss: 45.9001 - val_accuracy: 0.5933\n",
            "Epoch 15/55\n",
            "90/90 [==============================] - 24s 272ms/step - loss: 0.7910 - accuracy: 0.6525 - val_loss: 66.5902 - val_accuracy: 0.5333\n",
            "Epoch 16/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.8034 - accuracy: 0.6574 - val_loss: 43.3056 - val_accuracy: 0.5533\n",
            "Epoch 17/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.8200 - accuracy: 0.6529 - val_loss: 58.0811 - val_accuracy: 0.5133\n",
            "Epoch 18/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.7608 - accuracy: 0.6886 - val_loss: 49.1462 - val_accuracy: 0.5600\n",
            "Epoch 19/55\n",
            "90/90 [==============================] - 25s 272ms/step - loss: 0.7738 - accuracy: 0.6644 - val_loss: 41.9295 - val_accuracy: 0.5733\n",
            "Epoch 20/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.7596 - accuracy: 0.6732 - val_loss: 42.0712 - val_accuracy: 0.5667\n",
            "Epoch 21/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.7758 - accuracy: 0.6550 - val_loss: 96.2885 - val_accuracy: 0.4733\n",
            "Epoch 22/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.7561 - accuracy: 0.6802 - val_loss: 53.1877 - val_accuracy: 0.5800\n",
            "Epoch 23/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.7304 - accuracy: 0.6982 - val_loss: 59.3632 - val_accuracy: 0.5267\n",
            "Epoch 24/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.7566 - accuracy: 0.6730 - val_loss: 43.8047 - val_accuracy: 0.5867\n",
            "Epoch 25/55\n",
            "90/90 [==============================] - 24s 272ms/step - loss: 0.7089 - accuracy: 0.6959 - val_loss: 50.9662 - val_accuracy: 0.5600\n",
            "Epoch 26/55\n",
            "90/90 [==============================] - 24s 272ms/step - loss: 0.7548 - accuracy: 0.6780 - val_loss: 40.2261 - val_accuracy: 0.6333\n",
            "Epoch 27/55\n",
            "90/90 [==============================] - 25s 274ms/step - loss: 0.7157 - accuracy: 0.6796 - val_loss: 49.1377 - val_accuracy: 0.6400\n",
            "Epoch 28/55\n",
            "90/90 [==============================] - 25s 273ms/step - loss: 0.7188 - accuracy: 0.7091 - val_loss: 47.2041 - val_accuracy: 0.5800\n",
            "Epoch 29/55\n",
            "90/90 [==============================] - 24s 272ms/step - loss: 0.6952 - accuracy: 0.7095 - val_loss: 63.1676 - val_accuracy: 0.5133\n",
            "Epoch 30/55\n",
            "90/90 [==============================] - 25s 272ms/step - loss: 0.7392 - accuracy: 0.6805 - val_loss: 95.9089 - val_accuracy: 0.5067\n",
            "Epoch 31/55\n",
            "90/90 [==============================] - 25s 273ms/step - loss: 0.7046 - accuracy: 0.6958 - val_loss: 92.8097 - val_accuracy: 0.4933\n",
            "Epoch 32/55\n",
            "90/90 [==============================] - 25s 273ms/step - loss: 0.6967 - accuracy: 0.7110 - val_loss: 109.7275 - val_accuracy: 0.4800\n",
            "Epoch 33/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6708 - accuracy: 0.7253 - val_loss: 117.6421 - val_accuracy: 0.4667\n",
            "Epoch 34/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6815 - accuracy: 0.7114 - val_loss: 112.5977 - val_accuracy: 0.4733\n",
            "Epoch 35/55\n",
            "90/90 [==============================] - 25s 273ms/step - loss: 0.6777 - accuracy: 0.7110 - val_loss: 152.7398 - val_accuracy: 0.5000\n",
            "Epoch 36/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.6850 - accuracy: 0.7092 - val_loss: 192.9547 - val_accuracy: 0.4067\n",
            "Epoch 37/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6698 - accuracy: 0.7281 - val_loss: 66.1872 - val_accuracy: 0.5800\n",
            "Epoch 38/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6620 - accuracy: 0.7265 - val_loss: 47.1157 - val_accuracy: 0.6200\n",
            "Epoch 39/55\n",
            "90/90 [==============================] - 24s 272ms/step - loss: 0.6938 - accuracy: 0.7110 - val_loss: 83.7655 - val_accuracy: 0.5467\n",
            "Epoch 40/55\n",
            "90/90 [==============================] - 24s 272ms/step - loss: 0.6552 - accuracy: 0.7222 - val_loss: 43.1902 - val_accuracy: 0.6133\n",
            "Epoch 41/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6638 - accuracy: 0.7158 - val_loss: 75.3695 - val_accuracy: 0.5600\n",
            "Epoch 42/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6684 - accuracy: 0.7024 - val_loss: 59.2045 - val_accuracy: 0.5667\n",
            "Epoch 43/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6424 - accuracy: 0.7279 - val_loss: 89.6339 - val_accuracy: 0.5533\n",
            "Epoch 44/55\n",
            "90/90 [==============================] - 24s 272ms/step - loss: 0.6361 - accuracy: 0.7266 - val_loss: 35.4058 - val_accuracy: 0.6000\n",
            "Epoch 45/55\n",
            "90/90 [==============================] - 24s 269ms/step - loss: 0.6453 - accuracy: 0.7290 - val_loss: 121.2577 - val_accuracy: 0.4133\n",
            "Epoch 46/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6525 - accuracy: 0.7274 - val_loss: 89.1779 - val_accuracy: 0.4733\n",
            "Epoch 47/55\n",
            "90/90 [==============================] - 25s 272ms/step - loss: 0.6481 - accuracy: 0.7233 - val_loss: 145.4242 - val_accuracy: 0.4533\n",
            "Epoch 48/55\n",
            "90/90 [==============================] - 25s 272ms/step - loss: 0.6330 - accuracy: 0.7257 - val_loss: 63.0447 - val_accuracy: 0.5400\n",
            "Epoch 49/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6202 - accuracy: 0.7350 - val_loss: 62.5545 - val_accuracy: 0.5600\n",
            "Epoch 50/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6372 - accuracy: 0.7193 - val_loss: 123.3799 - val_accuracy: 0.4467\n",
            "Epoch 51/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6277 - accuracy: 0.7335 - val_loss: 120.3395 - val_accuracy: 0.4867\n",
            "Epoch 52/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6116 - accuracy: 0.7407 - val_loss: 92.5027 - val_accuracy: 0.4667\n",
            "Epoch 53/55\n",
            "90/90 [==============================] - 24s 270ms/step - loss: 0.6054 - accuracy: 0.7514 - val_loss: 175.6936 - val_accuracy: 0.4600\n",
            "Epoch 54/55\n",
            "90/90 [==============================] - 24s 271ms/step - loss: 0.6186 - accuracy: 0.7381 - val_loss: 81.2568 - val_accuracy: 0.5533\n",
            "Epoch 55/55\n",
            "90/90 [==============================] - 24s 269ms/step - loss: 0.6230 - accuracy: 0.7223 - val_loss: 82.6482 - val_accuracy: 0.5333\n",
            "Train Accuracy of the model is 0.5866620354289684\n",
            "Test Accuracy of the model is 0.5333333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3zU5f3A389l74QMQgIhYU9lyRAHOCoynK17tm6taJfWttYOrR0/q9ZVtVpXRepERKmDqYAQQGYgAzKB7L1zz++P577Jkdwll+QuN/K8X6+8bnzX55Lc9/N8tpBSotFoNJrBi8ndAmg0Go3GvWhFoNFoNIMcrQg0Go1mkKMVgUaj0QxytCLQaDSaQY5WBBqNRjPI0YpAM6gQQvxbCPFHB/c9KoQ4z9UyaTTuRisCjUajGeRoRaDReCFCCH93y6DxHbQi0HgcFpfMz4UQe4QQdUKIfwkhhgohPhVC1AghvhBCxFjtf5EQYr8QolIIsV4IMdFq23QhxE7Lce8AwZ2utVQIsdty7DdCiFMclHGJEGKXEKJaCJEvhHik0/YzLOertGy/yfJ+iBDi/4QQuUKIKiHEZst7C4QQBTZ+D+dZnj8ihHhXCPGmEKIauEkIMVsIscVyjWNCiGeEEIFWx08WQnwuhCgXQpwQQjwkhEgUQtQLIWKt9pshhCgRQgQ48tk1vodWBBpP5XLgfGAcsAz4FHgIiEf9394LIIQYB7wN3GfZtgb4WAgRaLkpfgi8AQwB/ms5L5ZjpwOvALcDscA/gVVCiCAH5KsDbgCigSXAnUKISyznHWmR9x8WmaYBuy3H/Q2YCZxukekXgNnB38nFwLuWa74FtAH3A3HAPOBc4C6LDBHAF8BnQBIwBvhSSnkcWA9cYXXe64EVUsoWB+XQ+BhaEWg8lX9IKU9IKQuBTcA2KeUuKWUj8AEw3bLflcAnUsrPLTeyvwEhqBvtXCAAeFJK2SKlfBfYbnWN24B/Sim3SSnbpJSvAU2W47pFSrleSrlXSmmWUu5BKaOzLZuvAb6QUr5tuW6ZlHK3EMIE/BBYLqUstFzzGyllk4O/ky1Syg8t12yQUqZLKbdKKVullEdRisyQYSlwXEr5f1LKRilljZRym2Xba8B1AEIIP+BqlLLUDFK0ItB4KiesnjfYeB1ueZ4E5BobpJRmIB9ItmwrlCd3Vsy1ej4S+KnFtVIphKgERliO6xYhxBwhxDqLS6UKuAO1Msdyjmwbh8WhXFO2tjlCficZxgkhVgshjlvcRY85IAPAR8AkIUQayuqqklJ+20eZND6AVgQab6cIdUMHQAghUDfBQuAYkGx5zyDF6nk+8KiUMtrqJ1RK+bYD1/0PsAoYIaWMAl4AjOvkA6NtHFMKNNrZVgeEWn0OP5RbyZrOrYKfBzKAsVLKSJTrzFqGUbYEt1hVK1FWwfVoa2DQoxWBxttZCSwRQpxrCXb+FOXe+QbYArQC9wohAoQQlwGzrY59CbjDsroXQogwSxA4woHrRgDlUspGIcRslDvI4C3gPCHEFUIIfyFErBBimsVaeQV4QgiRJITwE0LMs8QkDgPBlusHAL8GeopVRADVQK0QYgJwp9W21cAwIcR9QoggIUSEEGKO1fbXgZuAi9CKYNCjFYHGq5FSHkKtbP+BWnEvA5ZJKZullM3AZagbXjkqnvC+1bE7gFuBZ4AKIMuyryPcBfxeCFEDPIxSSMZ584DFKKVUjgoUn2rZ/DNgLypWUQ78GTBJKass53wZZc3UASdlEdngZygFVINSau9YyVCDcvssA44DmcBCq+1fo4LUO6WU1u4yzSBE6ME0Gs3gRAjxFfAfKeXL7pZF4160ItBoBiFCiNOAz1Exjhp3y6NxL9o1pNEMMoQQr6FqDO7TSkAD2iLQaDSaQY+2CDQajWaQ43WNq+Li4mRqaqq7xdBoNBqvIj09vVRK2bk2BfBCRZCamsqOHTvcLYZGo9F4FUIIu2nC2jWk0Wg0gxytCDQajWaQoxWBRqPRDHK8LkZgi5aWFgoKCmhsbHS3KC4lODiY4cOHExCg54doNBrn4ROKoKCggIiICFJTUzm50aTvIKWkrKyMgoIC0tLS3C2ORqPxIXzCNdTY2EhsbKzPKgEAIQSxsbE+b/VoNJqBxycUAeDTSsBgMHxGjUYz8PiMItBoNBpvR0rJFwdO8HVW6YBeVysCJ1BZWclzzz3X6+MWL15MZWWlCyTSaDTexsFj1Vz90lZueX0HN736Ldtyygbs2loROAF7iqC1tbXb49asWUN0dLSrxNJoNB5CaW0TVQ0tNreV1zXz6w/3suTpTWQcr+G3yyYxYkgot7+ZTm5Z3YDI5xNZQ+7mwQcfJDs7m2nTphEQEEBwcDAxMTFkZGRw+PBhLrnkEvLz82lsbGT58uXcdtttQEe7jNraWi688ELOOOMMvvnmG5KTk/noo48ICQlx8yfTaDT9paiygfOe2EB9cxtDI4MYNzSCMQnhjE2IoK6plX98lUldcxs3zEvlvvPGEh0ayMLxCVzy3Nf88N/bef+u+USFuDZl3OcUwe8+3s+BomqnnnNSUiS/XTbZ7vbHH3+cffv2sXv3btavX8+SJUvYt29fe5rnK6+8wpAhQ2hoaOC0007j8ssvJzY29qRzZGZm8vbbb/PSSy9xxRVX8N5773Hdddc59XNoNJqB5y+fZdBqlvzse+M4UlpPZnEN72zPp765DYAzxsTx8LJJjBvaMSo7NS6MF66byfX/2sY9/9nJKzedRoCf6xw4PqcIPIHZs2eflOv/9NNP88EHHwCQn59PZmZmF0WQlpbGtGnTAJg5cyZHjx4dMHk1Go1r2J1fyYe7i7h74WjuOWds+/tms6SoqoHqhlYmDouwmRE4d1Qsj146lV+8u4fffbyfP1w8xWWZgz6nCLpbuQ8UYWFh7c/Xr1/PF198wZYtWwgNDWXBggU2awGCgoLan/v5+dHQ0DAgsmo0GkVjSxuHjtcwOiGc8KD+3xqllPxh9QHiI4K4c8GYk7aZTILhMaEQ0/05rpg1guySWv65IYcx8eHcNN81xaQ+pwjcQUREBDU1tif+VVVVERMTQ2hoKBkZGWzdunWApdNoND3R0NzGVS9t5bt8lcWXFhfGpKRIJidFMjkpijlpQwgO8OvVOVfvOUZ6bgV/vnxqvxTLAxdM4EhJHb9ffYCRcWEsHJ/Q53PZQysCJxAbG8v8+fOZMmUKISEhDB06tH3bokWLeOGFF5g4cSLjx49n7ty5bpRUo/FOmlrbWH+ohA93FbI5s5Rl05J4eOmkXt+cbWE2S36ycjd7Cip5aPEEmlrM7C+qZk9BJZ/sOQbAqLgwnrpqOlOHRzl0zsaWNh7/NIOJwyL5/swR/ZLPZBI8edU0bn8j3SmWii28bmbxrFmzZOfBNAcPHmTixIlukmhgGUyfVTO4MZsl6XkVfLCrkE/2HKOqoYW48ECmp8Tw+YETTEiM4NlrZzA6PtzuOWqbWgnwEwT521cYj605yIsbc/j1konccuaok7ZV1bew9UgZj6zaT2ltEz+/YDy3nDEKk6l7X/1z67P4y2eH+M8tczh9TFzvPriLEEKkSyln2dqmLQKNRuNxlNY2cfsb6aTnVhAS4McFk4dyyfRkzhgTh7+fiXWHivnpyu9Y9o/NPHrpFC6dPrz9WCklO/MqeGNLLmv2Hic6NIBfL53EslOGdQm2vrk1lxc35nD93JH86Iyu/veo0AAumJzInLQhPPjeXh5bk8HGw6X83xWnMjQy2KbsJTVNPLcum/MmDvUYJdATWhFoNBqPIqu4hpv/vZ3i6iYevXQKl0xLJqyTS2Th+ATW3Hsm9769i/vf+Y4t2WU8sGgCa/ef4I2tuRw8Vk1EkD9XnjaCXfkV3Pv2LlZ8m8fvL57CmARlQaw/VMxvV+1n4fh4frtsUrcZOdGhgTx/3Qze2Z7P7z4+wKInN/Kny07hvIkJ+HdK63zi80M0trTx0OIJzv/luAitCDQaTY+U1jbxwvpsJg6L5LIZyd3eNKWUrNyRz77CauaNjmX+6DiiQh0riPo6q5Q73kwnyN+Pd26fx7QR9ivvE6OC+c+tc3jyi0yeXZ/Fyh0FAExIjOCxS6dy8bQkwoL8aTNL3tqWy1/XHuLCpzZy65mjOHfiUO5+ayfjh0bwzDUzutzMbSGE4KrZKcxKHcLyFbu44810Av1MjIoPY0xCOOOGRhAbHsg72/O56fQ0RnXjsvI0dIzAyxhMn1Xjfppbzby+5ShPfZFJTZNqmbLklGE8dslUmzf3stomfvHuHr7MKCbQz0RzmxmTgGkjojlzbDxnjYtnSnKkTZ/9O9vz+NUH+xgdH86/bpql0isd5OusUr7KKGbx1ERmpMTYVFQlNU386dODvL+zEIDEyGA+vHs+iVG2XTzd0dTaxqd7j5NxvIbMEzVkFteSX1GPlBAdGsD6ny0gOjSw1+d1Jd3FCLQi8DIG02fVuJd1h4r5w+oD5JTUcfa4eH69ZCKfHzzBE/87zNDIYP5+5TRmpw1p339TZgk/WfkdVfUt/HLxBK6dM5LvCirZdLiEDZml7CmoRErwMwlGxoYy1rKKHpMQzv6ial7cmMOZY+N49toZRAa7rqXCtpwyXttylB+fM5aJwyKddt6G5jayimuJCgkgJdZxJTZQaEXgQwymz6rpHfnl9Xy4q5CjZfVcNXsEp6UO6fkgK9rMkvzyeg6fqGHF9ny+yigmLS6M3yydyMLxCe2r7O/yK1m+Yhd55fXcs3AMdy4Yw9+/OMyLG3MYmxDOU1dNZ1JS1xtsRV0zW3LKOHismswTtRwuriG3rJ42s7oHXTMnhd9fNNkhN42m92hF4GGEh4dTW1vbp2O97bNqnIOU0qa7o6KumU/2HuPDXYXsyK0AIDzIn9qmVmaNjOHOBaM5Z0JCl2ObWtv4Lr+KHbnlHDpeQ+aJWrJLamlqNbef495zx3DT6WkE+ne9Mdc2tfLIqv28m15AWKAfdc1tXDc3hV8tnkRIoOO5/U2tbRwtrae+uZVpI6L18CUXotNHNRovpaaxhbve2sk32WWEB/kTHuRPRLD6MQnBzrwKWtok44aG88CiCVw0LYkhoYG8sz2PlzYd4Uev7WD80AjuXDCaYVHBbM0pZ9uRMtJzK9pv+snRIYwdGs78MbGMTYhg7FDlsumcqWNNeJA/f/vBqZw9Lp6XNx/h7gWj+d7kxF5/viB/P8YnRvS8o8alaEXgBB588EFGjBjB3XffDcAjjzyCv78/69ato6KigpaWFv74xz9y8cUXu1lSjTdRVd/CDa9+y/7CKq6fOxKA6sYWahtbqW1qpb65jZvnp3HJtOQujctump/GtXNH8vF3RTy/Ppv73tkNgBAwaVgk184ZydxRQ5idNqRfQc1lpyax7NSk/n1QjdvxPdfQpw/C8b3OvWjiVLjwcbubd+3axX333ceGDRsAmDRpEmvXriUqKorIyEhKS0uZO3cumZmZCCG0a0jTI+V1zVz38jayimt59toZnD9paM8H2cFslmzKKqW51czs1CEOp3JqfAu3uYaEEIuApwA/4GUp5eOdtv8dWGh5GQokSCm9bmTX9OnTKS4upqioiJKSEmJiYkhMTOT+++9n48aNmEwmCgsLOXHiBImJvTefNYOL4ppGrnt5G7ll9bx04yzOHhffr/OZTKLf59D4Ni5TBEIIP+BZ4HygANguhFglpTxg7COlvN9q/x8D0/t94W5W7q7kBz/4Ae+++y7Hjx/nyiuv5K233qKkpIT09HQCAgJITU212X5a41s0trSRX15Pblk9R8vqyCuvZ2RsGD+cn+pQIPRYVQPXvrSN49WNvHrzaZw+2jtaFGi8G1daBLOBLCllDoAQYgVwMXDAzv5XA791oTwu5corr+TWW2+ltLSUDRs2sHLlShISEggICGDdunXk5ua6W0SNCzlSWsePXttOTsnJM2ZDAvxoaGmjqLKBXy+Z2K0yyC2r47p/baOiroXXfzibWb1M/9Ro+oorFUEykG/1ugCYY2tHIcRIIA34ys7224DbAFJSUpwrpZOYPHkyNTU1JCcnM2zYMK699lqWLVvG1KlTmTVrFhMmeE/fEU3veXFjNkWVDdx/3jhGxoZafsKICQ3gdx8f4F+bj+DvJ3hw0QSbymBLdhl3vpUOwFu3zOHUbloraDTOxlOyhq4C3pVSttnaKKV8EXgRVLB4IAXrDXv3dgSp4+Li2LJli839+hoo1ngmVfUtfLCrkEumJbP8vLFdtv922SRa2sz8c0MOgX4mfvq98Sdt/8+2PB7+aB+pcWH868ZZjIwN63IOjcaVuFIRFALWExmGW96zxVXA3S6URaNxGf9Nz6exxcz180ba3C6E4A8XT6HNLPnHV1kE+Jm499yxtLaZ+eMnB/n3N0dZOD6ep66e7tLWChqNPVypCLYDY4UQaSgFcBVwTeedhBATUJM7bS+fNZoBwGyWPQ4bsXfcG1tzOS01hslJ9qdXmUyCxy6dSkub5InPD9NqluzMrWBzVim3npnGgxdOxK8P19donIHLFIGUslUIcQ+wFpU++oqUcr8Q4vfADinlKsuuVwErZD8LGuyV4PsS3lbz4S18k1XKD1/bztTkKC6ZnsySqcMcLrLakFlCblk9P+vk7rGFyST4y/dPodVs5ukvMwnwU6+vmNW/UYYaTX/xiYKyI0eOEBERQWxsrM8qAyklZWVl1NTUkJbWdZKSpm/kl9dz0TObiQgOINDfRFZxLQF+goXjE7h0ejILJyR0Oxf35le/ZX9RNZsfOMdmTx5btLaZeXFTDnPSYpk5MsZZH0Wj6Raf7zU0fPhwCgoKKCkpcbcoLiU4OJjhw4f3vKOGstom9hRUsWB8vN3FQUNzG7e9kU6rWfLvm08jLS6M/UXVfLirkI++K+J/B06QHB3Cu3fOY1hUSJfjj5bWsf5wCfeeM9ZhJQDg72firgVj+vzZNBpn4xOKICAgQK+SNe3sK6zittd3UFTVyOKpifzl+6cS3qmBmpSSX7y3h4zj1bxy42nt06SmJEcxJTmKXy6eyIbDxdz79m5++O8d/PeOeV3O8ebWXPyE4Jo5npnSrNE4im78rfEpPt17jB+8sAUJ3H72KNbuP8FFz2zm8Imak/Z7cWMOH39XxM++N56FExK6nMfPJDhnwlCevXYGh0/UcM9/dtLaZm7fXt/cysod+Syakmh3iLlG4y1oRaDxCaSUPP1lJne+tZMJwyL46J75/PLCibx1yxyqG1q5+Jmv+Wi3yl7ecLiEP3+WweKpidy1YHS35z17XDx/uHgK6w+V8MjH+9sD9h/tLqK6sZUbT0919UfTaFyOT7iGNIObhuY2fv7ud6zec4zLpifz2GVT2wO8c0fFsubeM7jnP7tYvmI3mzNLWbv/OOOGRvDX75/qUHLBNXNSyC2v458bchg5JIxbzkzj9S25TBwWySwd7NX4AFoRaLyagop67nxzJ/uKqnjwwgncftaoLjf3hMhg3rp1Dn9de4gXN+YQFRLAi9fP6nbwSmceuGAC+eX1PPbpQUpqmzh4rJo/XTbVZ7PUNIMLrQg0A8K6jGIOnajhljPSnDaTdsPhEpav2EVbm+Sl62dxXjc9+wP8TDy0eCILxsczJCyw18PFTSbBE1dM41jVVl7cmENksD8XT9MDWTS+gVYEGpezr7CKO95Mp6nVzFcZxTxz9XQS+hFgNZslT3+VyVNfZjJ+aATPXzeTtDjH+vP0p61zcIAfL90wixv+9S1LTx1GaKD++mh8A58oKNN4LhV1zSz9x2bMUnLXgtE8tiaD8GB/nrl6OnNGxfbpfPe9s5sNh0u4bHoyj146tVfD0p3BYKhi1/gePl9QpvFM2sySe1fsoqSmiZV3zGPaiGhmp8Vy55vpXPPyNh5cNIFbzkxrv6mW1jaxObOUjYdLOHCsmsjgAIaEBRIbHkhsWCCRIQG8+vVRSmqaePTSKVwzO8UtN2StBDS+hlYEmh4prm7kWFUjk5IiCeiFf/+Jzw+xKbOUxy+byjRLf/3xiSq18+f/3cOjaw6yI7ecUfHhbMosYV9hNQAxoQFMGxFNfXMb2SW1fHu0mYr6ZqSE5OgQ/nvHPN2vX6NxIloRaGxS29TK2n3H+XB3IV9nlWKWEBHkz7zRsZw1Lp6zx8UzYoj9gOva/cd5dl02V502gqtmn1x5GxEcwPPXzeDlTUd4/LMMxMFiZqTE8LPvjeOscfFMTorq0omzzSyprG9u7wmk0Wich44RDFK+PVLO4RM1BPqbCPI3EehnItDfRFOrmc/2Hed/B47T2GJmxJAQLpmWzNihEWzJLmXj4VIKKxsASIsLY07aEGakxDA9JZrR8eGYTILskloufuZrRseH8c7t87pt2lZc00hIgB8Rug+/RuNSdIxA005dUyt//OQgb3+bZ3ef6NAAvj9zOJdOT2ZGSky7T/yiU5OQUpJTWsfGwyVsyixlzd5jrNiuJpJGBPszbUQ0eeX1BPqbeP66md0qAYCECN2eQaNxN1oRDCLSc8v5ycrvyCuv5/azR3Hz6Wm0tJlpbjPT3Kp+zFIyOSnKrvtFCMHo+HBGx4dz8/w0zGalGHblVbAzr5JdeRWU1jTx0g2zSIru2rFTo9F4HloRDAKaW838/YvD/HNDNskxIbxz2zxmpw1xyrlNJsGYhHDGJITzAz1gRaPxSrQi8HGOlNZx11s7OXismitnjeA3yyZ1aaes0WgGN/qO4MMcOl7DtS9vwywlL90wi/O7acGg0WgGL1oR+Cj7Cqu4/l/bCPQ3seKWeYxJCHe3SBqNxkPRCdk+yK68Cq55aSuhgf6svF0rAadTXw6tTe6WQqNxGtoi8AJa28xkHK9hV14Fu/Iq2ZVfSaCfiUVTEllyyjDGDY1o33f70XJufnU7seGBvHXLHIbH9K7LpqYbao7Dhr/Aztdgzh1wwaPulkijcQpaEXgwGw+X8Nz6LL7Lr6KhpQ2AuPAgZqREU9XQ0t6Bc0xCOIunJJIaF8avPthHUnQwb90yl8QonaPvFBoq4eunYOvzYG6BoEg4usndUmk0TkMrAg+kurGFR1cf5J0d+aQMCeXK00YwPSWaGSkxDI8JaS/wKq5pZO2+43yy9xjPrMvCLGFCYgRv/GgO8RFBbv4UPkBLI2x7HjY/CY2VMPUHsPAh2PkGfPM0tDRAgK6V0Hg/WhF4GOsOFfPQ+3s5Ud3IHWeP5r7zxtqtzk2ICOb6ealcPy+Vkpomvs4qZcH4eKJDAwdYah9l8xOw4c8w9gI49zeQOFW9nzwTzK1wfC+MmO1eGTUaJ6AVgYdQVd/CHz45wLvpBYxNCOf5u+a3d+x0hPiIIC6ZnuxCCQchBdth2Klw7cqT30+eoR4Ld2pFoPEJtCJwM2az5MPdhTz+aQZldc3cvXA09547liD/gR22orFB8UEYtbDr+5FJEDEMCtMHXiaNxgVoReBGdudX8siq/ezOr+TUEdH868bTmDo8yt1iaUCliNYcg4SJtrcnz9SKQOMzaEXgBoqrG/nzZ4d4b2cB8RFB/O0Hp3LZ9GRMJj35ymMoyVCPCZNsb0+aDhmroaECQmIGTi6NxgVoRTAASCk5WlbPrrwK0nMr+HBXIS1tkjvOHs0954zRvX88keID6rE7iwCgaBeMPmdgZHI3tSUQFK4zpXwQfQdyEU2tbfz766NsO1LOrrwKKupbAAgP8mfB+AR+fsF4UuPC3Cylxi7FB1W9QGSS7e1J09VjYfrgUARtrfDCGTDlclj0mLul0TgZrQhcxNNfZvLsumzGJIRz/qShTE+JYUZKDGMSwruMYdR4IMUHlTVgb1B9SDTEjoHCXQMrl7vI/Rpqj+u4iI+iFYELOFJax0sbj3DZjGSeuGKau8XR9BYplSKYdFH3+yXPhJz1an97CsNXyPhEPRYfdOzzNtWogrzweNfLpuk3uumck5FS8ruP9xPob+LBCye4WxxNX6gthoZy+4Fig+SZUHsCqosGRi53IaVSBCZ/aKpy7PN++iC8usj1smmcglYETubLg8WsP1TCfeeN1fN4vZWeAsUGSZbCsqKdrpXH3RzbDdUFcOpV6nXxwZ6PKfgWyrKgMt+1smmcglYETqSxpY3frd7P2IRwbjw91d3iaPqKcaPrySJInKpWyb7uNz+4GoQJ5t+vXhuK0h7NdVCaqZ7nb3OtbBqn4FJFIIRYJIQ4JITIEkI8aGefK4QQB4QQ+4UQ/3GlPK7mxY055Jc38LuLJhPgp3Ws11J8AMLiISyu+/0CgmHoFN9XBBmfwMj5EDcGwhN7tghOHACkep77jcvF0/Qfl92thBB+wLPAhcAk4GohxKRO+4wFfgnMl1JOBu5zlTyuJr+8nmfXZbHklGGcPqaHG4jGszEyhhwheQYU7Qaz2bUyuYuybCg5CBOWqtcJE3u2CI7vUY9x4yFvq2vl0zgFVy5bZwNZUsocKWUzsAK4uNM+twLPSikrAKSUxS6Up99knqjh5U057C+qwmyWJ2179JODmITgV4sdvIFoPBOzWVUV9+QWMkieCU3Vyh/ui2SsVo8TFqvHhElQcqh7xXd8DwRHw9TvK6XRUOFcmcqyoa3Fuecc5LgyfTQZsI4UFQBzOu0zDkAI8TXgBzwipfys84mEELcBtwGkpKS4RNieqG5s4YevbSe/vAFQA2LOHBvHWePi8DOZ+Gz/cX5+wXiSonXVpVdTlQ/Ntb2wCCwVxoXpED/OdXK5i4OrVQfWaMv3LmEitDZA5VEYMsr2Mcf3qvhJyjxAQv63MO4C58hTmQfPnAaXPNcRvNb0G3fXEfgDY4EFwHBgoxBiqpSy0nonKeWLwIsAs2bNkp1P4mqklPz6g30UVTby0g2zqG5oYWNmCRsOl/DBrkIAUmNDueXMtIEWTeNsHA0UG8SNg4AwlTk07WrXyeUOao6rVtwLH+p4z/i9FB+0rQjaWuHEfjjtFqUkTQGQt8V5iiDrS5BtUFXgnPNpANcqgkJghNXr4Zb3rCkAtkkpW4AjQojDKMWw3YVy9Zr3dhay6rsifnr+OM6fNBSAy2cOx2yWHDhWzTfZpcwfE+cbraNPHOi+otbXMfzf8eMd29/kp9pN+GLA+NAaQHbEB6Dj91J8ANHNIe0AACAASURBVCYs6XpMeTa0NiqLIDAUkqZB7hbnyZSzTj062900yHFljGA7MFYIkSaECASuAlZ12udDlDWAECIO5SrKcaFMvSanpJaHP9rHnLQh3LVwzEnbTCbBlOQobjtrNJOTfKB9dGE6PD+vo4p0MFJ8ECKHQ3Av/p7JM5Q7pLXZdXK5g4xPICbtZDdZUDhEj7SfOXTMEig2prmlzFXWUktj/+Uxt0HOBvW8sbL7fTW9wmWKQErZCtwDrAUOAiullPuFEL8XQhi1+2uBMiHEAWAd8HMpZZmrZOotza1mlq/YTaC/iSevmub7PYIyP1ePeU5cwXkbJb3IGDJIngFtzXBin2tkcgeNVeqmO3FpV+swYaJ9RXB8D/gFKZcZQMrp6ndT5ISeTMd2dyiABq0InIlLYwRSyjXAmk7vPWz1XAI/sfx4HH/73yH2Flbxz+tnMixqEASBsy1md6EPV8pWFYB/CITFdt3W1golh21PJesO64CxMcbS28n8HMwtJ7uFDBImQtYXygLy7zQf+/hetd0vQL1Omase876BkfP6J5Px/xk7RikqjdPQVU922HC4hBc35nDtnBQumJzobnFcT2O1Cgya/NXKq63V3RK5hje/D29fqfrndKbiCLQ1OR4oNogaoQrQfEmBZqyGsAQYflrXbQmTwNyq4gHWSKksAsMtBBA6BOInOKeeIGc9DJ2qrA0dI3AqWhHYoKKumZ+u/I5xQ8P5zdJe3hS8laObVTbGqVdBSz2UHnK3RM6noUK5fgq2q8/bGUd7DHVGCNV3yFd6DrU2KYtg/IUqGN4Z4/fTubCs5hjUl0HiKSe/nzIX8rYpH39faa5TymT0AlWjoF1DTkUrAhs8uy6L8romnrxyOsEBPpAJ5Ag565TLZO7d6rU3ZcEc3+eYBWP4qYUJNj/RdXvxQUA4njFkTfJMVWjVWN37Yz2NnA2qlmLiMtvbY8eC8OsaJzi+Vz0O66wI5qmupY40q7NH7jfKVTVqoZoFoYPFTkUrgk7kl9fz+pZcvj9zOJOSIt0tzsCRvQ5Gnq5We8FR3uPmqC2Gf54FO17peV/jM51+L2R/1TWAWXxA5cb3ZRRj8gxAwrHven+sp3Fkgwr4pp1le3tAMMSOtqEILBlDQyef/H6KJTbQnySE7HVKppGnK4uguVZXFzsRrQg68ffPDyME3HeeD1aJ2qOqAMoyYfTCDjeHt1gE5UeUS+voxp73LdypVrNn/kSNodz895O396bHUGcMd4ixKvZm6ssgPAH8g+zvY6vn0LE9SpEGRZz8fnQKRCT1TxHkrFMupoAQCIlR72n3kNPQisCKA0XVfLC7kJvmpw6uVhFGNoaRLZM8U1WHtjS4/tpFu6G+vO/HV1m6mORttR0AtsbI6gmOUpWvB1Z1tEtuaVQ9bHobKDaIGArhQ31EEZR33GztkTBJKeHm+o73ju/tGh8AtbgYOU8VlvX0N7JFzXGldEZb/j9DotWjdg85Da0IrPjzZxlEBgdw19ljet7Zl8hZpzJEDJM+eYZaZbv6pvbdCnjxbHjyFNjwF2iq7f05jFYDdSXqRm6P6iI1c9dI9Zx7p1rxfv2Uel2WqT5zXy0CUNkyvqAIGhxRBBMB2ZFU0Fitsq6sM4asSZkHNUWqV1BvyVmvHo2FSrBFEWiLwGk4pAiEEO8LIZYIIXxWcXyTVcqGwyXcvXA0UaEB7hZn4DCb1Rdt1IKOwiHrvHhXcfBj+PAuSD1TZYKsexSeOhW2vqCyVhylKh+wyN2d68H4LMZnC0+A6dcpZVRV2PseQ7ZInKqyknojvyfSUKHSPrsj3sgcsvzejGI6WxYBWNUT9CGNNHsdhMZ2nFtbBE7H0Rv7c8A1QKYQ4nEhRB/SKjwXs1ny+GcZJEUFc8O8VHeLM7Cc2Kd8wqOtiqgiEpVP11WKIPsrePeHyvK4egVc+Sbc8hUMnQSfPQD/mAV733XsXFUFypIJGdL9TaYwXdVIDJ3S8d7p94I0w5ZnlevBFKCCoH0l8RSVX1+S0fdzeAL15er32R1DRoFfYIciMCwhexZBwiQIirKtrJtqVFaQLbeRlGqhknY2mCy3q/YYga4lcBYOKQIp5RdSymuBGcBR4AshxDdCiJuFEF6/fF6z7xh7Cqr4yffGD550UQOjideoBSe/nzzDNZlDeVthxbWqKOja/6reNQDDZ8KNH8P1H6oV33s/Uj7onqgqUAVdKfNU9ao9CncqJRBgNUc6ZqTqmZ/+b3UjihvbURHbF3whYGw2q5V2T64hP381eKZdEexRRXURdoovTX4wYvbJiqClEbY8pyzBVy9U7sHOFB9ULj3rhYp2DTkdh109QohY4CbgFmAX8BRKMXzuEskGiJY2M39de4gJiRFcOj3Z3eIMPNnrlJkfmXTy+8kzVeVofwK5nTn2Hbx1hbrW9R/YvtmMXgiL/6qeG4Hc7qjKh6jhyvVQngM1J7ruYzarVFHDLWTN/PugpU7N1u1PfAAsqadhHY3XvJGmKmUl9eQagpN7DhkzCLrrWjtynrKWaktg11vwzCxY+0uloCddAusfU4rBmpxOiQygXUMuwNEYwQfAJiAUWCalvEhK+Y6U8sdAuCsFdDVvf5tHblk9Dyya4PtN5TrT0qhWaKNt9NYxeuY4o1kYqJv6G5dBcKRa9Ycn2N83xjLXoeJo9+dsrFY9Z6KGd5+rXpalpojZ6gM0dBKMu1A9768iMJkgcYp3WwSGu6UniwDU76u6AOrKlEKw5xYyMP5Gz82Fj+5SM6Gv/xBuXAWX/wsmXqQUw843Oo7JXqd6C0VbdbT3C1AKd6AsghMH1Gf0YRy1CJ6WUk6SUv5JSnnMeoOUcpYL5Bow3tiSy8yRMSwYH+9uUQaevC2qd7ytJmtJ09Wjs9omfP5btdK84aOTv9S2CE+AgFCVhdId1ZbxFtEj1BQt/xDbcQLjM9iyCADO+pmqlB0+u/vrOYKROeStM4zrDUXgiEVgCawf+FB1GLUXKDZImqHOGzoErngDbl3XsQjx84fLX4bR58LH98K+91XQPfdr2/+fITEDEyMoy4YXFyhrxYdxVBFMEkJEGy+EEDFCiLtcJNOA0dxqJqe0jrmjhiAG4yCWnHUqQJo6v+u24Cjlx3dGnKCtBY5shMmXOBaMFQJiUnu2CCotNQRRI1QXzOGzbFsEhelqBRlnp0hw+Cz4RQ6MOrtn2XoicSo010Blbv/P5Q4aLK5ARy0CgD0r1WNPiiAgGO7bC3dthUkXdXUj+QepxIERc+H9W2HdY6rvlS2LdSDaTEgJHy9XjQh7+l/0chxVBLdaj4+0DJu/1TUiDRx55XW0mSVjErzau9V3stfBiDkQGGZ7u1FhbK8I6Nge5e/tiYId6ubYm/bOMak9B4uNYrKo4eoxZa4KWjbVnLxfYbqycGw1UDMIiba/rTe0B4y9NE5grLIdiRFEjYDAcMjfqiw4R5R8UHj3f4fAULhmhYobfP2kstRSz+i630A0nvvubTi6SX3Gqs7DFV1IRW73NTEuwFFF4CeslsxCCD8gsJv9vYKsYlXANDp+ECqCulJ1sxq9wP4+yTOh9oQqxupMaSa8fK5K9+yJnHWq0Zu93jW2iElTq7DuKlGrClRKaLgaH0rKPOV+KrCadNrarFw1AzUnIGGiunl5a5zASA5wxDVkMqkW06BSeLu7wfeG4Ci47n1ImAxjzrU9Lc7VFkFdGaz9lVoonXqV7e+Aq1j1Y3jlAucmavSAo4rgM+AdIcS5Qohzgbct73k1g1oRtFdrnmN/H3uFZVLC6vuVX/jw/3ouoMpeZ/EP92LVHZMKrQ1KEdmjqkBlIBk3oOGnKYVjHSc4sU/JOVCKICBEuaC8VREYFoGjozoTLIqgp0BxbwmLhTs2K1eRLUKiXRsj+N+vVILB0ieV5dNU1dXSdBVlWapS/ovfDsz1cFwRPIAaJXmn5edL4BeuEmqgyC6pIykqmLAglw5q80xy1inzOmma/X0Sp6gYQmdFsPstZTJPvEi5fI500/CtsUodb8vP2x1DHMgcMmoIDIIj1Q0p16qeoHNF8UCQONV7U0gbypUS8HPwO2EEjJ2tCEBZHPYa37nSNZSzXrmF5i9XWWWRlrTygbAKWhrVdUKGwM7XT/5fdiGOFpSZpZTPSym/b/n5p5SyH1MmPIOs4lpGD8b4QPUx1XBtzLndm/P+QUoZWGcO1ZXC/36tAnqXvaj8pwc/tn+OI5tUD59RC3onY0yqeuwuTtBZEYByDxXs6GhRXLRLFTp13s+VDDtF9dWpKx24azqLhgrHAsUGKXPVYiHldNfJZIuQaGUxOrudR0uDsnaHjIKzfq7eM2psqgcgTlCZB0g492GISlHB6gFoWeJoHcFYIcS7QogDQogc48fVwrkSs1mSXVI7ON1Cnz2g/rkW/qrnfZNnQuGujnTItQ+p5nDLnlJukLHnw6E19qdP5axTGTu9Tc2MTgGEfYugrVV9MY1AsUHKXHWDMOYCFKYrt9RAZoUZq2NvdA850l7CmuSZ8Mv8DhfRQOGq6uKNf1OFiUv/3jGXIspiEQxEwNhImR46GZY+AaWHYfOTLr+so66hV4HngVZgIfA6YMd55x0cr26kvrlt8GUMHfoMDnwEZ//csSyPpBnK/VOWqXoE7XkHzriv44s/YanyZ1oHaK3JXqfSUzsPOe8J/yBlkturJag9riyNLorAqrCsqUZNDRtItxB4d+aQIw3nOtOXQT79xRX9hooPqm60p1x1sgUbMUw9DoRryFj4xKSqRdbky2DT3xyrsu8HjiqCECnll4CQUuZKKR8BlrhOLNczKAPFTbWw5meqpcTpyx07xriJ5n4Nq38CQ0bDmT/r2D72fOUayFjd9djKPNWmojdpo9YMSbNvERjtpzu7fCISVcZR3lY16wA58IogdAhEDvdOi8CRFtSegCvaTOx4VVUtX/Doye/7B6k27QPhGio/oizoMEuB66LHlaJdfX/fZjk4iKOKoMnSgjpTCHGPEOJSvLy1hKEIBpVFsO4xlXu/7EnHV+hxYyEwQlUGVxyxmMxWjduCo1Qh1sHVXf9RjYE3vQ0UG8SMtB8jaFcEw7tuG3m6sggKd6jXRpX0QOKtswnqK3rnGnIXwS6YUlaWqTK+wuK6botMGhhFUHFUWQOGKzNiKJz3O5Wcsfstl13WUUWwHNVn6F5gJnAdcKOrhBoIsktqiQoJIC7c68shOshZb7vpGqig6bbnYebNHb3hHcHkpzKLmqrh1GtsV99OWKKUROcZtjnrlFkd30f/cUwa1BVDc13XbZ2LyaxJmataa3/3jvpShcX27fr9IXGq8u8OxJQ3Z9HWqtIkB6tFUJZt310aNXyAXENHOjLmDGbcqJIz/vdrlyUg9KgILMVjV0opa6WUBVLKm6WUl0sp+zBhwnPIKq5ldHyY77SWOLEfXr8Ynp4GX/7+5JVSW6vKPgiLh/Me6f25Ry2A8ET43h9tbx+/BBAnu4fMZsjZcPLAm95iZA7Zcg9VFagbVpANi86IE5QcHHi3kMGwU1Rx24kDPe/rKRg31d7GCNyBs2MErU1qcRFrZzphZJLrg8VSdlgE1phMKjmjqValtbqAHhWBJU3URo23d5NdUutbbqGDqwGhfPab/k/1eN/8pJop++0/VRbNosf71krhzJ/CfXvsr6wjhqpiLmtFcPw75W/ua3wAuq8lqMy3bQ2A+jKHWsz7pAEqJOtMe+aQFwWMG3rRcM7dGAVvznINVRxVinuIHYsgMsn1RWU1x1UTyM6KAFRyxh2bYN49Lrm0o5VUu4QQq4D/Au12upTyfZdI5WIq65sprW32LUWQ8bEqh7/idVXM9NUfVGXithdUu+ax34PJl/bt3ELYL+wxmLgUPn9YBYijUzriA6MW9O2a0NGO2lacoKpAxRBsIYRyD2Wsdp9FED1STeTypjhBfS8azrkbkx8ERTrPNWT09rHnGoq0LDqqj0F8hHOu2Zn2jKE029v72ya9GxyNEQQDZcA5wDLLz1JXCeVqskt8LGOoIlfdcCZYErmGnaKmf920Rt2U/fxh8d9cm0s/wfLvkLFGPeasU71iIob2/ZwhMepmas81ZM8iABi/WM25HdZDR0xXIYQlYOyFFkGoFygCcG51cblFEQwZZXt7e1FZgXOuZwsjVbpzjGAAcMgikFLe7GpBBhKfyxjK+EQ9TuiU0Zs6H364VlXZ9jaPv7fEjlZpqRmrYcYNKn1z9m39O6cQatXfuZagsUqZ6d0pgmnXqGZhzmqE1hcSp8LO11SxnTvlcJTetKD2BJzZeK4sW31ue/GRqAFoM1FxVPXKGsgqeAsOKQIhxKtAlyRWKeUPnS7RAJBdUkegv4nhMaHuFsU5ZHyier7YMmuFcL0SMJiwBDY/oZRBW3P/4gMGQ9JUINwaI2jX3RdGCNUF1J0kTlX99MtzVBqup9ObzqOegDMbz5Vn248PQEdRmSsDxuVHlAtqoL6vVjjqGloNfGL5+RKIBGpdJZSrySquZVRcmG+MpqwrVUPbJ3iAp27iUhVw++J34Beo8vn7S0yqcn1Zt7CwV0zmaRhuKaPdhafTUKFWpEGR7pbEMZzpGirLsZ8xBJaisnjX1hJUHLUf93Ixjjade8/q5y3gCsBrR1T6VLO5w5+pm29nt5A7GDZNrWiqCywDb5xgccWkgbnlZJO8Kk89duca8gTixquqa28JGBtVxSZH14duxlmuoZYG9T/bU8uVyGQXu4Zs1BAMEH39i48Fupk+7rk0trSRX1HvO4Hig6vVynjYqe6WRLljDIXU12rizrTXEljFCaoK1A02vB+B6IHAP1Cl/XU35c2TaPCSqmKDkBhlEfT3d1tu6Z9pL1BsEJnsOougqVb17LKVOjoAONp9tEYIUW38AB+jZhR4HUdK65DSRwLFTbWqEdyEJQPbXbM7TrlSjS0c7yQLxVYtQftAGi9YuY4+R7UHeHGB+lt5skKo95I+QwbB0WqecH+rt3tKHTWIcqEi6Cl11MU4mjXkosTZgac9Y8gXLILsL9UXwRPiAwbDZ8JDRc5TTJHD1TjK8k4WQXSKc87vas79rcqmWvcYvHGpGtd57iPq9+RpNFR0pEl6A9ZtJvrjhmxPHe3JNZRkyVirtV3R3h+su466AUctgkuFEFFWr6OFEJe4TizXkV1SixAwKt7OwHZvIuMTZcobLRU8BWdaJ37+yvXV2SLw9PiAgckPpl0NP94BF/5FtZx4+RxYca2qjvYkejuUxt04ayZBWbYKBAf3ECR35aQyN9YQgOMxgt9KKauMF1LKSqDHgZpCiEVCiENCiCwhxIM2tt8khCgRQuy2/NziuOh9I6u4luExIQQHeEFed3e0tahA8fgLHR8r6K3EpHZ8Udpa1RfRWxSBgX8QzLkdlu9WA4Fy1sNrS1WlqqfQ26E07sZZjefKc3q2BsBKEbigqKziqGqb4SZF7KgisLVft3cfS7O6Z4ELgUnA1UKISTZ2fUdKOc3y87KD8vSZ7JI633ALHd2szFRPcgu5Cuu5BDXHbA+k8RaCIuDsX8CNq1Tq7xuXQF2Zu6VSTdda6rynqhic13iuLLv71FGD9upiF1gE5UfcFh8AxxXBDiHEE0KI0ZafJ4D0Ho6ZDWRJKXOklM3ACuDi/gjbX9rMkhxfGU+ZsVoFZZ2VnePJxKSqL3tDZfdzCLyJ5JlwzTtKwb15mVLqriRvm5rWZo/2hnNepAic4RpqqlHT7mJ7yBgC1yoCW11HBxBHFcGPgWbgHdQNvRG4u4djkgFrJ2iB5b3OXC6E2GOZiWyzQkgIcZsQYocQYkdJSYmDInelsKKBplaz92cMmc2qp8+Yc90zJnCgibHKHGpXBF4SLO6O1DPgijfgxD74z1WqU6wraKiENy9X/ezt7uNFnUcNnOEaak8ddcA1ZBSVVTnZNWRuU80a3RQfAMcLyuqklA9KKWdJKU+TUj4kpbQxLaTXfAykSilPAT4HXrNz/Rct154VHx/f54u1N5vzdkVQtAtqigaHWwhOriVoH0hja03hhYz7Hlz2EuRvhZXXQ2uz86+x/WU1d9q46dnCmzqPGgRFAaJ/FoGjqaMGkUnOtwiqC1XRpKdbBEKIz4UQ0VavY4QQa3s4rBCwXuEPt7zXjpSyTErZZHn5Mmr6mcvwidRRKdUAeeEH4y5wtzQDg/WAmqoCtWoN9IGsL4Mpl8GypyHrC3jvRyog7ixaGmDr8+p551Yd1rR3HvUii8BkUgHW/sQIeuo62pnI4c6vJTBSo70gRhBnyRQCQEpZQc+VxduBsUKINCFEIHAVsMp6ByHEMKuXFwGdZh06l6ziWmLDAokJ89LxlEe/hlcuUINmJi71rtVbfwiOVC2lyy0WgbfHB2wx43q44E9wcBV8fK9y/zmDXW9CfSlMvaJrqw5rGrys4ZxBf9tMlOWohnKOLixcMbvYzTUE4PhgGrMQIkVKmQcghEjFRjdSa6SUrUKIe4C1gB/wipRyvxDi98AOKeUq4F4hxEVAK1AO3NSnT+Eg2d4aKD62R42fzPpc/dMuewqmXetuqQaWGEvmUF2JW1dOLmXeXSp4uf4xCAyHC//cv5qMthb4+mnV92naNbB3pXKvRdsIxXmjawj633iu3MGMIYOoZOcXlVUcUUWTblzgOKoIfgVsFkJsAARwJtBjs3kp5RpgTaf3HrZ6/kvglw5L2w+klGSV1HLhlGE97+wp1JfDmp/DvnfVP/z5v1c9/gdDgLgzMalQ8K360qee6W5pXMfZv4CmatjyjLKEzukmwNsT+95TDfoW//XkVh1pZ3Xdt6FCdYz1Npdbvy2CrN7F2qyLyuLHdd1efFBtG3Ou4+esOKoq5d04s8LRFhOfCSFmoW7+u4APgX42+BhYyuqaqaxv8a6MoU9+Cgc/VjODT7+3b/OGfYUhaerGhrS9ovUVhIDv/VEpg41/VXUH85f3/jxms5pZnTBJjSmV5q6tOqwxOo96Ss8qRwmJ6XsWT0Ml1Jc5HigGK0VQaFsRfPJTyN8Gt2+CobbKpmzg5hoCcHwwzS3AclTAdzcwF9iCGl3pFWQXG+MpvWTFk/k57H8fFjwEC7yyv59ziUml3RvpizECa4SApU8q98PnDytlMKuXM6AOfwYlB1VGkskEmLq26rDG2zqPGvTHNeRojyFr2msJbMQJ6kohb4tSuqvvg5s/c6wxYsVR983WtuBosHg5cBqQK6VcCEwHnDQRYmDIKvGi8ZTNdbD6JxA3Ds64z93SeAbWKyZPH0jjDEx+cNmLMG6R+l/Ys9LxY6VUk+KiU2DyZR3vW7fq6Ey9l/UZMjBcQ33p6lpmSaftlUXQTVHZoU+VEphzp7IK0l/t+XwNFUp+N9YQgOOKoFFK2QgghAiSUmYA410nlvOJDQvivIkJJEV5gX99/Z+Ub3fZU6qIRXNyRoWvWwQGfgHwg3+rwrMP7uiYTd0TuV9DwXblTrTuQ2XdqqMzDRXelTpqEBwN5la1eOot5dmA6J1bprtJZRmfqELHCx5TcZgvfgc1x7s/nwdkDIHjiqDAUkfwIfC5EOIjINd1YjmfRVMSefnG0zB5+njKY3tgy3NqALwzRj36ChHDwC9IBTTDvHImUt8ICIGr34akafDfm1Szup7Y9IS6WU2/7uT3Y9I6WnV0psHLZhEY9KffUFm2WlQEBPfuuMikrrOLrWeDmEzKtdfaCJ/24Nb1gBoCcLyy+FIpZaWU8hHgN8C/AK9sQ+3RmNtUDnnoEJUhpOnAZFLzXCOTvWMgjTMJioBr34XYsfD2NZD/rf19c9arORVz7+yaXWZdmGeNlN43lMagpzYT2eugwE5btPLs3rmFDCKHd3UNtc8GsQxkih0NZ/0cDnwIh7upvW23CNwzq9ig198oKeUGKeUqSyM5jTP59iXVPmLR4975pXQ1Y7+nJn4NRkKHwPUfQMRQeOv7Xecgl2bCyhvh9YshIglOs9HRvT2FtFOcoKVB3cS81TUE9gPGH94Jb1/ZUSdhIKVKHe1NoNggMqlrK+qDq7vOBpm/HOInqEyiplrb56o4oqy3IPfO/hpkSysPpqoAvvoDjD4Xplzubmk8kwsehaVPuFsK9xExFG74SBWbvXGpuvlXFcKqH8Ozc1Sm2dkPwN3bVOuFztizCBq8tJgMurcIqotU2/K6Evii0/iU+nJVGNYni8BqUhlYZoOs7TobxD9QuYiq8lXczxZu7jpqoBWBp/DpA8o1tPQJ78vl1gwc0SlKGUgJryyCp6fDdytUoeHy72DhQ/YnbQVFQGhc11oCb+w8atBdjKBwp3pMOwt2vq5atBj0JXXUwEhWqLEMFTq6CZrszAYZOQ9m3gRbn1MxhM6UH3V7fAC0IvAM6srUfIHT7/GI1YHGw4kbCzd8qOb0TrkM7tkBFz4O4Q505o1J7WoRGG4TX3MNFaarIrofvKYU6MfL1QAe6H3XUWuMFFKjkC3jk+5ng5z3iEp5fuNS1W78xH71fmuzcjF5wHdeKwJPoMiychm1wJ1SaLyJxKlw31649IXeBRqHpHWNEXjjUBqDoAjVideWa6gwHYZOVgpuyd+hLBM2/11tK88GYYLoPgRprdtMmM1KEXQ3GyQkBu7aAuc+DLnfwPPz4f3blCUhzW6vIQCtCDyDwnT1Tzlsmrsl0fg6MalqJdvW0vGet3YeBeVGDY7qahGYzVC0u6Nid+x5Kva26f+g5LCyCKJHKj9+b4mw9CurLrTMBjnWc7+iwDDVKmb5bhVEPvCRmkwH2iLQWChMV9kFzupmqNHYIyZNrUIr8zre89bOowYhMV1jBOXZym9v3bph0eNq1b76PmUd9MUtBKruIDROKYKM1b2bDRI6BM7/Hdy7C2beDPETldXiZhztPqpxFVKqoNa4Re6WRDMYsM4cMm6EDRXKx93bwipPwVYH0kJL7UDSjI73whNUfc7HliZ+s/tRsBmVrFxDud+oyu/eKtHI2AJ5vgAAD/xJREFUJFj2ZN+v72S0ReBuKvPU4JDkGT3vq9H0F1u1BN7acM7AVuO5wp0QEAbxnTrhTL+hI9e/rxYBqDhB/jYoPQwTl/X9PB6CVgTuxli5uLn7oGaQEJ6oWnWUd1YEXuoWAvsWQdL0rj3+TSbVwytuHIyc3/drRloG1ACMX9z383gIWhG4m6Kd6ovpAX5CzSDAZOqaQlpfDqHerAg6xQham+H4Hkiebnv/+PFwz3ZInNL3axoppEkzlJvIy9GKwN0U7oRhp6hOkxrNQNBZEXi7RRAcrVbnxpzn4v3Q1uxaK9tIITV6C3k5WhG4E3PbySluGs1AYLSjNnr4N5R7d4wgJFplQjXXqNcD4W4dcZqa/jb1B667xgCiFYE7KTkELXVaEWgGlphUaK5VE7Wk9A2LADoCxoU7VXqnKwcYDRmlisTc3DXUWWhF4E5spbhpNK4mxmqQfVONGuzije0lDDr3GyrcqRZXumeXw2hF4E4K01VV5JBR7pZEM5horyU44t1VxQbWHUibaqAkQ6dj9xKtCNxJ0U5lDQy2QSsa92K4MyqOenefIQNr11DRbkBqd2sv0Xcgd9HSoLoQ6pWLZqAJCFH9csqPeHfnUQNri8Bo4Kjdrb1Ct5hwF8f3Kt+sXrlo3EFMmu9YBNYxgqJdqplcWKx7ZfIytEXgLoyhGVoRaNxBTKolRuDFQ2kMAkLBFKBcQ0agWNMrtCJwF4XparZsRKK7JdEMRoakqfbJxhB2b7YIhFDuobIsNRZSK4JeoxWBuyhM1/EBjfswUkiP7YagyJNn7XojwdGQs0E919+rXqMVgTtoqFD90vXKReMujBTSwp3ebQ0YhMSoymJhgmGnulsar0MrAndQtEs96pWLxl0Y7agbK31EEVgyhxImqWlgml6hFYE7aK8ottMdUaNxNaGxEGiZiOfNqaMGRi2B/k71Ca0I3EHhLtUPPTjK3ZJoBitCdMQJvDljyMCwCLS7tU9oRTDQSAmFO3TBi8b9GBXGPuEasnwGrQj6hJenCngh1UVQe0L/w2rcjxEn8AXXUNpZcGyPihFoeo1WBANNkS4k03gIRuaQL1gEqWeoH02f0K4hZ7DjVcjf7ti+hemqCrI/Y/I0GmfgSzECTb9wqSIQQiwSQhwSQmQJIR7sZr/LhRBSCDHLlfK4BCnhswdh898d278wXc0n9g9yrVwaTU8kz4S0s2HEbHdLonEzLlMEQgg/4FngQmAScLUQoosDTwgRASwHtrlKFpdSWwytjR0un+4wm1Wb3OHep+80PkhINNy4qiNWoBm0uNIimA1kSSlzpJTNwArgYhv7/QH4M9DoQllcR2WuerTu22KPsixoqtYZQxqNxqNwpSJIBvKtXhdY3mtHCDEDGCGl/KS7EwkhbhNC7BBC7CgpKXG+pP2hMq/juVEoZo+BGKqt0Wg0vcRtwWIhhAl4AvhpT/tKKV+UUs6SUs6Kj493vXC9wbAIhF9Ha2l7FO2EwAiIG+t6uTQajcZBXJk+WgiMsHo93PKeQQQwBVgv1JDpRGCVEOIiKeUOF8rlXCrzIDQOopIdswiSpoHJb2Bk02g0GgdwpUWwHRgrhEgTQgQCVwGrjI1SyiopZZyUMlVKmQpsBbxLCYBSBNEpyt1TtEsFhG3R2qSmkulGcxqNxsNwmSKQUrYC9wBrgYPASinlfiHE74UQF7nqugNORa5SBEkzVCC4LMv2fif2QVuzjg9oNBqPw6WVxVLKNcCaTu89bGffBa6UxSWYzWoi0oQlHTf4op0QP67rvoV6qLZGo/FMdGVxf6g9oVb5MSMhfjwEhNmPExTuhLAEiBo+sDJqNBpND2hF0B+M1NHokSoAnDS9G0VgGU2pAuMajUbjMWhF0B/aFUGKekyergLCrc0n79dYDaWHdXxAo9F4JFoR9AejhiDKkiWbPFO5ik7sO3m/Y7sBqTOGNBqNR6IVQX+ozIWweAgMVa+NFX9n91D7aEqtCDQajeehFUF/qMxT8QGDqBGquMwYTm9QuFO1/PWFASAajcbn0IqgPxjFZAZCKKugi0WwU8cHNBqNxzK4FIGUzjuX2QyV+ScrAlA3/JJD0FSjXtecgOoCHR/QaDQey+BRBAdXw+sXQVuLc85XexzMLTYUwQxAqrkDoEdTajQaj2fwKAJhgiMb4ZunnXO+CkvGUMzIk983AsKGe6gwXXUmTTzFOdfVaDQaJzN4FMGExTBxGWz4C5Tn9P981sVk1oTFqqHg1oogYVJHZpFGo9F4GINHEQBc+Bc1OH71/f2PFxiKwFbLiKQZKnNISkugWMcHNBqN5zK4FEFkEpz3W8hZD3tW9u9clbkQPhQCQrpuS56pmtHlbYXGSq0INBqNRzO4FAHArB9C8ixY+0uoL+/7eTqnjlpjBIa3v3zya41Go/FABp8iMPnBsqegsQr+95u+n6cyt2t8wGDYKSo4feAj8A+B+Il9v45Go9G4mMGnCAASp8C8e2D3m3BkU++PN7dBVYF9iyAwTAWIzS0w7FTwc+nYB41Go+kXg1MRAJz9gFrRr74PWhp7d2zNMTC32lcE0BEX0G4hjUbj4QxeRRAYCkv/rkZLrnu0d8d2bj9tC0MB6ECxRqPxcAa3z2LMuTDzZlVkFjEM5t3l2HH2agisGb8EcrfAmPP6L6dGo9G4kMGtCAAW/w3qy1QWUVA4zLih52OMquLoEfb3CY+Hy/7pHBk1Go3GhQxe15CBnz9c/rJaua+6F/a91/MxlXnKgvAPcr18Go1G42K0IgB1Q7/iDUiZB+/fBofXdr9/ZW738QGNRqPxIrQiMAgMhWtWwNApsPKG7tNKuysm02g0Gi9DKwJrgqPguvdV07i3r1JzBTrT1grVhVoRaDQan0Ergs6ExcL1H6jnG/7SdXtNkaWGoJuMIY1Go/EitCKwRWQSzLoZ9r8P5UdO3uZIDYFGo9F4EVoR2GPu3WDy7zrIRisCjUbjY2hFYI/IYXDq1bDrLTV32KAyDxC25xBoNBqNF6IVQXfMX64ax219tuM9XUOg0Wh8DK0IuiN2NEy6BLa/Ag2V6r3KvK5zijUajcaL0YqgJ864D5prOobMVOhiMo1G41toRdATw05V7Se2Pg+N1bqGQKPR+BxaETjCGT+B+lLY8GeQbVoRaDQan0IrAkcYeTqMmAPbXlCvdTGZRqPxIbQicAQh4Iz7VUUxaItAo9H4FFoROMrYC9QcYmGCyGR3S6PRaDROw6WKQAixSAhxSAiRJYR40Mb2O4QQe4UQu4UQm4UQk1wpT78wmWDpk3DeI+Af6G5pNBqNxmm4bEKZEMIPeBY4HygAtgshVkkpD1jt9h8p5QuW/S8CngAWuUqmfpMyR/1oNBqND+FKi2A2kCWlzJFSNgMrgIutd5BSVlu9DAOkC+XRaDQajQ1cObM4Gci3el0AdFlOCyHuBn4CBALn2DqREOI24DaAlBQdqNVoNBpn4vZgsZTy2f9v7/5C5CrPOI5/f43WqpFG7VZKEo2JAbWgKwbRaiGNrdhWai7if0VKLxUitFQttsVALrzxz0WhShsaaazGaDSUQBvTkOqFfxITrUZBWlIwaLal2jaCYuKvF+cdHHc3zeru7Mk55/eBZea8czJ5H/adfc6cM/M8thcAtwJ3HGSfB2wvsr1oaGhoeicYEdFyg0wEe4C5fdtzytjBPAwsHeB8IiJiHINMBC8ACyWdKunzwNXAhv4dJC3s2/wu8MYA5xMREeMY2DUC2/sl3Qz8AZgBrLL9qqQVwDbbG4CbJX0T+BB4B7hxUPOJiIjxDfJiMbY3AhtHjf2s7/7yQf7/ERFxaLVfLI6IiHrJbtZH9yX9A/j7Z/znXwL+OYXTORy1PcbE13xtj/Fwje8U2+N+7LJxiWAyJG2zvajueQxS22NMfM3X9hibGF9ODUVEdFwSQUREx3UtETxQ9wSmQdtjTHzN1/YYGxdfp64RRETEWF17RxAREaMkEUREdFxnEsGhuqU1jaRVkkYkvdI3doKkTZLeKLfH1znHyZA0V9IWSbskvSppeRlvU4xfkPS8pJdKjHeW8VMlPVfW6iOlVldjSZohaYek35fttsW3u6/T4rYy1qh12olE0Nct7dvAmcA1h3VbzIn5DWO7ud0GbLa9ENhctptqP/BD22cC5wM3ld9Zm2L8AFhi+2xgGLhU0vnAXcA9tk+jqsH1gxrnOBWWA6/1bbctPoBv2B7u+/5Ao9ZpJxIBE+iW1jS2/wz8a9Tw5cDqcn81DS7rbfst2y+W+/+l+kMym3bFaNv7yuaR5cdUDZrWlfFGxyhpDlVl4V+VbdGi+P6PRq3TriSC8bqlza5pLoN0ku23yv23gZPqnMxUkTQPOAd4jpbFWE6b7ARGgE3AX4F3be8vuzR9rd4L/Bj4qGyfSLvigyp5/1HS9tJNERq2TgdafTTqY9uSGv/ZYEkzgceAW2z/pzqgrLQhRtsHgGFJs4D1wOk1T2nKSLoMGLG9XdLiuuczQBfZ3iPpy8AmSa/3P9iEddqVdwSftltaU+2V9BWAcjtS83wmRdKRVElgje3Hy3CrYuyx/S6wBbgAmCWpd5DW5LV6IfA9SbupTscuAe6jPfEBYHtPuR2hSubn0bB12pVEcMhuaS2xgY+b+9wIPFnjXCalnEv+NfCa7bv7HmpTjEPlnQCSjga+RXUtZAuwrOzW2Bht3257ju15VK+5P9m+jpbEByDpWEnH9e4DlwCv0LB12plvFkv6DtX5yl63tJU1T2lSJP0OWExV8nYv8HPgCWAtcDJVqe4rbY++oNwIki4Cngb+wsfnl39CdZ2gLTGeRXUhcQbVQdla2yskzac6gj4B2AFcb/uD+mY6eeXU0I9sX9am+Eos68vmEcBDtldKOpEGrdPOJIKIiBhfV04NRUTEQSQRRER0XBJBRETHJRFERHRcEkFERMclEURMI0mLe1U4Iw4XSQQRER2XRBAxDknXl14BOyXdX4rD7ZN0T+kdsFnSUNl3WNKzkl6WtL5Xe17SaZKeKv0GXpS0oDz9TEnrJL0uaY36CyhF1CCJIGIUSWcAVwEX2h4GDgDXAccC22x/FdhK9W1ugAeBW22fRfVN6N74GuAXpd/A14BeNcpzgFuoemPMp6rJE1GbVB+NGOti4FzghXKwfjRV0bCPgEfKPr8FHpf0RWCW7a1lfDXwaKk/M9v2egDb7wOU53ve9ptleycwD3hm8GFFjC+JIGIsAatt3/6JQemno/b7rPVZ+uvqHCCvw6hZTg1FjLUZWFbqy/f6z55C9XrpVc28FnjG9r+BdyR9vYzfAGwtXdXelLS0PMdRko6Z1igiJihHIhGj2N4l6Q6qrlOfAz4EbgLeA84rj41QXUeAqszwL8sf+r8B3y/jNwD3S1pRnuOKaQwjYsJSfTRigiTtsz2z7nlETLWcGoqI6Li8I4iI6Li8I4iI6LgkgoiIjksiiIjouCSCiIiOSyKIiOi4/wH4bp9oOV1pugAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNNMRj6FgKua"
      },
      "source": [
        "**Selfmade Model 6**\r\n",
        "\r\n",
        "Higher Dropout Rate\r\n",
        "\r\n",
        "More stable but lower test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaMAlPm_jCyY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a02740db-3d66-4b78-c72b-ddfd760d4484"
      },
      "source": [
        "# Define our CNN\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(Dropout(0.3)) # Dropout is optional.\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.4)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.4)) # Dropout is optional.\r\n",
        "model.add(Dropout(0.3)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(40 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.3)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(32, activation='relu'))\r\n",
        "model.add(Dropout(0.2)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax'))\r\n",
        "\r\n",
        "#apply learning rate\r\n",
        "opt = optimizers.Adam(learning_rate=0.0001)\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=0.0001,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "\r\n",
        "#fit call to use the datagen. 200 epichs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = bs) ,epochs = 200 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "print(bs)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "plt.savefig('loss'+str(bs)+'.png')\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "plt.savefig('accuracy'+str(bs)+'.png')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 32, 55, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 32, 55, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 32, 55, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 16, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 16, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 16, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 8, 14, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 8, 14, 128)        73856     \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 8, 14, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 8, 14, 128)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 8, 14, 128)        512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 4, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 4, 7, 40)          46120     \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 4, 7, 40)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 4, 7, 40)          160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 2, 4, 40)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 32)                10272     \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 150,923\n",
            "Trainable params: 150,331\n",
            "Non-trainable params: 592\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "53/53 [==============================] - 21s 367ms/step - loss: 1.4082 - accuracy: 0.3818 - val_loss: 10.2258 - val_accuracy: 0.3800\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 1.1113 - accuracy: 0.5071 - val_loss: 9.4144 - val_accuracy: 0.4667\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 1.0137 - accuracy: 0.5695 - val_loss: 9.4244 - val_accuracy: 0.4733\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.9852 - accuracy: 0.5610 - val_loss: 7.7755 - val_accuracy: 0.4933\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 1.0111 - accuracy: 0.5470 - val_loss: 8.5520 - val_accuracy: 0.5133\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.9397 - accuracy: 0.5710 - val_loss: 7.3939 - val_accuracy: 0.5933\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.9391 - accuracy: 0.5675 - val_loss: 12.3476 - val_accuracy: 0.5333\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.8966 - accuracy: 0.5962 - val_loss: 12.8878 - val_accuracy: 0.5200\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.8776 - accuracy: 0.6005 - val_loss: 13.5491 - val_accuracy: 0.5333\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.8277 - accuracy: 0.6226 - val_loss: 13.7590 - val_accuracy: 0.5733\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.8352 - accuracy: 0.6112 - val_loss: 17.0798 - val_accuracy: 0.5400\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.8376 - accuracy: 0.6032 - val_loss: 16.9562 - val_accuracy: 0.5667\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 20s 370ms/step - loss: 0.8292 - accuracy: 0.6226 - val_loss: 21.3395 - val_accuracy: 0.5467\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.8077 - accuracy: 0.6272 - val_loss: 31.0385 - val_accuracy: 0.5600\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 20s 367ms/step - loss: 0.8204 - accuracy: 0.6363 - val_loss: 34.4688 - val_accuracy: 0.5267\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.7811 - accuracy: 0.6508 - val_loss: 32.8553 - val_accuracy: 0.5467\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 20s 367ms/step - loss: 0.7943 - accuracy: 0.6237 - val_loss: 36.5373 - val_accuracy: 0.5733\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.7767 - accuracy: 0.6379 - val_loss: 38.9086 - val_accuracy: 0.5733\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.7774 - accuracy: 0.6513 - val_loss: 37.2891 - val_accuracy: 0.5333\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.7717 - accuracy: 0.6559 - val_loss: 39.6879 - val_accuracy: 0.5600\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.7715 - accuracy: 0.6458 - val_loss: 43.7836 - val_accuracy: 0.5600\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.7818 - accuracy: 0.6372 - val_loss: 40.5756 - val_accuracy: 0.5667\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.7180 - accuracy: 0.6799 - val_loss: 45.7341 - val_accuracy: 0.5533\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.7615 - accuracy: 0.6488 - val_loss: 42.6175 - val_accuracy: 0.5667\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.7145 - accuracy: 0.6851 - val_loss: 37.9317 - val_accuracy: 0.5933\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.7371 - accuracy: 0.6539 - val_loss: 36.6844 - val_accuracy: 0.5867\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.7204 - accuracy: 0.6756 - val_loss: 44.1033 - val_accuracy: 0.5600\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.7275 - accuracy: 0.6718 - val_loss: 45.1601 - val_accuracy: 0.5667\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.7207 - accuracy: 0.6585 - val_loss: 42.1584 - val_accuracy: 0.5533\n",
            "Epoch 30/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.6861 - accuracy: 0.6912 - val_loss: 45.3700 - val_accuracy: 0.5667\n",
            "Epoch 31/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.7056 - accuracy: 0.6811 - val_loss: 49.5305 - val_accuracy: 0.5600\n",
            "Epoch 32/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.7070 - accuracy: 0.6878 - val_loss: 45.3238 - val_accuracy: 0.5733\n",
            "Epoch 33/200\n",
            "53/53 [==============================] - 20s 367ms/step - loss: 0.7018 - accuracy: 0.6786 - val_loss: 41.6852 - val_accuracy: 0.5667\n",
            "Epoch 34/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.6744 - accuracy: 0.7033 - val_loss: 49.6374 - val_accuracy: 0.5533\n",
            "Epoch 35/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.6661 - accuracy: 0.7044 - val_loss: 42.1816 - val_accuracy: 0.5800\n",
            "Epoch 36/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.7236 - accuracy: 0.6582 - val_loss: 39.5894 - val_accuracy: 0.5867\n",
            "Epoch 37/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.6936 - accuracy: 0.6783 - val_loss: 41.4701 - val_accuracy: 0.5933\n",
            "Epoch 38/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.6841 - accuracy: 0.6867 - val_loss: 46.2369 - val_accuracy: 0.5867\n",
            "Epoch 39/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.6938 - accuracy: 0.6823 - val_loss: 38.2830 - val_accuracy: 0.5933\n",
            "Epoch 40/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.6686 - accuracy: 0.7029 - val_loss: 40.9430 - val_accuracy: 0.5867\n",
            "Epoch 41/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.6661 - accuracy: 0.7021 - val_loss: 37.3554 - val_accuracy: 0.5933\n",
            "Epoch 42/200\n",
            "53/53 [==============================] - 20s 367ms/step - loss: 0.6940 - accuracy: 0.6823 - val_loss: 36.4567 - val_accuracy: 0.5933\n",
            "Epoch 43/200\n",
            "53/53 [==============================] - 19s 372ms/step - loss: 0.6796 - accuracy: 0.6694 - val_loss: 34.6752 - val_accuracy: 0.6067\n",
            "Epoch 44/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.6577 - accuracy: 0.7197 - val_loss: 39.2237 - val_accuracy: 0.5733\n",
            "Epoch 45/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.6489 - accuracy: 0.7064 - val_loss: 36.5225 - val_accuracy: 0.6000\n",
            "Epoch 46/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.6619 - accuracy: 0.7009 - val_loss: 34.7346 - val_accuracy: 0.5933\n",
            "Epoch 47/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.6500 - accuracy: 0.7050 - val_loss: 39.7720 - val_accuracy: 0.6067\n",
            "Epoch 48/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.6487 - accuracy: 0.7130 - val_loss: 34.3404 - val_accuracy: 0.6000\n",
            "Epoch 49/200\n",
            "53/53 [==============================] - 20s 367ms/step - loss: 0.6324 - accuracy: 0.7246 - val_loss: 42.3959 - val_accuracy: 0.5867\n",
            "Epoch 50/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.6477 - accuracy: 0.7107 - val_loss: 37.5030 - val_accuracy: 0.5533\n",
            "Epoch 51/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.6327 - accuracy: 0.7120 - val_loss: 34.8272 - val_accuracy: 0.5667\n",
            "Epoch 52/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.6273 - accuracy: 0.7114 - val_loss: 42.4395 - val_accuracy: 0.5533\n",
            "Epoch 53/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.6582 - accuracy: 0.7107 - val_loss: 32.1129 - val_accuracy: 0.6000\n",
            "Epoch 54/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.6326 - accuracy: 0.7143 - val_loss: 40.4551 - val_accuracy: 0.5600\n",
            "Epoch 55/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.6271 - accuracy: 0.7147 - val_loss: 33.2274 - val_accuracy: 0.5867\n",
            "Epoch 56/200\n",
            "53/53 [==============================] - 20s 370ms/step - loss: 0.6210 - accuracy: 0.7203 - val_loss: 39.3627 - val_accuracy: 0.5933\n",
            "Epoch 57/200\n",
            "53/53 [==============================] - 20s 371ms/step - loss: 0.6261 - accuracy: 0.7198 - val_loss: 43.0534 - val_accuracy: 0.5333\n",
            "Epoch 58/200\n",
            "53/53 [==============================] - 20s 372ms/step - loss: 0.5949 - accuracy: 0.7421 - val_loss: 38.5683 - val_accuracy: 0.5733\n",
            "Epoch 59/200\n",
            "53/53 [==============================] - 20s 370ms/step - loss: 0.6304 - accuracy: 0.7198 - val_loss: 32.8918 - val_accuracy: 0.5800\n",
            "Epoch 60/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.6398 - accuracy: 0.7303 - val_loss: 32.6101 - val_accuracy: 0.6067\n",
            "Epoch 61/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.6098 - accuracy: 0.7189 - val_loss: 32.2401 - val_accuracy: 0.6000\n",
            "Epoch 62/200\n",
            "53/53 [==============================] - 20s 367ms/step - loss: 0.6323 - accuracy: 0.7160 - val_loss: 33.2020 - val_accuracy: 0.5867\n",
            "Epoch 63/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.6275 - accuracy: 0.7243 - val_loss: 34.1145 - val_accuracy: 0.5333\n",
            "Epoch 64/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.5974 - accuracy: 0.7336 - val_loss: 34.0490 - val_accuracy: 0.6000\n",
            "Epoch 65/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.6134 - accuracy: 0.7250 - val_loss: 33.9134 - val_accuracy: 0.5467\n",
            "Epoch 66/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.6078 - accuracy: 0.7358 - val_loss: 37.3479 - val_accuracy: 0.5400\n",
            "Epoch 67/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.6342 - accuracy: 0.6984 - val_loss: 33.6330 - val_accuracy: 0.5933\n",
            "Epoch 68/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.5977 - accuracy: 0.7340 - val_loss: 33.6301 - val_accuracy: 0.5400\n",
            "Epoch 69/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.6156 - accuracy: 0.7398 - val_loss: 24.3306 - val_accuracy: 0.6133\n",
            "Epoch 70/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.5983 - accuracy: 0.7542 - val_loss: 31.0317 - val_accuracy: 0.5933\n",
            "Epoch 71/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.5901 - accuracy: 0.7397 - val_loss: 31.3630 - val_accuracy: 0.5933\n",
            "Epoch 72/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5868 - accuracy: 0.7314 - val_loss: 26.8890 - val_accuracy: 0.5467\n",
            "Epoch 73/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.5870 - accuracy: 0.7480 - val_loss: 42.1143 - val_accuracy: 0.5667\n",
            "Epoch 74/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.6107 - accuracy: 0.7351 - val_loss: 39.2763 - val_accuracy: 0.5867\n",
            "Epoch 75/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.5953 - accuracy: 0.7389 - val_loss: 26.7827 - val_accuracy: 0.5333\n",
            "Epoch 76/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.5811 - accuracy: 0.7412 - val_loss: 31.5510 - val_accuracy: 0.6000\n",
            "Epoch 77/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.5869 - accuracy: 0.7391 - val_loss: 39.6590 - val_accuracy: 0.5600\n",
            "Epoch 78/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.5658 - accuracy: 0.7587 - val_loss: 32.0294 - val_accuracy: 0.5600\n",
            "Epoch 79/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.6098 - accuracy: 0.7354 - val_loss: 46.5218 - val_accuracy: 0.5933\n",
            "Epoch 80/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.5768 - accuracy: 0.7453 - val_loss: 31.4956 - val_accuracy: 0.6067\n",
            "Epoch 81/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.5812 - accuracy: 0.7389 - val_loss: 38.5056 - val_accuracy: 0.5867\n",
            "Epoch 82/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5811 - accuracy: 0.7446 - val_loss: 30.9856 - val_accuracy: 0.6000\n",
            "Epoch 83/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5623 - accuracy: 0.7550 - val_loss: 31.3314 - val_accuracy: 0.5800\n",
            "Epoch 84/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.5852 - accuracy: 0.7463 - val_loss: 21.1935 - val_accuracy: 0.5800\n",
            "Epoch 85/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5545 - accuracy: 0.7602 - val_loss: 28.2817 - val_accuracy: 0.5867\n",
            "Epoch 86/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.5602 - accuracy: 0.7619 - val_loss: 26.9789 - val_accuracy: 0.5867\n",
            "Epoch 87/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.5550 - accuracy: 0.7668 - val_loss: 29.8311 - val_accuracy: 0.6000\n",
            "Epoch 88/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.5483 - accuracy: 0.7655 - val_loss: 35.7871 - val_accuracy: 0.5667\n",
            "Epoch 89/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5532 - accuracy: 0.7606 - val_loss: 31.4948 - val_accuracy: 0.6000\n",
            "Epoch 90/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5646 - accuracy: 0.7636 - val_loss: 36.2196 - val_accuracy: 0.5867\n",
            "Epoch 91/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5571 - accuracy: 0.7574 - val_loss: 34.8090 - val_accuracy: 0.5733\n",
            "Epoch 92/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5542 - accuracy: 0.7607 - val_loss: 24.8815 - val_accuracy: 0.5800\n",
            "Epoch 93/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5380 - accuracy: 0.7612 - val_loss: 30.7377 - val_accuracy: 0.5667\n",
            "Epoch 94/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.5768 - accuracy: 0.7450 - val_loss: 32.6880 - val_accuracy: 0.6067\n",
            "Epoch 95/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.5385 - accuracy: 0.7736 - val_loss: 35.1916 - val_accuracy: 0.5667\n",
            "Epoch 96/200\n",
            "53/53 [==============================] - 20s 368ms/step - loss: 0.5582 - accuracy: 0.7590 - val_loss: 37.4959 - val_accuracy: 0.5600\n",
            "Epoch 97/200\n",
            "53/53 [==============================] - 20s 371ms/step - loss: 0.5674 - accuracy: 0.7527 - val_loss: 40.2461 - val_accuracy: 0.5867\n",
            "Epoch 98/200\n",
            "53/53 [==============================] - 19s 366ms/step - loss: 0.5682 - accuracy: 0.7446 - val_loss: 26.0988 - val_accuracy: 0.6000\n",
            "Epoch 99/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.5317 - accuracy: 0.7711 - val_loss: 32.3108 - val_accuracy: 0.6067\n",
            "Epoch 100/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.5305 - accuracy: 0.7782 - val_loss: 35.3067 - val_accuracy: 0.5933\n",
            "Epoch 101/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.5599 - accuracy: 0.7522 - val_loss: 31.6489 - val_accuracy: 0.6133\n",
            "Epoch 102/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5449 - accuracy: 0.7670 - val_loss: 31.0450 - val_accuracy: 0.5867\n",
            "Epoch 103/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.5241 - accuracy: 0.7869 - val_loss: 31.4849 - val_accuracy: 0.6000\n",
            "Epoch 104/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.5531 - accuracy: 0.7641 - val_loss: 39.2274 - val_accuracy: 0.5667\n",
            "Epoch 105/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.5377 - accuracy: 0.7603 - val_loss: 24.6469 - val_accuracy: 0.5600\n",
            "Epoch 106/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5479 - accuracy: 0.7726 - val_loss: 23.7454 - val_accuracy: 0.6000\n",
            "Epoch 107/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.5311 - accuracy: 0.7846 - val_loss: 25.2928 - val_accuracy: 0.5867\n",
            "Epoch 108/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5259 - accuracy: 0.7774 - val_loss: 34.2054 - val_accuracy: 0.5200\n",
            "Epoch 109/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.5196 - accuracy: 0.7934 - val_loss: 31.4958 - val_accuracy: 0.5933\n",
            "Epoch 110/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5128 - accuracy: 0.7870 - val_loss: 28.8515 - val_accuracy: 0.6133\n",
            "Epoch 111/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5207 - accuracy: 0.7817 - val_loss: 32.3502 - val_accuracy: 0.6067\n",
            "Epoch 112/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4972 - accuracy: 0.7953 - val_loss: 29.5481 - val_accuracy: 0.5600\n",
            "Epoch 113/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.5096 - accuracy: 0.7863 - val_loss: 41.5367 - val_accuracy: 0.5667\n",
            "Epoch 114/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5216 - accuracy: 0.7766 - val_loss: 27.5063 - val_accuracy: 0.5933\n",
            "Epoch 115/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5163 - accuracy: 0.7811 - val_loss: 25.6475 - val_accuracy: 0.5733\n",
            "Epoch 116/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.5265 - accuracy: 0.7607 - val_loss: 39.3612 - val_accuracy: 0.5933\n",
            "Epoch 117/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5299 - accuracy: 0.7775 - val_loss: 25.7196 - val_accuracy: 0.6067\n",
            "Epoch 118/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5217 - accuracy: 0.7884 - val_loss: 32.3640 - val_accuracy: 0.5933\n",
            "Epoch 119/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.4897 - accuracy: 0.7994 - val_loss: 20.3813 - val_accuracy: 0.5933\n",
            "Epoch 120/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4871 - accuracy: 0.8067 - val_loss: 27.8400 - val_accuracy: 0.5933\n",
            "Epoch 121/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.5066 - accuracy: 0.7711 - val_loss: 20.3394 - val_accuracy: 0.6267\n",
            "Epoch 122/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5063 - accuracy: 0.7846 - val_loss: 28.2669 - val_accuracy: 0.5867\n",
            "Epoch 123/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4770 - accuracy: 0.8160 - val_loss: 28.5720 - val_accuracy: 0.6200\n",
            "Epoch 124/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.5011 - accuracy: 0.7764 - val_loss: 35.1859 - val_accuracy: 0.5867\n",
            "Epoch 125/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.5002 - accuracy: 0.7918 - val_loss: 23.7727 - val_accuracy: 0.6000\n",
            "Epoch 126/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.5168 - accuracy: 0.7774 - val_loss: 39.6005 - val_accuracy: 0.5533\n",
            "Epoch 127/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.5173 - accuracy: 0.7789 - val_loss: 27.3927 - val_accuracy: 0.6000\n",
            "Epoch 128/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.5167 - accuracy: 0.7792 - val_loss: 24.7790 - val_accuracy: 0.6067\n",
            "Epoch 129/200\n",
            "53/53 [==============================] - 20s 374ms/step - loss: 0.5002 - accuracy: 0.7999 - val_loss: 28.2343 - val_accuracy: 0.5800\n",
            "Epoch 130/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.5265 - accuracy: 0.7773 - val_loss: 39.1499 - val_accuracy: 0.5867\n",
            "Epoch 131/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5185 - accuracy: 0.7801 - val_loss: 28.0705 - val_accuracy: 0.5867\n",
            "Epoch 132/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.5053 - accuracy: 0.7802 - val_loss: 28.0671 - val_accuracy: 0.5933\n",
            "Epoch 133/200\n",
            "53/53 [==============================] - 19s 359ms/step - loss: 0.4821 - accuracy: 0.7958 - val_loss: 33.0796 - val_accuracy: 0.5933\n",
            "Epoch 134/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.4835 - accuracy: 0.8005 - val_loss: 35.5453 - val_accuracy: 0.5467\n",
            "Epoch 135/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.4899 - accuracy: 0.7939 - val_loss: 31.1616 - val_accuracy: 0.6000\n",
            "Epoch 136/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.4888 - accuracy: 0.7866 - val_loss: 21.8028 - val_accuracy: 0.6267\n",
            "Epoch 137/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4686 - accuracy: 0.8131 - val_loss: 35.4640 - val_accuracy: 0.5600\n",
            "Epoch 138/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.5106 - accuracy: 0.7962 - val_loss: 27.7377 - val_accuracy: 0.6000\n",
            "Epoch 139/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.4913 - accuracy: 0.7965 - val_loss: 29.3149 - val_accuracy: 0.5867\n",
            "Epoch 140/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4766 - accuracy: 0.8144 - val_loss: 39.5682 - val_accuracy: 0.5800\n",
            "Epoch 141/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.5004 - accuracy: 0.7951 - val_loss: 44.3873 - val_accuracy: 0.5533\n",
            "Epoch 142/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.5062 - accuracy: 0.7825 - val_loss: 24.4818 - val_accuracy: 0.6067\n",
            "Epoch 143/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.4581 - accuracy: 0.8084 - val_loss: 31.5178 - val_accuracy: 0.5933\n",
            "Epoch 144/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.4913 - accuracy: 0.8101 - val_loss: 29.8635 - val_accuracy: 0.6133\n",
            "Epoch 145/200\n",
            "53/53 [==============================] - 19s 363ms/step - loss: 0.4848 - accuracy: 0.7992 - val_loss: 25.0232 - val_accuracy: 0.6267\n",
            "Epoch 146/200\n",
            "53/53 [==============================] - 19s 359ms/step - loss: 0.4891 - accuracy: 0.8032 - val_loss: 30.9654 - val_accuracy: 0.5800\n",
            "Epoch 147/200\n",
            "53/53 [==============================] - 19s 358ms/step - loss: 0.4562 - accuracy: 0.8036 - val_loss: 35.3653 - val_accuracy: 0.5600\n",
            "Epoch 148/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.4858 - accuracy: 0.7969 - val_loss: 32.7165 - val_accuracy: 0.6000\n",
            "Epoch 149/200\n",
            "53/53 [==============================] - 19s 367ms/step - loss: 0.4683 - accuracy: 0.8145 - val_loss: 28.7737 - val_accuracy: 0.6133\n",
            "Epoch 150/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.4708 - accuracy: 0.8033 - val_loss: 29.7380 - val_accuracy: 0.6067\n",
            "Epoch 151/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.4849 - accuracy: 0.7940 - val_loss: 26.8829 - val_accuracy: 0.6000\n",
            "Epoch 152/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.4986 - accuracy: 0.7801 - val_loss: 31.9454 - val_accuracy: 0.5867\n",
            "Epoch 153/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.4469 - accuracy: 0.8125 - val_loss: 35.1903 - val_accuracy: 0.5667\n",
            "Epoch 154/200\n",
            "53/53 [==============================] - 19s 359ms/step - loss: 0.4688 - accuracy: 0.8035 - val_loss: 35.2428 - val_accuracy: 0.5800\n",
            "Epoch 155/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.4513 - accuracy: 0.8225 - val_loss: 31.8380 - val_accuracy: 0.5933\n",
            "Epoch 156/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.4792 - accuracy: 0.8079 - val_loss: 27.5296 - val_accuracy: 0.6133\n",
            "Epoch 157/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.4851 - accuracy: 0.7992 - val_loss: 34.4694 - val_accuracy: 0.5867\n",
            "Epoch 158/200\n",
            "53/53 [==============================] - 19s 358ms/step - loss: 0.4655 - accuracy: 0.8042 - val_loss: 31.4000 - val_accuracy: 0.5867\n",
            "Epoch 159/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.4576 - accuracy: 0.8091 - val_loss: 29.9493 - val_accuracy: 0.6000\n",
            "Epoch 160/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.4323 - accuracy: 0.8263 - val_loss: 43.3287 - val_accuracy: 0.5800\n",
            "Epoch 161/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.4579 - accuracy: 0.8170 - val_loss: 23.3670 - val_accuracy: 0.6200\n",
            "Epoch 162/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4743 - accuracy: 0.7968 - val_loss: 37.1723 - val_accuracy: 0.5800\n",
            "Epoch 163/200\n",
            "53/53 [==============================] - 19s 359ms/step - loss: 0.4698 - accuracy: 0.7911 - val_loss: 25.0860 - val_accuracy: 0.6067\n",
            "Epoch 164/200\n",
            "53/53 [==============================] - 19s 359ms/step - loss: 0.4822 - accuracy: 0.8044 - val_loss: 33.4027 - val_accuracy: 0.5800\n",
            "Epoch 165/200\n",
            "53/53 [==============================] - 19s 359ms/step - loss: 0.4534 - accuracy: 0.8052 - val_loss: 25.0376 - val_accuracy: 0.6067\n",
            "Epoch 166/200\n",
            "53/53 [==============================] - 19s 357ms/step - loss: 0.4769 - accuracy: 0.7997 - val_loss: 34.3639 - val_accuracy: 0.6133\n",
            "Epoch 167/200\n",
            "53/53 [==============================] - 19s 360ms/step - loss: 0.4715 - accuracy: 0.8013 - val_loss: 33.5921 - val_accuracy: 0.5933\n",
            "Epoch 168/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4523 - accuracy: 0.8144 - val_loss: 39.6201 - val_accuracy: 0.6000\n",
            "Epoch 169/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.4600 - accuracy: 0.8088 - val_loss: 31.5980 - val_accuracy: 0.5800\n",
            "Epoch 170/200\n",
            "53/53 [==============================] - 19s 359ms/step - loss: 0.4739 - accuracy: 0.8034 - val_loss: 34.1831 - val_accuracy: 0.6000\n",
            "Epoch 171/200\n",
            "53/53 [==============================] - 19s 362ms/step - loss: 0.4546 - accuracy: 0.8082 - val_loss: 29.7622 - val_accuracy: 0.5867\n",
            "Epoch 172/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4612 - accuracy: 0.8150 - val_loss: 34.9303 - val_accuracy: 0.5200\n",
            "Epoch 173/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.4711 - accuracy: 0.8015 - val_loss: 33.3400 - val_accuracy: 0.6000\n",
            "Epoch 174/200\n",
            "53/53 [==============================] - 19s 361ms/step - loss: 0.4369 - accuracy: 0.8211 - val_loss: 33.7332 - val_accuracy: 0.5600\n",
            "Epoch 175/200\n",
            "53/53 [==============================] - 20s 377ms/step - loss: 0.4528 - accuracy: 0.8190 - val_loss: 28.0059 - val_accuracy: 0.6000\n",
            "Epoch 176/200\n",
            "53/53 [==============================] - 20s 377ms/step - loss: 0.4680 - accuracy: 0.8074 - val_loss: 23.9815 - val_accuracy: 0.6000\n",
            "Epoch 177/200\n",
            "53/53 [==============================] - 20s 379ms/step - loss: 0.4345 - accuracy: 0.8185 - val_loss: 25.7008 - val_accuracy: 0.5933\n",
            "Epoch 178/200\n",
            "53/53 [==============================] - 20s 378ms/step - loss: 0.4344 - accuracy: 0.8194 - val_loss: 33.2091 - val_accuracy: 0.6067\n",
            "Epoch 179/200\n",
            "53/53 [==============================] - 20s 377ms/step - loss: 0.4169 - accuracy: 0.8343 - val_loss: 28.8433 - val_accuracy: 0.5867\n",
            "Epoch 180/200\n",
            "53/53 [==============================] - 20s 381ms/step - loss: 0.4453 - accuracy: 0.8245 - val_loss: 30.8693 - val_accuracy: 0.5933\n",
            "Epoch 181/200\n",
            "53/53 [==============================] - 20s 385ms/step - loss: 0.4464 - accuracy: 0.8250 - val_loss: 43.5633 - val_accuracy: 0.5667\n",
            "Epoch 182/200\n",
            "53/53 [==============================] - 20s 380ms/step - loss: 0.4409 - accuracy: 0.8218 - val_loss: 35.7263 - val_accuracy: 0.6000\n",
            "Epoch 183/200\n",
            "53/53 [==============================] - 20s 378ms/step - loss: 0.4502 - accuracy: 0.8182 - val_loss: 38.3180 - val_accuracy: 0.5600\n",
            "Epoch 184/200\n",
            "53/53 [==============================] - 20s 374ms/step - loss: 0.4390 - accuracy: 0.8184 - val_loss: 22.8135 - val_accuracy: 0.6333\n",
            "Epoch 185/200\n",
            "53/53 [==============================] - 20s 369ms/step - loss: 0.4522 - accuracy: 0.8075 - val_loss: 30.2512 - val_accuracy: 0.6067\n",
            "Epoch 186/200\n",
            "53/53 [==============================] - 20s 370ms/step - loss: 0.4653 - accuracy: 0.8102 - val_loss: 28.3113 - val_accuracy: 0.5867\n",
            "Epoch 187/200\n",
            "53/53 [==============================] - 20s 376ms/step - loss: 0.4622 - accuracy: 0.8137 - val_loss: 28.6443 - val_accuracy: 0.6133\n",
            "Epoch 188/200\n",
            "53/53 [==============================] - 20s 373ms/step - loss: 0.4359 - accuracy: 0.8225 - val_loss: 32.3847 - val_accuracy: 0.6067\n",
            "Epoch 189/200\n",
            "53/53 [==============================] - 20s 371ms/step - loss: 0.4453 - accuracy: 0.8275 - val_loss: 33.1851 - val_accuracy: 0.5733\n",
            "Epoch 190/200\n",
            "53/53 [==============================] - 20s 370ms/step - loss: 0.4471 - accuracy: 0.8075 - val_loss: 47.5428 - val_accuracy: 0.5467\n",
            "Epoch 191/200\n",
            "53/53 [==============================] - 20s 370ms/step - loss: 0.4449 - accuracy: 0.8221 - val_loss: 29.2702 - val_accuracy: 0.6133\n",
            "Epoch 192/200\n",
            "53/53 [==============================] - 20s 371ms/step - loss: 0.4316 - accuracy: 0.8319 - val_loss: 28.1565 - val_accuracy: 0.6067\n",
            "Epoch 193/200\n",
            "53/53 [==============================] - 20s 372ms/step - loss: 0.4256 - accuracy: 0.8340 - val_loss: 34.4074 - val_accuracy: 0.6000\n",
            "Epoch 194/200\n",
            "53/53 [==============================] - 20s 367ms/step - loss: 0.4253 - accuracy: 0.8337 - val_loss: 37.7472 - val_accuracy: 0.6000\n",
            "Epoch 195/200\n",
            "53/53 [==============================] - 20s 373ms/step - loss: 0.4564 - accuracy: 0.8104 - val_loss: 33.0721 - val_accuracy: 0.5733\n",
            "Epoch 196/200\n",
            "53/53 [==============================] - 20s 371ms/step - loss: 0.4294 - accuracy: 0.8208 - val_loss: 33.8470 - val_accuracy: 0.5867\n",
            "Epoch 197/200\n",
            "53/53 [==============================] - 20s 373ms/step - loss: 0.4110 - accuracy: 0.8335 - val_loss: 32.1334 - val_accuracy: 0.6067\n",
            "Epoch 198/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.4213 - accuracy: 0.8307 - val_loss: 32.1234 - val_accuracy: 0.5933\n",
            "Epoch 199/200\n",
            "53/53 [==============================] - 19s 365ms/step - loss: 0.4253 - accuracy: 0.8254 - val_loss: 26.0708 - val_accuracy: 0.6133\n",
            "Epoch 200/200\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 0.4370 - accuracy: 0.8203 - val_loss: 31.5688 - val_accuracy: 0.6000\n",
            "Train Accuracy of the model is 0.6446682875998611\n",
            "Test Accuracy of the model is 0.6\n",
            "55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.33, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4j-ALPqgtSV"
      },
      "source": [
        "**Selfmade Model 7**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HGQLiaEtaim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f5f7fc-e9c7-4227-c76d-5d54b4f906f3"
      },
      "source": [
        "# Define our CNN\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(Dropout(0.5)) # Dropout is optional.\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.5)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.6)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.6)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.5)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(32, activation='relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax')) \r\n",
        "\r\n",
        "#apply learning rate\r\n",
        "opt = optimizers.Adam(learning_rate=0.0001)\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=0.0001,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "\r\n",
        "#fit call to use the datagen. 50 epichs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 50 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "plt.xlim([0, 1])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_77 (Conv2D)           (None, 32, 55, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_99 (Batc (None, 32, 55, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_92 (Dropout)         (None, 32, 55, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_77 (MaxPooling (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 16, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_93 (Dropout)         (None, 16, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_100 (Bat (None, 16, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_78 (MaxPooling (None, 8, 14, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 8, 14, 128)        73856     \n",
            "_________________________________________________________________\n",
            "dropout_94 (Dropout)         (None, 8, 14, 128)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_101 (Bat (None, 8, 14, 128)        512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_79 (MaxPooling (None, 4, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 4, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "dropout_95 (Dropout)         (None, 4, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_102 (Bat (None, 4, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_80 (MaxPooling (None, 2, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 2, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "dropout_96 (Dropout)         (None, 2, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_103 (Bat (None, 2, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_81 (MaxPooling (None, 1, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 1, 2, 256)         590080    \n",
            "_________________________________________________________________\n",
            "dropout_97 (Dropout)         (None, 1, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_104 (Bat (None, 1, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_82 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 1, 1, 64)          147520    \n",
            "_________________________________________________________________\n",
            "dropout_98 (Dropout)         (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_105 (Bat (None, 1, 1, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_83 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_99 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_106 (Bat (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,279,619\n",
            "Trainable params: 1,277,699\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "90/90 [==============================] - 34s 359ms/step - loss: 1.6094 - accuracy: 0.3419 - val_loss: 4.5100 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "90/90 [==============================] - 32s 360ms/step - loss: 1.4318 - accuracy: 0.4017 - val_loss: 9.3513 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "90/90 [==============================] - 31s 346ms/step - loss: 1.2513 - accuracy: 0.4527 - val_loss: 13.7828 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "90/90 [==============================] - 31s 339ms/step - loss: 1.2132 - accuracy: 0.4621 - val_loss: 19.8812 - val_accuracy: 0.4533\n",
            "Epoch 5/50\n",
            "90/90 [==============================] - 31s 340ms/step - loss: 1.2207 - accuracy: 0.4745 - val_loss: 32.2648 - val_accuracy: 0.3467\n",
            "Epoch 6/50\n",
            "90/90 [==============================] - 31s 340ms/step - loss: 1.1823 - accuracy: 0.4817 - val_loss: 28.4848 - val_accuracy: 0.4867\n",
            "Epoch 7/50\n",
            "90/90 [==============================] - 31s 340ms/step - loss: 1.1190 - accuracy: 0.5201 - val_loss: 32.7526 - val_accuracy: 0.4933\n",
            "Epoch 8/50\n",
            "90/90 [==============================] - 30s 337ms/step - loss: 1.1147 - accuracy: 0.5171 - val_loss: 43.4236 - val_accuracy: 0.5133\n",
            "Epoch 9/50\n",
            "90/90 [==============================] - 31s 342ms/step - loss: 1.0893 - accuracy: 0.5264 - val_loss: 35.8590 - val_accuracy: 0.5067\n",
            "Epoch 10/50\n",
            "90/90 [==============================] - 31s 343ms/step - loss: 1.0923 - accuracy: 0.5260 - val_loss: 38.2215 - val_accuracy: 0.5067\n",
            "Epoch 11/50\n",
            "90/90 [==============================] - 31s 340ms/step - loss: 1.0447 - accuracy: 0.5181 - val_loss: 31.6703 - val_accuracy: 0.5133\n",
            "Epoch 12/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 1.0107 - accuracy: 0.5303 - val_loss: 26.8418 - val_accuracy: 0.5067\n",
            "Epoch 13/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.9893 - accuracy: 0.5436 - val_loss: 33.0304 - val_accuracy: 0.4867\n",
            "Epoch 14/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.9518 - accuracy: 0.5568 - val_loss: 39.3968 - val_accuracy: 0.4600\n",
            "Epoch 15/50\n",
            "90/90 [==============================] - 31s 339ms/step - loss: 1.0241 - accuracy: 0.5392 - val_loss: 38.7239 - val_accuracy: 0.4800\n",
            "Epoch 16/50\n",
            "90/90 [==============================] - 31s 343ms/step - loss: 0.9685 - accuracy: 0.5491 - val_loss: 39.4928 - val_accuracy: 0.5067\n",
            "Epoch 17/50\n",
            "90/90 [==============================] - 31s 344ms/step - loss: 0.9913 - accuracy: 0.5299 - val_loss: 32.2643 - val_accuracy: 0.5067\n",
            "Epoch 18/50\n",
            "90/90 [==============================] - 31s 339ms/step - loss: 0.9493 - accuracy: 0.5743 - val_loss: 37.2769 - val_accuracy: 0.5067\n",
            "Epoch 19/50\n",
            "90/90 [==============================] - 31s 339ms/step - loss: 0.9102 - accuracy: 0.5692 - val_loss: 33.4552 - val_accuracy: 0.5267\n",
            "Epoch 20/50\n",
            "90/90 [==============================] - 31s 344ms/step - loss: 0.9288 - accuracy: 0.5785 - val_loss: 40.3665 - val_accuracy: 0.4400\n",
            "Epoch 21/50\n",
            "90/90 [==============================] - 31s 344ms/step - loss: 0.9273 - accuracy: 0.5428 - val_loss: 31.7074 - val_accuracy: 0.5067\n",
            "Epoch 22/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.8787 - accuracy: 0.5763 - val_loss: 34.6750 - val_accuracy: 0.4867\n",
            "Epoch 23/50\n",
            "90/90 [==============================] - 31s 339ms/step - loss: 0.9199 - accuracy: 0.5619 - val_loss: 33.6436 - val_accuracy: 0.5067\n",
            "Epoch 24/50\n",
            "90/90 [==============================] - 30s 338ms/step - loss: 0.8883 - accuracy: 0.5845 - val_loss: 26.2952 - val_accuracy: 0.5267\n",
            "Epoch 25/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.8717 - accuracy: 0.5755 - val_loss: 25.3755 - val_accuracy: 0.5333\n",
            "Epoch 26/50\n",
            "90/90 [==============================] - 31s 343ms/step - loss: 0.8733 - accuracy: 0.5968 - val_loss: 21.3948 - val_accuracy: 0.5200\n",
            "Epoch 27/50\n",
            "90/90 [==============================] - 31s 345ms/step - loss: 0.8843 - accuracy: 0.5944 - val_loss: 34.3439 - val_accuracy: 0.5133\n",
            "Epoch 28/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.8903 - accuracy: 0.5713 - val_loss: 32.1720 - val_accuracy: 0.5133\n",
            "Epoch 29/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.8825 - accuracy: 0.5761 - val_loss: 26.7452 - val_accuracy: 0.5267\n",
            "Epoch 30/50\n",
            "90/90 [==============================] - 32s 352ms/step - loss: 0.8325 - accuracy: 0.5986 - val_loss: 26.9906 - val_accuracy: 0.5267\n",
            "Epoch 31/50\n",
            "90/90 [==============================] - 32s 353ms/step - loss: 0.8853 - accuracy: 0.5665 - val_loss: 49.0966 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "90/90 [==============================] - 31s 348ms/step - loss: 0.8713 - accuracy: 0.5952 - val_loss: 46.3263 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "90/90 [==============================] - 31s 346ms/step - loss: 0.8691 - accuracy: 0.5930 - val_loss: 49.8809 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "90/90 [==============================] - 31s 340ms/step - loss: 0.8822 - accuracy: 0.5744 - val_loss: 24.7529 - val_accuracy: 0.5600\n",
            "Epoch 35/50\n",
            "90/90 [==============================] - 31s 344ms/step - loss: 0.8291 - accuracy: 0.6029 - val_loss: 36.1180 - val_accuracy: 0.5067\n",
            "Epoch 36/50\n",
            "90/90 [==============================] - 31s 342ms/step - loss: 0.8330 - accuracy: 0.5957 - val_loss: 32.7073 - val_accuracy: 0.5200\n",
            "Epoch 37/50\n",
            "90/90 [==============================] - 31s 340ms/step - loss: 0.8420 - accuracy: 0.5925 - val_loss: 34.4629 - val_accuracy: 0.5267\n",
            "Epoch 38/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.8275 - accuracy: 0.5924 - val_loss: 27.3822 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "90/90 [==============================] - 31s 342ms/step - loss: 0.8351 - accuracy: 0.6053 - val_loss: 39.6562 - val_accuracy: 0.5067\n",
            "Epoch 40/50\n",
            "90/90 [==============================] - 31s 339ms/step - loss: 0.8395 - accuracy: 0.5946 - val_loss: 43.0133 - val_accuracy: 0.5067\n",
            "Epoch 41/50\n",
            "90/90 [==============================] - 31s 339ms/step - loss: 0.7719 - accuracy: 0.6345 - val_loss: 27.9834 - val_accuracy: 0.5333\n",
            "Epoch 42/50\n",
            "90/90 [==============================] - 31s 340ms/step - loss: 0.8433 - accuracy: 0.5863 - val_loss: 20.6759 - val_accuracy: 0.5200\n",
            "Epoch 43/50\n",
            "90/90 [==============================] - 31s 342ms/step - loss: 0.8036 - accuracy: 0.6107 - val_loss: 37.8471 - val_accuracy: 0.4933\n",
            "Epoch 44/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.8089 - accuracy: 0.6092 - val_loss: 48.9606 - val_accuracy: 0.4400\n",
            "Epoch 45/50\n",
            "90/90 [==============================] - 31s 342ms/step - loss: 0.7976 - accuracy: 0.6084 - val_loss: 33.2165 - val_accuracy: 0.5133\n",
            "Epoch 46/50\n",
            "90/90 [==============================] - 31s 341ms/step - loss: 0.7892 - accuracy: 0.6206 - val_loss: 20.5645 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "58/90 [==================>...........] - ETA: 11s - loss: 0.7861 - accuracy: 0.6257"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1iXk1dugzJs"
      },
      "source": [
        "**Selfmade Model 8**\r\n",
        "\r\n",
        "Small Network high Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qEHY7z9lKhUU",
        "outputId": "aeefb7e4-59fa-4b3f-d59b-077b4b8a31a6"
      },
      "source": [
        "# Define our CNN\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(16, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.5)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax')) \r\n",
        "\r\n",
        "#apply learning rate\r\n",
        "opt = optimizers.Adam(learning_rate=0.00005)\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=0.0001,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "\r\n",
        "#fit call to use the datagen. 100 epichs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 100 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 32, 55, 16)        448       \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 32, 55, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 32, 55, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 16, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 16, 28, 32)        4640      \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 16, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 8, 14, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 14, 32)         9248      \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 8, 14, 32)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 8, 14, 32)         128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 4, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                14352     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 29,123\n",
            "Trainable params: 28,931\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "90/90 [==============================] - 11s 112ms/step - loss: 1.5144 - accuracy: 0.3867 - val_loss: 35.4333 - val_accuracy: 0.3667\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 1.2725 - accuracy: 0.4520 - val_loss: 51.2637 - val_accuracy: 0.4333\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 1.1851 - accuracy: 0.4856 - val_loss: 87.9758 - val_accuracy: 0.4600\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 1.1116 - accuracy: 0.5088 - val_loss: 132.0913 - val_accuracy: 0.4600\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 1.1292 - accuracy: 0.5093 - val_loss: 178.1247 - val_accuracy: 0.4867\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 1.0921 - accuracy: 0.5243 - val_loss: 213.2317 - val_accuracy: 0.4800\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 1.0648 - accuracy: 0.5528 - val_loss: 268.5890 - val_accuracy: 0.4933\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 1.0303 - accuracy: 0.5481 - val_loss: 285.9161 - val_accuracy: 0.4733\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 1.0047 - accuracy: 0.5502 - val_loss: 280.4713 - val_accuracy: 0.4800\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.9986 - accuracy: 0.5550 - val_loss: 282.9062 - val_accuracy: 0.4933\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.9533 - accuracy: 0.5609 - val_loss: 285.4700 - val_accuracy: 0.4933\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.9258 - accuracy: 0.5880 - val_loss: 281.4149 - val_accuracy: 0.4933\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.9515 - accuracy: 0.5679 - val_loss: 258.4519 - val_accuracy: 0.4867\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.9459 - accuracy: 0.5866 - val_loss: 256.1928 - val_accuracy: 0.4933\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9155 - accuracy: 0.5917 - val_loss: 264.1035 - val_accuracy: 0.4800\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8745 - accuracy: 0.5932 - val_loss: 245.9628 - val_accuracy: 0.4933\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9131 - accuracy: 0.5980 - val_loss: 241.8707 - val_accuracy: 0.4933\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8831 - accuracy: 0.6094 - val_loss: 253.4748 - val_accuracy: 0.4933\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.9305 - accuracy: 0.5971 - val_loss: 265.0318 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9028 - accuracy: 0.5957 - val_loss: 237.7328 - val_accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8733 - accuracy: 0.6011 - val_loss: 216.3480 - val_accuracy: 0.5067\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8574 - accuracy: 0.6024 - val_loss: 216.8651 - val_accuracy: 0.5067\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 0.8637 - accuracy: 0.6139 - val_loss: 208.9291 - val_accuracy: 0.4867\n",
            "Epoch 24/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8858 - accuracy: 0.5879 - val_loss: 203.4473 - val_accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8534 - accuracy: 0.6023 - val_loss: 203.2592 - val_accuracy: 0.4933\n",
            "Epoch 26/100\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 0.8581 - accuracy: 0.6139 - val_loss: 211.9489 - val_accuracy: 0.4933\n",
            "Epoch 27/100\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 0.8371 - accuracy: 0.6183 - val_loss: 190.6469 - val_accuracy: 0.4933\n",
            "Epoch 28/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8460 - accuracy: 0.5974 - val_loss: 195.5105 - val_accuracy: 0.5067\n",
            "Epoch 29/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8406 - accuracy: 0.6184 - val_loss: 193.3727 - val_accuracy: 0.5067\n",
            "Epoch 30/100\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 0.8273 - accuracy: 0.6114 - val_loss: 191.0072 - val_accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8346 - accuracy: 0.6170 - val_loss: 180.1662 - val_accuracy: 0.5133\n",
            "Epoch 32/100\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 0.8167 - accuracy: 0.6216 - val_loss: 181.5780 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.8296 - accuracy: 0.6146 - val_loss: 188.1619 - val_accuracy: 0.5067\n",
            "Epoch 34/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.8086 - accuracy: 0.6318 - val_loss: 176.9041 - val_accuracy: 0.5133\n",
            "Epoch 35/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8222 - accuracy: 0.6196 - val_loss: 172.8232 - val_accuracy: 0.5133\n",
            "Epoch 36/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8070 - accuracy: 0.6166 - val_loss: 167.9162 - val_accuracy: 0.5067\n",
            "Epoch 37/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.8128 - accuracy: 0.6104 - val_loss: 160.1725 - val_accuracy: 0.5067\n",
            "Epoch 38/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.8322 - accuracy: 0.6156 - val_loss: 165.6991 - val_accuracy: 0.5067\n",
            "Epoch 39/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8128 - accuracy: 0.6269 - val_loss: 174.9674 - val_accuracy: 0.5133\n",
            "Epoch 40/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.8092 - accuracy: 0.6423 - val_loss: 195.4071 - val_accuracy: 0.5400\n",
            "Epoch 41/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7868 - accuracy: 0.6305 - val_loss: 171.1868 - val_accuracy: 0.5333\n",
            "Epoch 42/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8182 - accuracy: 0.6273 - val_loss: 176.9064 - val_accuracy: 0.5533\n",
            "Epoch 43/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7728 - accuracy: 0.6308 - val_loss: 172.9421 - val_accuracy: 0.5467\n",
            "Epoch 44/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7985 - accuracy: 0.6326 - val_loss: 156.0112 - val_accuracy: 0.5200\n",
            "Epoch 45/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7921 - accuracy: 0.6295 - val_loss: 159.0850 - val_accuracy: 0.5200\n",
            "Epoch 46/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8058 - accuracy: 0.6062 - val_loss: 148.3740 - val_accuracy: 0.5467\n",
            "Epoch 47/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7862 - accuracy: 0.6542 - val_loss: 162.7388 - val_accuracy: 0.5467\n",
            "Epoch 48/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7749 - accuracy: 0.6397 - val_loss: 179.1970 - val_accuracy: 0.5267\n",
            "Epoch 49/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7887 - accuracy: 0.6286 - val_loss: 138.1393 - val_accuracy: 0.5267\n",
            "Epoch 50/100\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.7319 - accuracy: 0.6605 - val_loss: 172.7903 - val_accuracy: 0.5333\n",
            "Epoch 51/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7608 - accuracy: 0.6392 - val_loss: 159.7086 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7597 - accuracy: 0.6520 - val_loss: 177.1794 - val_accuracy: 0.5533\n",
            "Epoch 53/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7558 - accuracy: 0.6361 - val_loss: 193.8217 - val_accuracy: 0.5333\n",
            "Epoch 54/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7499 - accuracy: 0.6561 - val_loss: 219.7309 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7571 - accuracy: 0.6550 - val_loss: 151.5860 - val_accuracy: 0.5533\n",
            "Epoch 56/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7799 - accuracy: 0.6531 - val_loss: 142.5047 - val_accuracy: 0.5200\n",
            "Epoch 57/100\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7499 - accuracy: 0.6552 - val_loss: 152.7812 - val_accuracy: 0.5533\n",
            "Epoch 58/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7584 - accuracy: 0.6616 - val_loss: 145.3517 - val_accuracy: 0.5600\n",
            "Epoch 59/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7593 - accuracy: 0.6594 - val_loss: 148.3418 - val_accuracy: 0.5533\n",
            "Epoch 60/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7692 - accuracy: 0.6439 - val_loss: 135.3638 - val_accuracy: 0.5200\n",
            "Epoch 61/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.7523 - accuracy: 0.6524 - val_loss: 127.1561 - val_accuracy: 0.5533\n",
            "Epoch 62/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.7786 - accuracy: 0.6431 - val_loss: 130.9811 - val_accuracy: 0.5267\n",
            "Epoch 63/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7613 - accuracy: 0.6554 - val_loss: 154.8475 - val_accuracy: 0.5333\n",
            "Epoch 64/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7442 - accuracy: 0.6466 - val_loss: 128.8085 - val_accuracy: 0.5533\n",
            "Epoch 65/100\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.7358 - accuracy: 0.6692 - val_loss: 129.2678 - val_accuracy: 0.5667\n",
            "Epoch 66/100\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7210 - accuracy: 0.6693 - val_loss: 148.0100 - val_accuracy: 0.5200\n",
            "Epoch 67/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7571 - accuracy: 0.6399 - val_loss: 153.2567 - val_accuracy: 0.5267\n",
            "Epoch 68/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7250 - accuracy: 0.6761 - val_loss: 152.1888 - val_accuracy: 0.5133\n",
            "Epoch 69/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7484 - accuracy: 0.6600 - val_loss: 119.5394 - val_accuracy: 0.5467\n",
            "Epoch 70/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7453 - accuracy: 0.6690 - val_loss: 133.5048 - val_accuracy: 0.5600\n",
            "Epoch 71/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7224 - accuracy: 0.6761 - val_loss: 144.0000 - val_accuracy: 0.5467\n",
            "Epoch 72/100\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7595 - accuracy: 0.6623 - val_loss: 125.9091 - val_accuracy: 0.5467\n",
            "Epoch 73/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.7536 - accuracy: 0.6582 - val_loss: 179.0189 - val_accuracy: 0.4933\n",
            "Epoch 74/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.7346 - accuracy: 0.6698 - val_loss: 130.6461 - val_accuracy: 0.5333\n",
            "Epoch 75/100\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7155 - accuracy: 0.6823 - val_loss: 138.9953 - val_accuracy: 0.5467\n",
            "Epoch 76/100\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.7357 - accuracy: 0.6631 - val_loss: 170.5797 - val_accuracy: 0.5067\n",
            "Epoch 77/100\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7176 - accuracy: 0.6598 - val_loss: 140.6633 - val_accuracy: 0.5600\n",
            "Epoch 78/100\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7190 - accuracy: 0.6588 - val_loss: 122.3171 - val_accuracy: 0.5400\n",
            "Epoch 79/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7260 - accuracy: 0.6667 - val_loss: 151.6273 - val_accuracy: 0.5467\n",
            "Epoch 80/100\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.7397 - accuracy: 0.6610 - val_loss: 173.0716 - val_accuracy: 0.5200\n",
            "Epoch 81/100\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.7187 - accuracy: 0.6763 - val_loss: 143.7580 - val_accuracy: 0.5333\n",
            "Epoch 82/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.7211 - accuracy: 0.6706 - val_loss: 135.0861 - val_accuracy: 0.5467\n",
            "Epoch 83/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7180 - accuracy: 0.6793 - val_loss: 138.0004 - val_accuracy: 0.5600\n",
            "Epoch 84/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7172 - accuracy: 0.6732 - val_loss: 119.4733 - val_accuracy: 0.5467\n",
            "Epoch 85/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7109 - accuracy: 0.6869 - val_loss: 127.4599 - val_accuracy: 0.5333\n",
            "Epoch 86/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7091 - accuracy: 0.6741 - val_loss: 140.3839 - val_accuracy: 0.5467\n",
            "Epoch 87/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7346 - accuracy: 0.6700 - val_loss: 138.4032 - val_accuracy: 0.5467\n",
            "Epoch 88/100\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7037 - accuracy: 0.6716 - val_loss: 154.2677 - val_accuracy: 0.5067\n",
            "Epoch 89/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7254 - accuracy: 0.6678 - val_loss: 144.5690 - val_accuracy: 0.5400\n",
            "Epoch 90/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7126 - accuracy: 0.6704 - val_loss: 144.8489 - val_accuracy: 0.5667\n",
            "Epoch 91/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7173 - accuracy: 0.6719 - val_loss: 125.0163 - val_accuracy: 0.5467\n",
            "Epoch 92/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6992 - accuracy: 0.6748 - val_loss: 141.9704 - val_accuracy: 0.5533\n",
            "Epoch 93/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.7057 - accuracy: 0.6779 - val_loss: 138.9288 - val_accuracy: 0.5600\n",
            "Epoch 94/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7148 - accuracy: 0.6648 - val_loss: 121.7131 - val_accuracy: 0.5533\n",
            "Epoch 95/100\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7171 - accuracy: 0.6701 - val_loss: 129.9987 - val_accuracy: 0.5600\n",
            "Epoch 96/100\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7063 - accuracy: 0.6790 - val_loss: 136.8414 - val_accuracy: 0.5467\n",
            "Epoch 97/100\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.7294 - accuracy: 0.6660 - val_loss: 125.3837 - val_accuracy: 0.5600\n",
            "Epoch 98/100\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.6901 - accuracy: 0.7004 - val_loss: 183.3438 - val_accuracy: 0.4867\n",
            "Epoch 99/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6888 - accuracy: 0.6934 - val_loss: 127.8367 - val_accuracy: 0.5533\n",
            "Epoch 100/100\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6970 - accuracy: 0.6786 - val_loss: 133.6246 - val_accuracy: 0.5533\n",
            "Train Accuracy of the model is 0.5592219520666898\n",
            "Test Accuracy of the model is 0.5533333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzKk50vng-4t"
      },
      "source": [
        "**Selfmade Model 9**\r\n",
        "\r\n",
        "Smal Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGkOOp1Becbg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "643f4add-a95d-4a77-cda5-45087e342086"
      },
      "source": [
        "# Define our CNN\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(16, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:],kernel_regularizer='l2')) # this layer has 32 filters. The filter size is: (3,3)\r\n",
        "model.add(BatchNormalization()) # This is optional to avoid overfitting\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(MaxPool2D((2,2), strides=2, padding='same'))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\r\n",
        "model.add(Dropout(0.5)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dropout(0.1)) # Dropout is optional.\r\n",
        "model.add(BatchNormalization()) # BatchNormalization is optional\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "model.add(Dense(3, activation='softmax')) \r\n",
        "\r\n",
        "#apply learning rate\r\n",
        "opt = optimizers.Adam(learning_rate=0.00005)\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=0.0001,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "\r\n",
        "#fit call to use the datagen. 500 epichs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 500 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_23 (Conv2D)           (None, 32, 55, 16)        448       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 32, 55, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 32, 55, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 16, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 16, 28, 32)        4640      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 16, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 8, 14, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 8, 14, 32)         9248      \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 8, 14, 32)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 8, 14, 32)         128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 4, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 16)                14352     \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 29,123\n",
            "Trainable params: 28,931\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "90/90 [==============================] - 11s 112ms/step - loss: 1.5423 - accuracy: 0.3238 - val_loss: 13.1252 - val_accuracy: 0.3600\n",
            "Epoch 2/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 1.3077 - accuracy: 0.4275 - val_loss: 14.9446 - val_accuracy: 0.4467\n",
            "Epoch 3/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 1.2134 - accuracy: 0.4680 - val_loss: 23.6399 - val_accuracy: 0.4533\n",
            "Epoch 4/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 1.1664 - accuracy: 0.4769 - val_loss: 36.4876 - val_accuracy: 0.4667\n",
            "Epoch 5/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 1.1005 - accuracy: 0.5193 - val_loss: 67.6608 - val_accuracy: 0.4000\n",
            "Epoch 6/500\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 1.0457 - accuracy: 0.5234 - val_loss: 112.2078 - val_accuracy: 0.3600\n",
            "Epoch 7/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 1.0579 - accuracy: 0.5214 - val_loss: 140.5900 - val_accuracy: 0.3600\n",
            "Epoch 8/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 1.0462 - accuracy: 0.5447 - val_loss: 195.6027 - val_accuracy: 0.3600\n",
            "Epoch 9/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 1.0171 - accuracy: 0.5349 - val_loss: 212.9637 - val_accuracy: 0.3600\n",
            "Epoch 10/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9842 - accuracy: 0.5648 - val_loss: 241.2934 - val_accuracy: 0.3533\n",
            "Epoch 11/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9634 - accuracy: 0.5751 - val_loss: 236.8448 - val_accuracy: 0.3533\n",
            "Epoch 12/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9552 - accuracy: 0.5746 - val_loss: 235.4833 - val_accuracy: 0.3600\n",
            "Epoch 13/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.9396 - accuracy: 0.5802 - val_loss: 253.9965 - val_accuracy: 0.3467\n",
            "Epoch 14/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9502 - accuracy: 0.5586 - val_loss: 236.7457 - val_accuracy: 0.3600\n",
            "Epoch 15/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9194 - accuracy: 0.5845 - val_loss: 262.3571 - val_accuracy: 0.3467\n",
            "Epoch 16/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.9001 - accuracy: 0.5918 - val_loss: 241.1153 - val_accuracy: 0.3533\n",
            "Epoch 17/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.9046 - accuracy: 0.5765 - val_loss: 227.3903 - val_accuracy: 0.3667\n",
            "Epoch 18/500\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 0.8869 - accuracy: 0.5922 - val_loss: 217.0495 - val_accuracy: 0.3800\n",
            "Epoch 19/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8616 - accuracy: 0.6114 - val_loss: 227.4975 - val_accuracy: 0.3667\n",
            "Epoch 20/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8945 - accuracy: 0.6031 - val_loss: 203.3535 - val_accuracy: 0.3800\n",
            "Epoch 21/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8893 - accuracy: 0.5866 - val_loss: 220.6078 - val_accuracy: 0.3667\n",
            "Epoch 22/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8554 - accuracy: 0.6172 - val_loss: 209.3704 - val_accuracy: 0.3733\n",
            "Epoch 23/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8558 - accuracy: 0.6252 - val_loss: 186.9936 - val_accuracy: 0.4333\n",
            "Epoch 24/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8299 - accuracy: 0.6140 - val_loss: 196.0195 - val_accuracy: 0.4133\n",
            "Epoch 25/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8218 - accuracy: 0.6215 - val_loss: 220.2892 - val_accuracy: 0.3800\n",
            "Epoch 26/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.8284 - accuracy: 0.6195 - val_loss: 188.3430 - val_accuracy: 0.4333\n",
            "Epoch 27/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8387 - accuracy: 0.6177 - val_loss: 183.7951 - val_accuracy: 0.4467\n",
            "Epoch 28/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8299 - accuracy: 0.6166 - val_loss: 197.4460 - val_accuracy: 0.4333\n",
            "Epoch 29/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8039 - accuracy: 0.6322 - val_loss: 187.9742 - val_accuracy: 0.4400\n",
            "Epoch 30/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8164 - accuracy: 0.6301 - val_loss: 187.0091 - val_accuracy: 0.4533\n",
            "Epoch 31/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8134 - accuracy: 0.6252 - val_loss: 206.3716 - val_accuracy: 0.4333\n",
            "Epoch 32/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.8326 - accuracy: 0.6233 - val_loss: 182.5459 - val_accuracy: 0.4600\n",
            "Epoch 33/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8081 - accuracy: 0.6408 - val_loss: 167.8652 - val_accuracy: 0.5067\n",
            "Epoch 34/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8178 - accuracy: 0.6232 - val_loss: 170.4107 - val_accuracy: 0.5000\n",
            "Epoch 35/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7790 - accuracy: 0.6391 - val_loss: 180.6749 - val_accuracy: 0.4667\n",
            "Epoch 36/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.8147 - accuracy: 0.6300 - val_loss: 183.3183 - val_accuracy: 0.4667\n",
            "Epoch 37/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8033 - accuracy: 0.6404 - val_loss: 176.9700 - val_accuracy: 0.4933\n",
            "Epoch 38/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7896 - accuracy: 0.6395 - val_loss: 184.0445 - val_accuracy: 0.4733\n",
            "Epoch 39/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7831 - accuracy: 0.6497 - val_loss: 144.6215 - val_accuracy: 0.5533\n",
            "Epoch 40/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7554 - accuracy: 0.6563 - val_loss: 194.1516 - val_accuracy: 0.4667\n",
            "Epoch 41/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.8158 - accuracy: 0.6206 - val_loss: 169.0885 - val_accuracy: 0.5133\n",
            "Epoch 42/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7792 - accuracy: 0.6457 - val_loss: 175.2914 - val_accuracy: 0.5000\n",
            "Epoch 43/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7881 - accuracy: 0.6465 - val_loss: 161.2297 - val_accuracy: 0.5333\n",
            "Epoch 44/500\n",
            "90/90 [==============================] - 10s 106ms/step - loss: 0.7811 - accuracy: 0.6623 - val_loss: 170.6313 - val_accuracy: 0.5067\n",
            "Epoch 45/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7507 - accuracy: 0.6734 - val_loss: 164.0082 - val_accuracy: 0.5333\n",
            "Epoch 46/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7422 - accuracy: 0.6592 - val_loss: 169.1348 - val_accuracy: 0.5400\n",
            "Epoch 47/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7515 - accuracy: 0.6609 - val_loss: 164.9492 - val_accuracy: 0.5533\n",
            "Epoch 48/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7902 - accuracy: 0.6445 - val_loss: 164.4179 - val_accuracy: 0.5467\n",
            "Epoch 49/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7457 - accuracy: 0.6686 - val_loss: 144.3523 - val_accuracy: 0.5667\n",
            "Epoch 50/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7622 - accuracy: 0.6606 - val_loss: 149.7943 - val_accuracy: 0.5600\n",
            "Epoch 51/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7602 - accuracy: 0.6575 - val_loss: 151.2614 - val_accuracy: 0.5667\n",
            "Epoch 52/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7382 - accuracy: 0.6739 - val_loss: 162.4601 - val_accuracy: 0.5533\n",
            "Epoch 53/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7367 - accuracy: 0.6746 - val_loss: 174.8979 - val_accuracy: 0.5400\n",
            "Epoch 54/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7549 - accuracy: 0.6680 - val_loss: 163.5811 - val_accuracy: 0.5600\n",
            "Epoch 55/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7558 - accuracy: 0.6779 - val_loss: 156.8181 - val_accuracy: 0.5667\n",
            "Epoch 56/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7639 - accuracy: 0.6621 - val_loss: 150.1991 - val_accuracy: 0.5667\n",
            "Epoch 57/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7476 - accuracy: 0.6614 - val_loss: 178.5147 - val_accuracy: 0.5333\n",
            "Epoch 58/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.7353 - accuracy: 0.6827 - val_loss: 158.5243 - val_accuracy: 0.5667\n",
            "Epoch 59/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7686 - accuracy: 0.6642 - val_loss: 180.1234 - val_accuracy: 0.5533\n",
            "Epoch 60/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7603 - accuracy: 0.6704 - val_loss: 147.3572 - val_accuracy: 0.5733\n",
            "Epoch 61/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7378 - accuracy: 0.6719 - val_loss: 177.6725 - val_accuracy: 0.5533\n",
            "Epoch 62/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.6968 - accuracy: 0.6840 - val_loss: 147.3845 - val_accuracy: 0.5667\n",
            "Epoch 63/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7142 - accuracy: 0.6800 - val_loss: 159.3822 - val_accuracy: 0.5667\n",
            "Epoch 64/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.7206 - accuracy: 0.6764 - val_loss: 152.6333 - val_accuracy: 0.5667\n",
            "Epoch 65/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7317 - accuracy: 0.6686 - val_loss: 174.1222 - val_accuracy: 0.5400\n",
            "Epoch 66/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7245 - accuracy: 0.6723 - val_loss: 171.4952 - val_accuracy: 0.5533\n",
            "Epoch 67/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7387 - accuracy: 0.6657 - val_loss: 135.6403 - val_accuracy: 0.5667\n",
            "Epoch 68/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6940 - accuracy: 0.6884 - val_loss: 161.1700 - val_accuracy: 0.5533\n",
            "Epoch 69/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7142 - accuracy: 0.6776 - val_loss: 175.2234 - val_accuracy: 0.5400\n",
            "Epoch 70/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.7263 - accuracy: 0.6943 - val_loss: 159.5697 - val_accuracy: 0.5667\n",
            "Epoch 71/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6925 - accuracy: 0.6903 - val_loss: 155.1624 - val_accuracy: 0.5667\n",
            "Epoch 72/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7281 - accuracy: 0.6875 - val_loss: 144.4015 - val_accuracy: 0.5667\n",
            "Epoch 73/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7165 - accuracy: 0.6796 - val_loss: 146.9725 - val_accuracy: 0.5533\n",
            "Epoch 74/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6907 - accuracy: 0.6854 - val_loss: 135.6812 - val_accuracy: 0.5667\n",
            "Epoch 75/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7072 - accuracy: 0.6905 - val_loss: 127.0433 - val_accuracy: 0.5733\n",
            "Epoch 76/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7008 - accuracy: 0.6821 - val_loss: 154.9907 - val_accuracy: 0.5600\n",
            "Epoch 77/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6899 - accuracy: 0.6989 - val_loss: 147.9347 - val_accuracy: 0.5600\n",
            "Epoch 78/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7268 - accuracy: 0.6713 - val_loss: 151.1950 - val_accuracy: 0.5667\n",
            "Epoch 79/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7055 - accuracy: 0.6928 - val_loss: 133.6555 - val_accuracy: 0.5733\n",
            "Epoch 80/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7028 - accuracy: 0.6883 - val_loss: 135.0927 - val_accuracy: 0.5800\n",
            "Epoch 81/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7133 - accuracy: 0.6714 - val_loss: 147.7003 - val_accuracy: 0.5733\n",
            "Epoch 82/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6780 - accuracy: 0.7145 - val_loss: 134.7934 - val_accuracy: 0.5800\n",
            "Epoch 83/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6890 - accuracy: 0.6884 - val_loss: 135.3903 - val_accuracy: 0.5733\n",
            "Epoch 84/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.7055 - accuracy: 0.6893 - val_loss: 152.8753 - val_accuracy: 0.5600\n",
            "Epoch 85/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6714 - accuracy: 0.7053 - val_loss: 133.4275 - val_accuracy: 0.5733\n",
            "Epoch 86/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6881 - accuracy: 0.6950 - val_loss: 116.0360 - val_accuracy: 0.5733\n",
            "Epoch 87/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6680 - accuracy: 0.7045 - val_loss: 118.9678 - val_accuracy: 0.5733\n",
            "Epoch 88/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.7000 - accuracy: 0.6898 - val_loss: 120.1677 - val_accuracy: 0.5800\n",
            "Epoch 89/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6878 - accuracy: 0.6954 - val_loss: 107.9869 - val_accuracy: 0.5867\n",
            "Epoch 90/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6870 - accuracy: 0.6968 - val_loss: 125.0182 - val_accuracy: 0.5800\n",
            "Epoch 91/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6758 - accuracy: 0.7004 - val_loss: 126.4806 - val_accuracy: 0.5800\n",
            "Epoch 92/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6738 - accuracy: 0.7062 - val_loss: 120.0160 - val_accuracy: 0.5867\n",
            "Epoch 93/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6885 - accuracy: 0.6894 - val_loss: 144.4654 - val_accuracy: 0.5667\n",
            "Epoch 94/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6898 - accuracy: 0.6892 - val_loss: 132.0521 - val_accuracy: 0.5733\n",
            "Epoch 95/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6855 - accuracy: 0.7088 - val_loss: 117.2525 - val_accuracy: 0.5800\n",
            "Epoch 96/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6798 - accuracy: 0.6886 - val_loss: 141.0321 - val_accuracy: 0.5667\n",
            "Epoch 97/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6903 - accuracy: 0.6956 - val_loss: 147.7645 - val_accuracy: 0.5667\n",
            "Epoch 98/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6942 - accuracy: 0.6920 - val_loss: 136.9240 - val_accuracy: 0.5667\n",
            "Epoch 99/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6685 - accuracy: 0.6992 - val_loss: 130.4407 - val_accuracy: 0.5667\n",
            "Epoch 100/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6972 - accuracy: 0.6903 - val_loss: 128.6385 - val_accuracy: 0.5733\n",
            "Epoch 101/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.6832 - accuracy: 0.7014 - val_loss: 130.5661 - val_accuracy: 0.5600\n",
            "Epoch 102/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6627 - accuracy: 0.7230 - val_loss: 123.3429 - val_accuracy: 0.5600\n",
            "Epoch 103/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6415 - accuracy: 0.7230 - val_loss: 126.4932 - val_accuracy: 0.5733\n",
            "Epoch 104/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6868 - accuracy: 0.7032 - val_loss: 127.4406 - val_accuracy: 0.5733\n",
            "Epoch 105/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6977 - accuracy: 0.6893 - val_loss: 146.4046 - val_accuracy: 0.5667\n",
            "Epoch 106/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6675 - accuracy: 0.7135 - val_loss: 145.1345 - val_accuracy: 0.5667\n",
            "Epoch 107/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6565 - accuracy: 0.7041 - val_loss: 123.4400 - val_accuracy: 0.5667\n",
            "Epoch 108/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6690 - accuracy: 0.6918 - val_loss: 129.2016 - val_accuracy: 0.5533\n",
            "Epoch 109/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6513 - accuracy: 0.7212 - val_loss: 134.8344 - val_accuracy: 0.5667\n",
            "Epoch 110/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6468 - accuracy: 0.7173 - val_loss: 117.5739 - val_accuracy: 0.5667\n",
            "Epoch 111/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6560 - accuracy: 0.6948 - val_loss: 115.5275 - val_accuracy: 0.5800\n",
            "Epoch 112/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6524 - accuracy: 0.7170 - val_loss: 125.7274 - val_accuracy: 0.5667\n",
            "Epoch 113/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6519 - accuracy: 0.7200 - val_loss: 119.3521 - val_accuracy: 0.5600\n",
            "Epoch 114/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6680 - accuracy: 0.7092 - val_loss: 108.0859 - val_accuracy: 0.5667\n",
            "Epoch 115/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6553 - accuracy: 0.7138 - val_loss: 112.5316 - val_accuracy: 0.5733\n",
            "Epoch 116/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6535 - accuracy: 0.7045 - val_loss: 132.1060 - val_accuracy: 0.5667\n",
            "Epoch 117/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6651 - accuracy: 0.7101 - val_loss: 129.3624 - val_accuracy: 0.5733\n",
            "Epoch 118/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6480 - accuracy: 0.7153 - val_loss: 118.8803 - val_accuracy: 0.5733\n",
            "Epoch 119/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6658 - accuracy: 0.6998 - val_loss: 120.8704 - val_accuracy: 0.5733\n",
            "Epoch 120/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.6410 - accuracy: 0.7224 - val_loss: 119.6369 - val_accuracy: 0.5667\n",
            "Epoch 121/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.6508 - accuracy: 0.7119 - val_loss: 140.8041 - val_accuracy: 0.5600\n",
            "Epoch 122/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6671 - accuracy: 0.6916 - val_loss: 136.0545 - val_accuracy: 0.5667\n",
            "Epoch 123/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6521 - accuracy: 0.7064 - val_loss: 118.2362 - val_accuracy: 0.5867\n",
            "Epoch 124/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6316 - accuracy: 0.7189 - val_loss: 126.7700 - val_accuracy: 0.5667\n",
            "Epoch 125/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6396 - accuracy: 0.7192 - val_loss: 124.0933 - val_accuracy: 0.5800\n",
            "Epoch 126/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6720 - accuracy: 0.6971 - val_loss: 123.9559 - val_accuracy: 0.5733\n",
            "Epoch 127/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6408 - accuracy: 0.7232 - val_loss: 142.9658 - val_accuracy: 0.5600\n",
            "Epoch 128/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6239 - accuracy: 0.7224 - val_loss: 93.6684 - val_accuracy: 0.5533\n",
            "Epoch 129/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6307 - accuracy: 0.7249 - val_loss: 122.1880 - val_accuracy: 0.5667\n",
            "Epoch 130/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6573 - accuracy: 0.7028 - val_loss: 105.4317 - val_accuracy: 0.5733\n",
            "Epoch 131/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.6140 - accuracy: 0.7317 - val_loss: 118.3447 - val_accuracy: 0.5667\n",
            "Epoch 132/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6415 - accuracy: 0.7104 - val_loss: 108.4693 - val_accuracy: 0.5733\n",
            "Epoch 133/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6507 - accuracy: 0.7101 - val_loss: 110.2985 - val_accuracy: 0.5667\n",
            "Epoch 134/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6582 - accuracy: 0.7084 - val_loss: 112.8927 - val_accuracy: 0.5800\n",
            "Epoch 135/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6395 - accuracy: 0.7163 - val_loss: 119.0590 - val_accuracy: 0.5733\n",
            "Epoch 136/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6279 - accuracy: 0.7166 - val_loss: 116.1844 - val_accuracy: 0.5733\n",
            "Epoch 137/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6341 - accuracy: 0.7254 - val_loss: 123.5086 - val_accuracy: 0.5667\n",
            "Epoch 138/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6371 - accuracy: 0.7047 - val_loss: 120.2136 - val_accuracy: 0.5667\n",
            "Epoch 139/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6516 - accuracy: 0.7218 - val_loss: 130.5402 - val_accuracy: 0.5733\n",
            "Epoch 140/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6273 - accuracy: 0.7259 - val_loss: 135.4926 - val_accuracy: 0.5667\n",
            "Epoch 141/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6101 - accuracy: 0.7269 - val_loss: 103.1886 - val_accuracy: 0.5733\n",
            "Epoch 142/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6359 - accuracy: 0.7203 - val_loss: 118.5082 - val_accuracy: 0.5667\n",
            "Epoch 143/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6093 - accuracy: 0.7405 - val_loss: 106.6541 - val_accuracy: 0.5600\n",
            "Epoch 144/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6206 - accuracy: 0.7264 - val_loss: 123.2446 - val_accuracy: 0.5600\n",
            "Epoch 145/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6098 - accuracy: 0.7302 - val_loss: 101.5423 - val_accuracy: 0.5600\n",
            "Epoch 146/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6412 - accuracy: 0.7218 - val_loss: 101.8534 - val_accuracy: 0.5733\n",
            "Epoch 147/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6233 - accuracy: 0.7315 - val_loss: 109.1064 - val_accuracy: 0.5733\n",
            "Epoch 148/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6143 - accuracy: 0.7299 - val_loss: 99.4783 - val_accuracy: 0.5733\n",
            "Epoch 149/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6487 - accuracy: 0.7134 - val_loss: 127.0376 - val_accuracy: 0.5667\n",
            "Epoch 150/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6394 - accuracy: 0.7238 - val_loss: 117.4366 - val_accuracy: 0.5733\n",
            "Epoch 151/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6467 - accuracy: 0.7196 - val_loss: 119.6138 - val_accuracy: 0.5600\n",
            "Epoch 152/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.6551 - accuracy: 0.7132 - val_loss: 131.6003 - val_accuracy: 0.5667\n",
            "Epoch 153/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.6111 - accuracy: 0.7349 - val_loss: 103.3435 - val_accuracy: 0.5733\n",
            "Epoch 154/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6449 - accuracy: 0.7241 - val_loss: 112.4386 - val_accuracy: 0.5800\n",
            "Epoch 155/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6206 - accuracy: 0.7306 - val_loss: 104.4715 - val_accuracy: 0.5867\n",
            "Epoch 156/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6172 - accuracy: 0.7390 - val_loss: 112.1967 - val_accuracy: 0.5800\n",
            "Epoch 157/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6439 - accuracy: 0.7167 - val_loss: 101.1499 - val_accuracy: 0.5867\n",
            "Epoch 158/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5964 - accuracy: 0.7539 - val_loss: 100.4146 - val_accuracy: 0.5800\n",
            "Epoch 159/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6327 - accuracy: 0.7276 - val_loss: 104.9521 - val_accuracy: 0.5667\n",
            "Epoch 160/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6261 - accuracy: 0.7372 - val_loss: 140.0605 - val_accuracy: 0.5600\n",
            "Epoch 161/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.6521 - accuracy: 0.7246 - val_loss: 124.9975 - val_accuracy: 0.5667\n",
            "Epoch 162/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.6303 - accuracy: 0.7289 - val_loss: 114.5188 - val_accuracy: 0.5867\n",
            "Epoch 163/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6195 - accuracy: 0.7374 - val_loss: 105.6512 - val_accuracy: 0.5733\n",
            "Epoch 164/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6094 - accuracy: 0.7347 - val_loss: 107.9870 - val_accuracy: 0.5733\n",
            "Epoch 165/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6181 - accuracy: 0.7275 - val_loss: 114.1687 - val_accuracy: 0.5867\n",
            "Epoch 166/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6375 - accuracy: 0.7223 - val_loss: 116.7325 - val_accuracy: 0.5667\n",
            "Epoch 167/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6210 - accuracy: 0.7190 - val_loss: 134.1489 - val_accuracy: 0.5667\n",
            "Epoch 168/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6102 - accuracy: 0.7425 - val_loss: 91.3575 - val_accuracy: 0.5667\n",
            "Epoch 169/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6100 - accuracy: 0.7262 - val_loss: 101.1004 - val_accuracy: 0.5800\n",
            "Epoch 170/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6387 - accuracy: 0.7167 - val_loss: 114.8852 - val_accuracy: 0.5733\n",
            "Epoch 171/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6168 - accuracy: 0.7348 - val_loss: 142.1681 - val_accuracy: 0.5600\n",
            "Epoch 172/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5977 - accuracy: 0.7400 - val_loss: 136.0251 - val_accuracy: 0.5667\n",
            "Epoch 173/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.6091 - accuracy: 0.7268 - val_loss: 116.0842 - val_accuracy: 0.5667\n",
            "Epoch 174/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6085 - accuracy: 0.7403 - val_loss: 116.5521 - val_accuracy: 0.5800\n",
            "Epoch 175/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6091 - accuracy: 0.7216 - val_loss: 112.5112 - val_accuracy: 0.5733\n",
            "Epoch 176/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5871 - accuracy: 0.7336 - val_loss: 130.1318 - val_accuracy: 0.5733\n",
            "Epoch 177/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.6266 - accuracy: 0.7330 - val_loss: 114.9474 - val_accuracy: 0.5733\n",
            "Epoch 178/500\n",
            "90/90 [==============================] - 10s 108ms/step - loss: 0.6077 - accuracy: 0.7266 - val_loss: 120.2608 - val_accuracy: 0.5667\n",
            "Epoch 179/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.6102 - accuracy: 0.7265 - val_loss: 117.2351 - val_accuracy: 0.5667\n",
            "Epoch 180/500\n",
            "90/90 [==============================] - 10s 109ms/step - loss: 0.6161 - accuracy: 0.7315 - val_loss: 112.8067 - val_accuracy: 0.5733\n",
            "Epoch 181/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.5995 - accuracy: 0.7334 - val_loss: 98.3110 - val_accuracy: 0.5733\n",
            "Epoch 182/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5901 - accuracy: 0.7404 - val_loss: 95.9066 - val_accuracy: 0.5733\n",
            "Epoch 183/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.6035 - accuracy: 0.7332 - val_loss: 111.2163 - val_accuracy: 0.5733\n",
            "Epoch 184/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.6190 - accuracy: 0.7192 - val_loss: 100.4783 - val_accuracy: 0.5733\n",
            "Epoch 185/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6047 - accuracy: 0.7346 - val_loss: 118.7617 - val_accuracy: 0.5533\n",
            "Epoch 186/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6029 - accuracy: 0.7317 - val_loss: 98.4791 - val_accuracy: 0.5733\n",
            "Epoch 187/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5895 - accuracy: 0.7402 - val_loss: 103.5076 - val_accuracy: 0.5733\n",
            "Epoch 188/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6024 - accuracy: 0.7267 - val_loss: 95.1368 - val_accuracy: 0.5733\n",
            "Epoch 189/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6026 - accuracy: 0.7516 - val_loss: 83.9297 - val_accuracy: 0.5867\n",
            "Epoch 190/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6255 - accuracy: 0.7215 - val_loss: 99.8504 - val_accuracy: 0.5800\n",
            "Epoch 191/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6019 - accuracy: 0.7330 - val_loss: 111.1783 - val_accuracy: 0.5733\n",
            "Epoch 192/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5930 - accuracy: 0.7484 - val_loss: 98.7318 - val_accuracy: 0.5800\n",
            "Epoch 193/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6069 - accuracy: 0.7229 - val_loss: 93.1124 - val_accuracy: 0.5733\n",
            "Epoch 194/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5901 - accuracy: 0.7375 - val_loss: 91.3400 - val_accuracy: 0.5733\n",
            "Epoch 195/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6006 - accuracy: 0.7344 - val_loss: 96.0581 - val_accuracy: 0.5800\n",
            "Epoch 196/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6021 - accuracy: 0.7519 - val_loss: 98.3524 - val_accuracy: 0.5733\n",
            "Epoch 197/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6173 - accuracy: 0.7331 - val_loss: 121.6793 - val_accuracy: 0.5733\n",
            "Epoch 198/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5909 - accuracy: 0.7397 - val_loss: 118.0213 - val_accuracy: 0.5733\n",
            "Epoch 199/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6137 - accuracy: 0.7228 - val_loss: 109.2748 - val_accuracy: 0.5800\n",
            "Epoch 200/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6004 - accuracy: 0.7303 - val_loss: 110.6506 - val_accuracy: 0.5733\n",
            "Epoch 201/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5813 - accuracy: 0.7539 - val_loss: 112.4675 - val_accuracy: 0.5600\n",
            "Epoch 202/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6127 - accuracy: 0.7291 - val_loss: 110.2244 - val_accuracy: 0.5733\n",
            "Epoch 203/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.5780 - accuracy: 0.7420 - val_loss: 106.8167 - val_accuracy: 0.5667\n",
            "Epoch 204/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.5822 - accuracy: 0.7492 - val_loss: 114.5595 - val_accuracy: 0.5800\n",
            "Epoch 205/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5830 - accuracy: 0.7363 - val_loss: 109.2865 - val_accuracy: 0.5667\n",
            "Epoch 206/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.6073 - accuracy: 0.7441 - val_loss: 105.0670 - val_accuracy: 0.5467\n",
            "Epoch 207/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5933 - accuracy: 0.7285 - val_loss: 103.1930 - val_accuracy: 0.5733\n",
            "Epoch 208/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5816 - accuracy: 0.7501 - val_loss: 122.3941 - val_accuracy: 0.5267\n",
            "Epoch 209/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5869 - accuracy: 0.7488 - val_loss: 114.5372 - val_accuracy: 0.5400\n",
            "Epoch 210/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5935 - accuracy: 0.7462 - val_loss: 101.8568 - val_accuracy: 0.5800\n",
            "Epoch 211/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.5908 - accuracy: 0.7421 - val_loss: 109.4622 - val_accuracy: 0.5467\n",
            "Epoch 212/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5912 - accuracy: 0.7425 - val_loss: 140.5560 - val_accuracy: 0.5333\n",
            "Epoch 213/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.5913 - accuracy: 0.7466 - val_loss: 112.5023 - val_accuracy: 0.5533\n",
            "Epoch 214/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5931 - accuracy: 0.7528 - val_loss: 120.4391 - val_accuracy: 0.5333\n",
            "Epoch 215/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5737 - accuracy: 0.7399 - val_loss: 96.9283 - val_accuracy: 0.5733\n",
            "Epoch 216/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5935 - accuracy: 0.7378 - val_loss: 136.9098 - val_accuracy: 0.5400\n",
            "Epoch 217/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6211 - accuracy: 0.7232 - val_loss: 115.1787 - val_accuracy: 0.5400\n",
            "Epoch 218/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5919 - accuracy: 0.7418 - val_loss: 141.1290 - val_accuracy: 0.5200\n",
            "Epoch 219/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5895 - accuracy: 0.7439 - val_loss: 115.7576 - val_accuracy: 0.5733\n",
            "Epoch 220/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.5882 - accuracy: 0.7500 - val_loss: 108.7445 - val_accuracy: 0.5400\n",
            "Epoch 221/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5739 - accuracy: 0.7513 - val_loss: 113.2249 - val_accuracy: 0.5533\n",
            "Epoch 222/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5725 - accuracy: 0.7491 - val_loss: 105.7498 - val_accuracy: 0.5800\n",
            "Epoch 223/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5748 - accuracy: 0.7586 - val_loss: 130.4984 - val_accuracy: 0.5533\n",
            "Epoch 224/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5943 - accuracy: 0.7449 - val_loss: 136.9362 - val_accuracy: 0.5333\n",
            "Epoch 225/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.6115 - accuracy: 0.7335 - val_loss: 133.9441 - val_accuracy: 0.5400\n",
            "Epoch 226/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.5617 - accuracy: 0.7617 - val_loss: 112.5574 - val_accuracy: 0.5800\n",
            "Epoch 227/500\n",
            "90/90 [==============================] - 10s 111ms/step - loss: 0.5685 - accuracy: 0.7539 - val_loss: 125.3697 - val_accuracy: 0.5333\n",
            "Epoch 228/500\n",
            "90/90 [==============================] - 10s 110ms/step - loss: 0.5598 - accuracy: 0.7604 - val_loss: 127.0472 - val_accuracy: 0.5333\n",
            "Epoch 229/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5762 - accuracy: 0.7491 - val_loss: 126.9639 - val_accuracy: 0.5400\n",
            "Epoch 230/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5787 - accuracy: 0.7435 - val_loss: 117.8029 - val_accuracy: 0.5467\n",
            "Epoch 231/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5785 - accuracy: 0.7425 - val_loss: 95.5744 - val_accuracy: 0.5933\n",
            "Epoch 232/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5647 - accuracy: 0.7610 - val_loss: 99.9107 - val_accuracy: 0.5733\n",
            "Epoch 233/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5797 - accuracy: 0.7564 - val_loss: 132.5556 - val_accuracy: 0.5267\n",
            "Epoch 234/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5791 - accuracy: 0.7360 - val_loss: 127.3030 - val_accuracy: 0.5200\n",
            "Epoch 235/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5585 - accuracy: 0.7563 - val_loss: 112.0750 - val_accuracy: 0.5400\n",
            "Epoch 236/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5760 - accuracy: 0.7593 - val_loss: 127.2469 - val_accuracy: 0.5333\n",
            "Epoch 237/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5890 - accuracy: 0.7526 - val_loss: 122.2096 - val_accuracy: 0.5333\n",
            "Epoch 238/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.6014 - accuracy: 0.7180 - val_loss: 116.5350 - val_accuracy: 0.5533\n",
            "Epoch 239/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5860 - accuracy: 0.7461 - val_loss: 85.5986 - val_accuracy: 0.5733\n",
            "Epoch 240/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5782 - accuracy: 0.7574 - val_loss: 108.6399 - val_accuracy: 0.5467\n",
            "Epoch 241/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5683 - accuracy: 0.7580 - val_loss: 116.3701 - val_accuracy: 0.5333\n",
            "Epoch 242/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5731 - accuracy: 0.7460 - val_loss: 98.5043 - val_accuracy: 0.5533\n",
            "Epoch 243/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5923 - accuracy: 0.7273 - val_loss: 134.6402 - val_accuracy: 0.4933\n",
            "Epoch 244/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5880 - accuracy: 0.7481 - val_loss: 97.8045 - val_accuracy: 0.5667\n",
            "Epoch 245/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5912 - accuracy: 0.7442 - val_loss: 125.2453 - val_accuracy: 0.5400\n",
            "Epoch 246/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5809 - accuracy: 0.7528 - val_loss: 115.9146 - val_accuracy: 0.5400\n",
            "Epoch 247/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5610 - accuracy: 0.7636 - val_loss: 109.0479 - val_accuracy: 0.5400\n",
            "Epoch 248/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5716 - accuracy: 0.7516 - val_loss: 105.2496 - val_accuracy: 0.5333\n",
            "Epoch 249/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5640 - accuracy: 0.7505 - val_loss: 119.2917 - val_accuracy: 0.5067\n",
            "Epoch 250/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5618 - accuracy: 0.7601 - val_loss: 131.9787 - val_accuracy: 0.5267\n",
            "Epoch 251/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5707 - accuracy: 0.7561 - val_loss: 120.7849 - val_accuracy: 0.5200\n",
            "Epoch 252/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.6021 - accuracy: 0.7355 - val_loss: 96.4053 - val_accuracy: 0.5600\n",
            "Epoch 253/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5584 - accuracy: 0.7440 - val_loss: 122.2669 - val_accuracy: 0.5200\n",
            "Epoch 254/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5660 - accuracy: 0.7481 - val_loss: 125.5847 - val_accuracy: 0.5133\n",
            "Epoch 255/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5609 - accuracy: 0.7643 - val_loss: 108.0663 - val_accuracy: 0.5200\n",
            "Epoch 256/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5590 - accuracy: 0.7575 - val_loss: 136.6383 - val_accuracy: 0.4867\n",
            "Epoch 257/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5586 - accuracy: 0.7477 - val_loss: 120.3056 - val_accuracy: 0.4933\n",
            "Epoch 258/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5519 - accuracy: 0.7646 - val_loss: 136.2225 - val_accuracy: 0.4733\n",
            "Epoch 259/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5613 - accuracy: 0.7644 - val_loss: 135.7899 - val_accuracy: 0.4733\n",
            "Epoch 260/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5785 - accuracy: 0.7522 - val_loss: 149.8007 - val_accuracy: 0.4733\n",
            "Epoch 261/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5790 - accuracy: 0.7396 - val_loss: 123.8583 - val_accuracy: 0.5000\n",
            "Epoch 262/500\n",
            "90/90 [==============================] - 10s 112ms/step - loss: 0.5912 - accuracy: 0.7427 - val_loss: 130.0366 - val_accuracy: 0.5000\n",
            "Epoch 263/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5588 - accuracy: 0.7647 - val_loss: 138.1444 - val_accuracy: 0.4600\n",
            "Epoch 264/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5482 - accuracy: 0.7757 - val_loss: 118.2192 - val_accuracy: 0.5000\n",
            "Epoch 265/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5555 - accuracy: 0.7525 - val_loss: 133.4353 - val_accuracy: 0.4867\n",
            "Epoch 266/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5305 - accuracy: 0.7712 - val_loss: 128.5146 - val_accuracy: 0.4867\n",
            "Epoch 267/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5736 - accuracy: 0.7555 - val_loss: 129.2182 - val_accuracy: 0.4867\n",
            "Epoch 268/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5639 - accuracy: 0.7552 - val_loss: 100.7035 - val_accuracy: 0.5533\n",
            "Epoch 269/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5515 - accuracy: 0.7604 - val_loss: 86.5114 - val_accuracy: 0.5400\n",
            "Epoch 270/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5361 - accuracy: 0.7662 - val_loss: 128.4683 - val_accuracy: 0.5067\n",
            "Epoch 271/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5717 - accuracy: 0.7483 - val_loss: 94.9162 - val_accuracy: 0.5467\n",
            "Epoch 272/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5657 - accuracy: 0.7643 - val_loss: 104.9930 - val_accuracy: 0.5333\n",
            "Epoch 273/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5550 - accuracy: 0.7552 - val_loss: 122.3288 - val_accuracy: 0.5133\n",
            "Epoch 274/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5547 - accuracy: 0.7608 - val_loss: 110.3167 - val_accuracy: 0.5200\n",
            "Epoch 275/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5580 - accuracy: 0.7595 - val_loss: 106.7654 - val_accuracy: 0.5267\n",
            "Epoch 276/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5504 - accuracy: 0.7555 - val_loss: 110.0049 - val_accuracy: 0.5267\n",
            "Epoch 277/500\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.5651 - accuracy: 0.7523 - val_loss: 93.2243 - val_accuracy: 0.5400\n",
            "Epoch 278/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5516 - accuracy: 0.7586 - val_loss: 111.7381 - val_accuracy: 0.5267\n",
            "Epoch 279/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5525 - accuracy: 0.7692 - val_loss: 90.5239 - val_accuracy: 0.5400\n",
            "Epoch 280/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5598 - accuracy: 0.7574 - val_loss: 104.2385 - val_accuracy: 0.5267\n",
            "Epoch 281/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5517 - accuracy: 0.7540 - val_loss: 93.0626 - val_accuracy: 0.5400\n",
            "Epoch 282/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5599 - accuracy: 0.7655 - val_loss: 103.7885 - val_accuracy: 0.5333\n",
            "Epoch 283/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5475 - accuracy: 0.7590 - val_loss: 95.8000 - val_accuracy: 0.5400\n",
            "Epoch 284/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5609 - accuracy: 0.7610 - val_loss: 123.3741 - val_accuracy: 0.5000\n",
            "Epoch 285/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5312 - accuracy: 0.7698 - val_loss: 96.4117 - val_accuracy: 0.5467\n",
            "Epoch 286/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5546 - accuracy: 0.7669 - val_loss: 112.2587 - val_accuracy: 0.5067\n",
            "Epoch 287/500\n",
            "90/90 [==============================] - 10s 113ms/step - loss: 0.5562 - accuracy: 0.7653 - val_loss: 111.4883 - val_accuracy: 0.5200\n",
            "Epoch 288/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5593 - accuracy: 0.7531 - val_loss: 88.3595 - val_accuracy: 0.5600\n",
            "Epoch 289/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5531 - accuracy: 0.7719 - val_loss: 99.3828 - val_accuracy: 0.5333\n",
            "Epoch 290/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5415 - accuracy: 0.7735 - val_loss: 127.3776 - val_accuracy: 0.5067\n",
            "Epoch 291/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5460 - accuracy: 0.7667 - val_loss: 162.3281 - val_accuracy: 0.4400\n",
            "Epoch 292/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5443 - accuracy: 0.7680 - val_loss: 110.1779 - val_accuracy: 0.5200\n",
            "Epoch 293/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5523 - accuracy: 0.7642 - val_loss: 126.1817 - val_accuracy: 0.4867\n",
            "Epoch 294/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5655 - accuracy: 0.7550 - val_loss: 130.5289 - val_accuracy: 0.5067\n",
            "Epoch 295/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5831 - accuracy: 0.7542 - val_loss: 104.2561 - val_accuracy: 0.5333\n",
            "Epoch 296/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5551 - accuracy: 0.7671 - val_loss: 124.4755 - val_accuracy: 0.4933\n",
            "Epoch 297/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5490 - accuracy: 0.7669 - val_loss: 138.3911 - val_accuracy: 0.4733\n",
            "Epoch 298/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5373 - accuracy: 0.7695 - val_loss: 96.7840 - val_accuracy: 0.5467\n",
            "Epoch 299/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5535 - accuracy: 0.7645 - val_loss: 132.8775 - val_accuracy: 0.4933\n",
            "Epoch 300/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 136.0134 - val_accuracy: 0.4867\n",
            "Epoch 301/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5636 - accuracy: 0.7584 - val_loss: 96.8648 - val_accuracy: 0.5533\n",
            "Epoch 302/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5270 - accuracy: 0.7737 - val_loss: 117.1605 - val_accuracy: 0.5000\n",
            "Epoch 303/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5512 - accuracy: 0.7639 - val_loss: 136.0617 - val_accuracy: 0.4733\n",
            "Epoch 304/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5525 - accuracy: 0.7478 - val_loss: 103.4084 - val_accuracy: 0.5333\n",
            "Epoch 305/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5688 - accuracy: 0.7432 - val_loss: 116.8247 - val_accuracy: 0.5200\n",
            "Epoch 306/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5364 - accuracy: 0.7808 - val_loss: 147.4310 - val_accuracy: 0.4600\n",
            "Epoch 307/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5516 - accuracy: 0.7664 - val_loss: 120.7225 - val_accuracy: 0.5000\n",
            "Epoch 308/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5424 - accuracy: 0.7674 - val_loss: 120.3039 - val_accuracy: 0.5067\n",
            "Epoch 309/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5409 - accuracy: 0.7829 - val_loss: 147.0222 - val_accuracy: 0.4667\n",
            "Epoch 310/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5498 - accuracy: 0.7706 - val_loss: 179.3085 - val_accuracy: 0.4533\n",
            "Epoch 311/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5817 - accuracy: 0.7434 - val_loss: 122.8062 - val_accuracy: 0.5067\n",
            "Epoch 312/500\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5577 - accuracy: 0.7624 - val_loss: 115.6512 - val_accuracy: 0.5067\n",
            "Epoch 313/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5413 - accuracy: 0.7632 - val_loss: 147.9565 - val_accuracy: 0.4800\n",
            "Epoch 314/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5355 - accuracy: 0.7660 - val_loss: 114.4361 - val_accuracy: 0.5200\n",
            "Epoch 315/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5527 - accuracy: 0.7651 - val_loss: 109.1002 - val_accuracy: 0.5267\n",
            "Epoch 316/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5345 - accuracy: 0.7700 - val_loss: 102.8434 - val_accuracy: 0.5200\n",
            "Epoch 317/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5512 - accuracy: 0.7637 - val_loss: 115.7405 - val_accuracy: 0.4933\n",
            "Epoch 318/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5932 - accuracy: 0.7465 - val_loss: 106.9999 - val_accuracy: 0.5267\n",
            "Epoch 319/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5353 - accuracy: 0.7633 - val_loss: 121.9289 - val_accuracy: 0.5067\n",
            "Epoch 320/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5664 - accuracy: 0.7627 - val_loss: 93.7774 - val_accuracy: 0.5200\n",
            "Epoch 321/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5360 - accuracy: 0.7564 - val_loss: 111.5634 - val_accuracy: 0.5200\n",
            "Epoch 322/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5402 - accuracy: 0.7743 - val_loss: 126.7208 - val_accuracy: 0.4800\n",
            "Epoch 323/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5369 - accuracy: 0.7660 - val_loss: 105.6762 - val_accuracy: 0.5200\n",
            "Epoch 324/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5766 - accuracy: 0.7551 - val_loss: 106.0848 - val_accuracy: 0.5267\n",
            "Epoch 325/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5517 - accuracy: 0.7589 - val_loss: 103.1041 - val_accuracy: 0.5200\n",
            "Epoch 326/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5633 - accuracy: 0.7618 - val_loss: 104.1335 - val_accuracy: 0.5267\n",
            "Epoch 327/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5436 - accuracy: 0.7683 - val_loss: 124.0762 - val_accuracy: 0.4800\n",
            "Epoch 328/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5263 - accuracy: 0.7714 - val_loss: 111.7678 - val_accuracy: 0.5200\n",
            "Epoch 329/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5518 - accuracy: 0.7686 - val_loss: 89.7094 - val_accuracy: 0.5333\n",
            "Epoch 330/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5424 - accuracy: 0.7658 - val_loss: 108.1830 - val_accuracy: 0.5200\n",
            "Epoch 331/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5577 - accuracy: 0.7517 - val_loss: 121.3747 - val_accuracy: 0.5133\n",
            "Epoch 332/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5472 - accuracy: 0.7758 - val_loss: 117.6162 - val_accuracy: 0.5000\n",
            "Epoch 333/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5272 - accuracy: 0.7726 - val_loss: 119.3602 - val_accuracy: 0.4933\n",
            "Epoch 334/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5220 - accuracy: 0.7798 - val_loss: 118.4044 - val_accuracy: 0.5133\n",
            "Epoch 335/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5372 - accuracy: 0.7649 - val_loss: 99.4565 - val_accuracy: 0.5200\n",
            "Epoch 336/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5283 - accuracy: 0.7968 - val_loss: 80.3145 - val_accuracy: 0.5800\n",
            "Epoch 337/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5429 - accuracy: 0.7565 - val_loss: 127.6739 - val_accuracy: 0.5000\n",
            "Epoch 338/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5549 - accuracy: 0.7641 - val_loss: 106.6771 - val_accuracy: 0.5267\n",
            "Epoch 339/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5298 - accuracy: 0.7714 - val_loss: 88.0687 - val_accuracy: 0.5533\n",
            "Epoch 340/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5329 - accuracy: 0.7691 - val_loss: 106.9916 - val_accuracy: 0.5133\n",
            "Epoch 341/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5368 - accuracy: 0.7640 - val_loss: 124.1669 - val_accuracy: 0.5067\n",
            "Epoch 342/500\n",
            "90/90 [==============================] - 11s 116ms/step - loss: 0.5469 - accuracy: 0.7667 - val_loss: 120.3119 - val_accuracy: 0.5000\n",
            "Epoch 343/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5269 - accuracy: 0.7616 - val_loss: 92.3298 - val_accuracy: 0.5333\n",
            "Epoch 344/500\n",
            "90/90 [==============================] - 10s 114ms/step - loss: 0.5533 - accuracy: 0.7741 - val_loss: 101.5645 - val_accuracy: 0.5400\n",
            "Epoch 345/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5248 - accuracy: 0.7710 - val_loss: 100.1780 - val_accuracy: 0.5267\n",
            "Epoch 346/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5663 - accuracy: 0.7592 - val_loss: 140.2930 - val_accuracy: 0.4733\n",
            "Epoch 347/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5353 - accuracy: 0.7758 - val_loss: 113.3362 - val_accuracy: 0.5067\n",
            "Epoch 348/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5585 - accuracy: 0.7588 - val_loss: 107.8198 - val_accuracy: 0.5333\n",
            "Epoch 349/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5360 - accuracy: 0.7638 - val_loss: 138.4418 - val_accuracy: 0.4600\n",
            "Epoch 350/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5365 - accuracy: 0.7762 - val_loss: 115.9272 - val_accuracy: 0.5200\n",
            "Epoch 351/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5393 - accuracy: 0.7653 - val_loss: 141.7807 - val_accuracy: 0.4800\n",
            "Epoch 352/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5553 - accuracy: 0.7628 - val_loss: 119.8267 - val_accuracy: 0.5000\n",
            "Epoch 353/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5406 - accuracy: 0.7676 - val_loss: 127.6334 - val_accuracy: 0.5000\n",
            "Epoch 354/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5123 - accuracy: 0.7746 - val_loss: 115.1664 - val_accuracy: 0.5133\n",
            "Epoch 355/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5645 - accuracy: 0.7635 - val_loss: 147.8538 - val_accuracy: 0.4800\n",
            "Epoch 356/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5404 - accuracy: 0.7683 - val_loss: 115.7311 - val_accuracy: 0.5133\n",
            "Epoch 357/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5152 - accuracy: 0.7866 - val_loss: 121.9740 - val_accuracy: 0.5200\n",
            "Epoch 358/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5173 - accuracy: 0.7777 - val_loss: 153.5382 - val_accuracy: 0.4667\n",
            "Epoch 359/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5205 - accuracy: 0.7775 - val_loss: 143.7653 - val_accuracy: 0.4867\n",
            "Epoch 360/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5487 - accuracy: 0.7570 - val_loss: 87.2859 - val_accuracy: 0.5733\n",
            "Epoch 361/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5529 - accuracy: 0.7606 - val_loss: 139.0905 - val_accuracy: 0.4800\n",
            "Epoch 362/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5504 - accuracy: 0.7466 - val_loss: 119.9073 - val_accuracy: 0.5067\n",
            "Epoch 363/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5287 - accuracy: 0.7613 - val_loss: 124.6625 - val_accuracy: 0.4800\n",
            "Epoch 364/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5273 - accuracy: 0.7918 - val_loss: 130.2594 - val_accuracy: 0.4933\n",
            "Epoch 365/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5237 - accuracy: 0.7787 - val_loss: 126.8539 - val_accuracy: 0.4933\n",
            "Epoch 366/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5460 - accuracy: 0.7634 - val_loss: 102.5359 - val_accuracy: 0.5333\n",
            "Epoch 367/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5453 - accuracy: 0.7743 - val_loss: 128.1066 - val_accuracy: 0.4867\n",
            "Epoch 368/500\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5241 - accuracy: 0.7740 - val_loss: 128.7296 - val_accuracy: 0.4867\n",
            "Epoch 369/500\n",
            "90/90 [==============================] - 11s 116ms/step - loss: 0.5415 - accuracy: 0.7690 - val_loss: 127.4373 - val_accuracy: 0.5067\n",
            "Epoch 370/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5259 - accuracy: 0.7798 - val_loss: 105.3716 - val_accuracy: 0.5200\n",
            "Epoch 371/500\n",
            "90/90 [==============================] - 11s 122ms/step - loss: 0.5209 - accuracy: 0.7805 - val_loss: 141.2099 - val_accuracy: 0.4733\n",
            "Epoch 372/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5394 - accuracy: 0.7682 - val_loss: 138.8718 - val_accuracy: 0.5000\n",
            "Epoch 373/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5366 - accuracy: 0.7713 - val_loss: 109.8128 - val_accuracy: 0.5400\n",
            "Epoch 374/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5216 - accuracy: 0.7788 - val_loss: 132.4496 - val_accuracy: 0.4867\n",
            "Epoch 375/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5146 - accuracy: 0.7894 - val_loss: 154.3740 - val_accuracy: 0.4733\n",
            "Epoch 376/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5435 - accuracy: 0.7676 - val_loss: 115.8038 - val_accuracy: 0.5200\n",
            "Epoch 377/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5290 - accuracy: 0.7740 - val_loss: 95.8065 - val_accuracy: 0.5533\n",
            "Epoch 378/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5274 - accuracy: 0.7845 - val_loss: 103.3049 - val_accuracy: 0.5200\n",
            "Epoch 379/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5339 - accuracy: 0.7739 - val_loss: 125.1344 - val_accuracy: 0.4800\n",
            "Epoch 380/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5340 - accuracy: 0.7858 - val_loss: 123.5532 - val_accuracy: 0.4800\n",
            "Epoch 381/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5302 - accuracy: 0.7788 - val_loss: 107.7632 - val_accuracy: 0.5200\n",
            "Epoch 382/500\n",
            "90/90 [==============================] - 11s 116ms/step - loss: 0.5357 - accuracy: 0.7565 - val_loss: 120.3215 - val_accuracy: 0.5000\n",
            "Epoch 383/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5168 - accuracy: 0.7754 - val_loss: 154.0663 - val_accuracy: 0.4533\n",
            "Epoch 384/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5269 - accuracy: 0.7772 - val_loss: 156.8601 - val_accuracy: 0.4533\n",
            "Epoch 385/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5162 - accuracy: 0.7878 - val_loss: 121.5215 - val_accuracy: 0.4867\n",
            "Epoch 386/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5330 - accuracy: 0.7576 - val_loss: 126.0894 - val_accuracy: 0.4867\n",
            "Epoch 387/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5299 - accuracy: 0.7745 - val_loss: 108.0301 - val_accuracy: 0.5133\n",
            "Epoch 388/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5439 - accuracy: 0.7694 - val_loss: 118.0657 - val_accuracy: 0.4933\n",
            "Epoch 389/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5137 - accuracy: 0.7853 - val_loss: 122.7677 - val_accuracy: 0.4733\n",
            "Epoch 390/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5171 - accuracy: 0.7720 - val_loss: 102.1924 - val_accuracy: 0.5400\n",
            "Epoch 391/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.4999 - accuracy: 0.7849 - val_loss: 122.7773 - val_accuracy: 0.4800\n",
            "Epoch 392/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5432 - accuracy: 0.7707 - val_loss: 151.9717 - val_accuracy: 0.4533\n",
            "Epoch 393/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5169 - accuracy: 0.7836 - val_loss: 111.3912 - val_accuracy: 0.4933\n",
            "Epoch 394/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5132 - accuracy: 0.7864 - val_loss: 162.4834 - val_accuracy: 0.4600\n",
            "Epoch 395/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.4951 - accuracy: 0.7931 - val_loss: 138.6140 - val_accuracy: 0.4667\n",
            "Epoch 396/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5328 - accuracy: 0.7677 - val_loss: 139.3103 - val_accuracy: 0.4800\n",
            "Epoch 397/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5420 - accuracy: 0.7671 - val_loss: 100.9440 - val_accuracy: 0.5267\n",
            "Epoch 398/500\n",
            "90/90 [==============================] - 11s 123ms/step - loss: 0.5307 - accuracy: 0.7701 - val_loss: 132.9397 - val_accuracy: 0.4800\n",
            "Epoch 399/500\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.5255 - accuracy: 0.7823 - val_loss: 137.3740 - val_accuracy: 0.4867\n",
            "Epoch 400/500\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.5190 - accuracy: 0.7770 - val_loss: 142.7163 - val_accuracy: 0.4533\n",
            "Epoch 401/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5269 - accuracy: 0.7760 - val_loss: 123.9578 - val_accuracy: 0.4867\n",
            "Epoch 402/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5084 - accuracy: 0.7770 - val_loss: 133.2956 - val_accuracy: 0.4933\n",
            "Epoch 403/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5144 - accuracy: 0.7790 - val_loss: 112.1904 - val_accuracy: 0.5200\n",
            "Epoch 404/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5130 - accuracy: 0.7819 - val_loss: 153.7458 - val_accuracy: 0.4733\n",
            "Epoch 405/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5082 - accuracy: 0.7945 - val_loss: 129.7298 - val_accuracy: 0.4933\n",
            "Epoch 406/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5133 - accuracy: 0.7938 - val_loss: 126.4088 - val_accuracy: 0.5000\n",
            "Epoch 407/500\n",
            "90/90 [==============================] - 11s 116ms/step - loss: 0.5153 - accuracy: 0.7876 - val_loss: 115.9090 - val_accuracy: 0.5067\n",
            "Epoch 408/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5244 - accuracy: 0.7811 - val_loss: 126.9634 - val_accuracy: 0.5067\n",
            "Epoch 409/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5126 - accuracy: 0.7776 - val_loss: 161.3216 - val_accuracy: 0.4667\n",
            "Epoch 410/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5057 - accuracy: 0.7810 - val_loss: 112.8619 - val_accuracy: 0.5267\n",
            "Epoch 411/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5099 - accuracy: 0.7876 - val_loss: 111.1069 - val_accuracy: 0.5200\n",
            "Epoch 412/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5329 - accuracy: 0.7606 - val_loss: 98.9670 - val_accuracy: 0.5467\n",
            "Epoch 413/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5258 - accuracy: 0.7682 - val_loss: 114.4876 - val_accuracy: 0.5200\n",
            "Epoch 414/500\n",
            "90/90 [==============================] - 11s 116ms/step - loss: 0.5073 - accuracy: 0.7765 - val_loss: 146.1188 - val_accuracy: 0.4867\n",
            "Epoch 415/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5352 - accuracy: 0.7641 - val_loss: 114.3938 - val_accuracy: 0.5267\n",
            "Epoch 416/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.4985 - accuracy: 0.7754 - val_loss: 158.8323 - val_accuracy: 0.4933\n",
            "Epoch 417/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5178 - accuracy: 0.7728 - val_loss: 136.7987 - val_accuracy: 0.5200\n",
            "Epoch 418/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5307 - accuracy: 0.7692 - val_loss: 129.6035 - val_accuracy: 0.5200\n",
            "Epoch 419/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5298 - accuracy: 0.7686 - val_loss: 136.9347 - val_accuracy: 0.5067\n",
            "Epoch 420/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5228 - accuracy: 0.7866 - val_loss: 144.9822 - val_accuracy: 0.4933\n",
            "Epoch 421/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5201 - accuracy: 0.7739 - val_loss: 107.1238 - val_accuracy: 0.5467\n",
            "Epoch 422/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5064 - accuracy: 0.7830 - val_loss: 120.4369 - val_accuracy: 0.5133\n",
            "Epoch 423/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5078 - accuracy: 0.7911 - val_loss: 132.0779 - val_accuracy: 0.4867\n",
            "Epoch 424/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5164 - accuracy: 0.7767 - val_loss: 126.0878 - val_accuracy: 0.5067\n",
            "Epoch 425/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.4857 - accuracy: 0.7876 - val_loss: 111.1152 - val_accuracy: 0.5133\n",
            "Epoch 426/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5300 - accuracy: 0.7798 - val_loss: 114.2775 - val_accuracy: 0.5067\n",
            "Epoch 427/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5160 - accuracy: 0.7778 - val_loss: 134.1505 - val_accuracy: 0.5067\n",
            "Epoch 428/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5131 - accuracy: 0.7725 - val_loss: 106.7893 - val_accuracy: 0.5267\n",
            "Epoch 429/500\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5214 - accuracy: 0.7832 - val_loss: 144.2480 - val_accuracy: 0.4933\n",
            "Epoch 430/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5243 - accuracy: 0.7822 - val_loss: 122.9653 - val_accuracy: 0.5200\n",
            "Epoch 431/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.4899 - accuracy: 0.7936 - val_loss: 120.7672 - val_accuracy: 0.4867\n",
            "Epoch 432/500\n",
            "90/90 [==============================] - 11s 116ms/step - loss: 0.5349 - accuracy: 0.7705 - val_loss: 120.1070 - val_accuracy: 0.4933\n",
            "Epoch 433/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.4986 - accuracy: 0.7806 - val_loss: 115.4465 - val_accuracy: 0.5467\n",
            "Epoch 434/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5209 - accuracy: 0.7891 - val_loss: 114.1002 - val_accuracy: 0.5333\n",
            "Epoch 435/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5102 - accuracy: 0.7752 - val_loss: 139.9582 - val_accuracy: 0.4867\n",
            "Epoch 436/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5199 - accuracy: 0.7707 - val_loss: 132.1404 - val_accuracy: 0.4933\n",
            "Epoch 437/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5188 - accuracy: 0.7740 - val_loss: 132.9350 - val_accuracy: 0.4667\n",
            "Epoch 438/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5199 - accuracy: 0.7818 - val_loss: 137.3627 - val_accuracy: 0.4600\n",
            "Epoch 439/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5399 - accuracy: 0.7676 - val_loss: 143.3939 - val_accuracy: 0.4533\n",
            "Epoch 440/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.4958 - accuracy: 0.7901 - val_loss: 98.6314 - val_accuracy: 0.5267\n",
            "Epoch 441/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5171 - accuracy: 0.7818 - val_loss: 151.8996 - val_accuracy: 0.4733\n",
            "Epoch 442/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5122 - accuracy: 0.7803 - val_loss: 127.9744 - val_accuracy: 0.5133\n",
            "Epoch 443/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5270 - accuracy: 0.7782 - val_loss: 126.3085 - val_accuracy: 0.4867\n",
            "Epoch 444/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5085 - accuracy: 0.7799 - val_loss: 130.7833 - val_accuracy: 0.4800\n",
            "Epoch 445/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5075 - accuracy: 0.7799 - val_loss: 117.9258 - val_accuracy: 0.5200\n",
            "Epoch 446/500\n",
            "90/90 [==============================] - 18s 205ms/step - loss: 0.5282 - accuracy: 0.7743 - val_loss: 110.9215 - val_accuracy: 0.5400\n",
            "Epoch 447/500\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.5363 - accuracy: 0.7624 - val_loss: 142.5971 - val_accuracy: 0.4867\n",
            "Epoch 448/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.4962 - accuracy: 0.7906 - val_loss: 139.5417 - val_accuracy: 0.4667\n",
            "Epoch 449/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5363 - accuracy: 0.7632 - val_loss: 126.3946 - val_accuracy: 0.4733\n",
            "Epoch 450/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5006 - accuracy: 0.7848 - val_loss: 115.9295 - val_accuracy: 0.5067\n",
            "Epoch 451/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5152 - accuracy: 0.7899 - val_loss: 95.4929 - val_accuracy: 0.5267\n",
            "Epoch 452/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5054 - accuracy: 0.7901 - val_loss: 96.3927 - val_accuracy: 0.5333\n",
            "Epoch 453/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4977 - accuracy: 0.7932 - val_loss: 131.2282 - val_accuracy: 0.4733\n",
            "Epoch 454/500\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.5241 - accuracy: 0.7883 - val_loss: 151.9634 - val_accuracy: 0.4600\n",
            "Epoch 455/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5310 - accuracy: 0.7761 - val_loss: 123.0490 - val_accuracy: 0.4733\n",
            "Epoch 456/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5052 - accuracy: 0.7902 - val_loss: 135.5073 - val_accuracy: 0.4667\n",
            "Epoch 457/500\n",
            "90/90 [==============================] - 11s 126ms/step - loss: 0.5547 - accuracy: 0.7601 - val_loss: 109.7858 - val_accuracy: 0.5067\n",
            "Epoch 458/500\n",
            "90/90 [==============================] - 11s 122ms/step - loss: 0.4919 - accuracy: 0.7967 - val_loss: 129.1392 - val_accuracy: 0.4867\n",
            "Epoch 459/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5116 - accuracy: 0.7834 - val_loss: 118.8096 - val_accuracy: 0.5000\n",
            "Epoch 460/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5106 - accuracy: 0.7721 - val_loss: 129.8417 - val_accuracy: 0.4800\n",
            "Epoch 461/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.4956 - accuracy: 0.7890 - val_loss: 141.6294 - val_accuracy: 0.4733\n",
            "Epoch 462/500\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.5225 - accuracy: 0.7736 - val_loss: 109.0430 - val_accuracy: 0.5267\n",
            "Epoch 463/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5064 - accuracy: 0.7765 - val_loss: 129.5793 - val_accuracy: 0.5133\n",
            "Epoch 464/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5133 - accuracy: 0.7804 - val_loss: 119.8898 - val_accuracy: 0.5200\n",
            "Epoch 465/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.4924 - accuracy: 0.7899 - val_loss: 167.6814 - val_accuracy: 0.4533\n",
            "Epoch 466/500\n",
            "90/90 [==============================] - 11s 116ms/step - loss: 0.5216 - accuracy: 0.7794 - val_loss: 119.1129 - val_accuracy: 0.5000\n",
            "Epoch 467/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.4958 - accuracy: 0.7898 - val_loss: 124.9397 - val_accuracy: 0.4800\n",
            "Epoch 468/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5019 - accuracy: 0.7790 - val_loss: 175.9669 - val_accuracy: 0.4667\n",
            "Epoch 469/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5134 - accuracy: 0.7922 - val_loss: 171.9078 - val_accuracy: 0.4733\n",
            "Epoch 470/500\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.5051 - accuracy: 0.7913 - val_loss: 127.5884 - val_accuracy: 0.4933\n",
            "Epoch 471/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5291 - accuracy: 0.7746 - val_loss: 141.2811 - val_accuracy: 0.4800\n",
            "Epoch 472/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5175 - accuracy: 0.7890 - val_loss: 167.1432 - val_accuracy: 0.4800\n",
            "Epoch 473/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5442 - accuracy: 0.7675 - val_loss: 135.5553 - val_accuracy: 0.4933\n",
            "Epoch 474/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5035 - accuracy: 0.7822 - val_loss: 127.4733 - val_accuracy: 0.5133\n",
            "Epoch 475/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4854 - accuracy: 0.7897 - val_loss: 129.5994 - val_accuracy: 0.5133\n",
            "Epoch 476/500\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4856 - accuracy: 0.7933 - val_loss: 90.0228 - val_accuracy: 0.5600\n",
            "Epoch 477/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5197 - accuracy: 0.7806 - val_loss: 126.8502 - val_accuracy: 0.5133\n",
            "Epoch 478/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5084 - accuracy: 0.7905 - val_loss: 123.1896 - val_accuracy: 0.4933\n",
            "Epoch 479/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5180 - accuracy: 0.7687 - val_loss: 119.9348 - val_accuracy: 0.5200\n",
            "Epoch 480/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.4950 - accuracy: 0.7880 - val_loss: 152.7237 - val_accuracy: 0.5067\n",
            "Epoch 481/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5128 - accuracy: 0.7848 - val_loss: 152.4277 - val_accuracy: 0.4867\n",
            "Epoch 482/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5292 - accuracy: 0.7747 - val_loss: 205.8446 - val_accuracy: 0.4333\n",
            "Epoch 483/500\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.5069 - accuracy: 0.7929 - val_loss: 121.5314 - val_accuracy: 0.5133\n",
            "Epoch 484/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5025 - accuracy: 0.7764 - val_loss: 127.4512 - val_accuracy: 0.5200\n",
            "Epoch 485/500\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5063 - accuracy: 0.7927 - val_loss: 117.2362 - val_accuracy: 0.5133\n",
            "Epoch 486/500\n",
            "90/90 [==============================] - 11s 126ms/step - loss: 0.5330 - accuracy: 0.7758 - val_loss: 123.1884 - val_accuracy: 0.5267\n",
            "Epoch 487/500\n",
            "90/90 [==============================] - 12s 133ms/step - loss: 0.5109 - accuracy: 0.7827 - val_loss: 115.3269 - val_accuracy: 0.5400\n",
            "Epoch 488/500\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.5040 - accuracy: 0.7864 - val_loss: 138.4140 - val_accuracy: 0.5133\n",
            "Epoch 489/500\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4858 - accuracy: 0.7930 - val_loss: 132.5645 - val_accuracy: 0.5267\n",
            "Epoch 490/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5089 - accuracy: 0.7865 - val_loss: 115.9536 - val_accuracy: 0.5400\n",
            "Epoch 491/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4845 - accuracy: 0.8055 - val_loss: 158.3504 - val_accuracy: 0.5000\n",
            "Epoch 492/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5083 - accuracy: 0.7894 - val_loss: 156.4768 - val_accuracy: 0.4933\n",
            "Epoch 493/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5114 - accuracy: 0.7803 - val_loss: 156.5644 - val_accuracy: 0.5000\n",
            "Epoch 494/500\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5222 - accuracy: 0.7691 - val_loss: 152.8001 - val_accuracy: 0.4933\n",
            "Epoch 495/500\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.5262 - accuracy: 0.7750 - val_loss: 136.7950 - val_accuracy: 0.5067\n",
            "Epoch 496/500\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5124 - accuracy: 0.7818 - val_loss: 150.4468 - val_accuracy: 0.4667\n",
            "Epoch 497/500\n",
            "90/90 [==============================] - 11s 122ms/step - loss: 0.5078 - accuracy: 0.7823 - val_loss: 152.1079 - val_accuracy: 0.4800\n",
            "Epoch 498/500\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4999 - accuracy: 0.7845 - val_loss: 149.6040 - val_accuracy: 0.4733\n",
            "Epoch 499/500\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4994 - accuracy: 0.7895 - val_loss: 138.9011 - val_accuracy: 0.4933\n",
            "Epoch 500/500\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.5108 - accuracy: 0.7827 - val_loss: 204.8318 - val_accuracy: 0.4400\n",
            "Train Accuracy of the model is 0.46891281695033\n",
            "Test Accuracy of the model is 0.44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMA-dn-Ad_B5"
      },
      "source": [
        "# **Application Model start here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfTKUNMghIcj"
      },
      "source": [
        "**VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Uw3759DI9Cx",
        "outputId": "bada34b1-030f-4638-a2cb-880456e713dd"
      },
      "source": [
        "# load existing CNN from tensorflow. Here we use VGG16, pretrained on imagenet. we will not include_top.\r\n",
        "# include_top means the flatten layer + the following dense layers. Wen only use the CNN-blocks from this network.\r\n",
        "model = applications.VGG16(weights='imagenet', include_top=False, input_shape=X_train.shape[1:])\r\n",
        "\r\n",
        "\r\n",
        "flat1 = Flatten()(model.output) # add a flatten to the VGG16\r\n",
        "class1 = Dense(256, activation='relu')(flat1) # add a Dense layer after the flatten\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "output = Dense(3, activation='softmax')(class1)\r\n",
        "\r\n",
        "model = Model(inputs=model.inputs, outputs=output) # define our final model. The first part is from VGG16 and the output is the layer defined above\r\n",
        "\r\n",
        "#apply learning rate\r\n",
        "opt = optimizers.Adam(learning_rate=0.00005)\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=1e-5,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#Early stopping\r\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "#fit call to use the datagen. 30 epichs\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 35) ,epochs = 30 , validation_data = (X_test, y_test))\r\n",
        "\r\n",
        "#Evaluation part; printing accuracy\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 32, 55, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 55, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 55, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 27, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 27, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 27, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 13, 128)        0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 13, 256)        295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 13, 256)        590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 13, 256)        590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 14,846,787\n",
            "Trainable params: 14,846,787\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "83/83 [==============================] - 374s 4s/step - loss: 0.8627 - accuracy: 0.5603 - val_loss: 113.0471 - val_accuracy: 0.4267\n",
            "Epoch 2/30\n",
            "83/83 [==============================] - 373s 4s/step - loss: 0.6283 - accuracy: 0.7175 - val_loss: 31.7668 - val_accuracy: 0.6067\n",
            "Epoch 3/30\n",
            "83/83 [==============================] - 372s 4s/step - loss: 0.5441 - accuracy: 0.7482 - val_loss: 51.2283 - val_accuracy: 0.5067\n",
            "Epoch 4/30\n",
            "83/83 [==============================] - 373s 4s/step - loss: 0.5202 - accuracy: 0.7565 - val_loss: 74.5413 - val_accuracy: 0.4600\n",
            "Epoch 5/30\n",
            "83/83 [==============================] - 370s 4s/step - loss: 0.5162 - accuracy: 0.7623 - val_loss: 25.7596 - val_accuracy: 0.6067\n",
            "Epoch 6/30\n",
            "83/83 [==============================] - 367s 4s/step - loss: 0.4553 - accuracy: 0.7940 - val_loss: 40.3523 - val_accuracy: 0.5933\n",
            "Epoch 7/30\n",
            "83/83 [==============================] - 364s 4s/step - loss: 0.4373 - accuracy: 0.8007 - val_loss: 22.8609 - val_accuracy: 0.6267\n",
            "Epoch 8/30\n",
            "83/83 [==============================] - 365s 4s/step - loss: 0.4177 - accuracy: 0.8159 - val_loss: 51.6986 - val_accuracy: 0.5933\n",
            "Epoch 9/30\n",
            "83/83 [==============================] - 364s 4s/step - loss: 0.3712 - accuracy: 0.8383 - val_loss: 19.6921 - val_accuracy: 0.5933\n",
            "Epoch 10/30\n",
            "83/83 [==============================] - 365s 4s/step - loss: 0.3848 - accuracy: 0.8231 - val_loss: 56.0170 - val_accuracy: 0.5400\n",
            "Epoch 11/30\n",
            "83/83 [==============================] - 368s 4s/step - loss: 0.3733 - accuracy: 0.8431 - val_loss: 61.5924 - val_accuracy: 0.5467\n",
            "Epoch 12/30\n",
            "83/83 [==============================] - 370s 4s/step - loss: 0.3494 - accuracy: 0.8403 - val_loss: 56.6184 - val_accuracy: 0.5333\n",
            "Epoch 13/30\n",
            "83/83 [==============================] - 366s 4s/step - loss: 0.3366 - accuracy: 0.8457 - val_loss: 79.9331 - val_accuracy: 0.4733\n",
            "Epoch 14/30\n",
            "83/83 [==============================] - 368s 4s/step - loss: 0.3090 - accuracy: 0.8634 - val_loss: 44.1812 - val_accuracy: 0.5467\n",
            "Epoch 15/30\n",
            "83/83 [==============================] - 366s 4s/step - loss: 0.3169 - accuracy: 0.8600 - val_loss: 45.3228 - val_accuracy: 0.6000\n",
            "Epoch 16/30\n",
            "83/83 [==============================] - 364s 4s/step - loss: 0.2602 - accuracy: 0.8897 - val_loss: 57.4621 - val_accuracy: 0.5333\n",
            "Epoch 17/30\n",
            "83/83 [==============================] - 367s 4s/step - loss: 0.2807 - accuracy: 0.8913 - val_loss: 30.8027 - val_accuracy: 0.6400\n",
            "Epoch 18/30\n",
            "83/83 [==============================] - 367s 4s/step - loss: 0.2536 - accuracy: 0.8957 - val_loss: 63.5034 - val_accuracy: 0.5200\n",
            "Epoch 19/30\n",
            "83/83 [==============================] - 369s 4s/step - loss: 0.2455 - accuracy: 0.9012 - val_loss: 31.4421 - val_accuracy: 0.6400\n",
            "Epoch 20/30\n",
            "83/83 [==============================] - 372s 4s/step - loss: 0.2446 - accuracy: 0.9013 - val_loss: 56.4276 - val_accuracy: 0.5400\n",
            "Epoch 21/30\n",
            "83/83 [==============================] - 372s 4s/step - loss: 0.2215 - accuracy: 0.9196 - val_loss: 56.9582 - val_accuracy: 0.5867\n",
            "Epoch 22/30\n",
            "83/83 [==============================] - 368s 4s/step - loss: 0.2079 - accuracy: 0.9226 - val_loss: 54.4137 - val_accuracy: 0.5933\n",
            "Epoch 23/30\n",
            "83/83 [==============================] - 370s 4s/step - loss: 0.2047 - accuracy: 0.9175 - val_loss: 48.4950 - val_accuracy: 0.5600\n",
            "Epoch 24/30\n",
            "83/83 [==============================] - 370s 4s/step - loss: 0.1842 - accuracy: 0.9319 - val_loss: 39.6992 - val_accuracy: 0.5733\n",
            "Epoch 25/30\n",
            "83/83 [==============================] - 369s 4s/step - loss: 0.1771 - accuracy: 0.9338 - val_loss: 55.5574 - val_accuracy: 0.6267\n",
            "Epoch 26/30\n",
            "83/83 [==============================] - 370s 4s/step - loss: 0.1855 - accuracy: 0.9275 - val_loss: 58.1570 - val_accuracy: 0.6133\n",
            "Epoch 27/30\n",
            "83/83 [==============================] - 380s 5s/step - loss: 0.1837 - accuracy: 0.9231 - val_loss: 78.6216 - val_accuracy: 0.5267\n",
            "Epoch 28/30\n",
            "83/83 [==============================] - 371s 4s/step - loss: 0.1521 - accuracy: 0.9445 - val_loss: 95.0408 - val_accuracy: 0.5133\n",
            "Epoch 29/30\n",
            "83/83 [==============================] - 371s 4s/step - loss: 0.1635 - accuracy: 0.9343 - val_loss: 79.8315 - val_accuracy: 0.5133\n",
            "Epoch 30/30\n",
            "83/83 [==============================] - 370s 4s/step - loss: 0.1348 - accuracy: 0.9444 - val_loss: 34.0572 - val_accuracy: 0.6200\n",
            "Train Accuracy of the model is 0.7120527961097604\n",
            "Test Accuracy of the model is 0.62\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RFf2ZvahT4g"
      },
      "source": [
        "**ResNet152V2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0fcFhK4vPEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e1bc52-de6f-454b-a913-33d6e03fe216"
      },
      "source": [
        "# load existing CNN from tensorflow. Here we use VGG16, pretrained on imagenet. we will not include_top.\r\n",
        "# include_top means the flatten layer + the following dense layers. Wen only use the CNN-blocks from this network.\r\n",
        "model = applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=X_train.shape[1:] ,kernel_regularizer='l2')\r\n",
        "\r\n",
        "flat1 = Flatten()(model.output) # add a flatten to the VGG16\r\n",
        "class1 = Dense(256, activation='relu')(flat1) # add a Dense layer after the flatten\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "output = Dense(3, activation='softmax')(class1) # add a dense layer after the 256-dense layer\r\n",
        "\r\n",
        "model = Model(inputs=model.inputs, outputs=output) # define our final model. The first part is from VGG16 and the output is the layer defined above\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 10 , validation_data = (X_test, y_test))\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print(\"Resnet152\")\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           [(None, 32, 55, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 61, 3)    0           input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 28, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 30, 64)   0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 14, 64)    0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 8, 14, 64)    256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 8, 14, 64)    0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 14, 64)    4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 14, 64)    0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 10, 16, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 14, 64)    36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 14, 64)    0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 14, 256)   16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 14, 256)   16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 8, 14, 256)   0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 8, 14, 256)   1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 8, 14, 256)   0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 14, 64)    16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 14, 64)    0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 10, 16, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 14, 64)    36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 14, 64)    0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 14, 256)   16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 8, 14, 256)   0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 8, 14, 256)   1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 8, 14, 256)   0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 14, 64)    16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 14, 64)    0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 10, 16, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 4, 7, 64)     36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 4, 7, 64)     256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 4, 7, 64)     0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 4, 7, 256)    0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 4, 7, 256)    16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 4, 7, 256)    0           max_pooling2d_26[0][0]           \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 4, 7, 256)    1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 4, 7, 256)    0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 7, 128)    32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 7, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 6, 9, 128)    0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 7, 128)    147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 4, 7, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 4, 7, 512)    131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 4, 7, 512)    0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 4, 7, 512)    2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 4, 7, 512)    0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 7, 128)    65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 7, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 6, 9, 128)    0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 7, 128)    147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 4, 7, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 4, 7, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 4, 7, 512)    2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 4, 7, 512)    0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 7, 128)    65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 7, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 6, 9, 128)    0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 7, 128)    147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 4, 7, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 4, 7, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 4, 7, 512)    2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 4, 7, 512)    0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 7, 128)    65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 7, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 6, 9, 128)    0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 7, 128)    147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 4, 7, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 4, 7, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_preact_bn (BatchNo (None, 4, 7, 512)    2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_preact_relu (Activ (None, 4, 7, 512)    0           conv3_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 4, 7, 128)    65536       conv3_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 4, 7, 128)    0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_pad (ZeroPadding (None, 6, 9, 128)    0           conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 4, 7, 128)    147456      conv3_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_relu (Activation (None, 4, 7, 128)    0           conv3_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_out (Add)          (None, 4, 7, 512)    0           conv3_block4_out[0][0]           \n",
            "                                                                 conv3_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_preact_bn (BatchNo (None, 4, 7, 512)    2048        conv3_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_preact_relu (Activ (None, 4, 7, 512)    0           conv3_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 4, 7, 128)    65536       conv3_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 4, 7, 128)    0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_pad (ZeroPadding (None, 6, 9, 128)    0           conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 4, 7, 128)    147456      conv3_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_relu (Activation (None, 4, 7, 128)    0           conv3_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_out (Add)          (None, 4, 7, 512)    0           conv3_block5_out[0][0]           \n",
            "                                                                 conv3_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_preact_bn (BatchNo (None, 4, 7, 512)    2048        conv3_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_preact_relu (Activ (None, 4, 7, 512)    0           conv3_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 4, 7, 128)    65536       conv3_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 4, 7, 128)    0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_pad (ZeroPadding (None, 6, 9, 128)    0           conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 4, 7, 128)    147456      conv3_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_relu (Activation (None, 4, 7, 128)    0           conv3_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_out (Add)          (None, 4, 7, 512)    0           conv3_block6_out[0][0]           \n",
            "                                                                 conv3_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_preact_bn (BatchNo (None, 4, 7, 512)    2048        conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_preact_relu (Activ (None, 4, 7, 512)    0           conv3_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 4, 7, 128)    65536       conv3_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 4, 7, 128)    0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_pad (ZeroPadding (None, 6, 9, 128)    0           conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 2, 4, 128)    147456      conv3_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_bn (BatchNormali (None, 2, 4, 128)    512         conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_relu (Activation (None, 2, 4, 128)    0           conv3_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling2D) (None, 2, 4, 512)    0           conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_3_conv (Conv2D)    (None, 2, 4, 512)    66048       conv3_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_out (Add)          (None, 2, 4, 512)    0           max_pooling2d_27[0][0]           \n",
            "                                                                 conv3_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 2, 4, 512)    2048        conv3_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 2, 4, 512)    0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 4, 256)    131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 2, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 2, 4, 1024)   525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 2, 4, 1024)   0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 2, 4, 1024)   4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 2, 4, 1024)   0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 4, 256)    262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 2, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 2, 4, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 2, 4, 1024)   4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 2, 4, 1024)   0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 4, 256)    262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 2, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 2, 4, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 2, 4, 1024)   4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 2, 4, 1024)   0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 4, 256)    262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 2, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 2, 4, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 2, 4, 1024)   4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 2, 4, 1024)   0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 4, 256)    262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 2, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 2, 4, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 2, 4, 1024)   4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 2, 4, 1024)   0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 4, 256)    262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 2, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 2, 4, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_bn (BatchNo (None, 2, 4, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_relu (Activ (None, 2, 4, 1024)   0           conv4_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 2, 4, 256)    262144      conv4_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 2, 4, 256)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 2, 4, 256)    0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Add)          (None, 2, 4, 1024)   0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_bn (BatchNo (None, 2, 4, 1024)   4096        conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_relu (Activ (None, 2, 4, 1024)   0           conv4_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 2, 4, 256)    262144      conv4_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 2, 4, 256)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 2, 4, 256)    0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Add)          (None, 2, 4, 1024)   0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_bn (BatchNo (None, 2, 4, 1024)   4096        conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_relu (Activ (None, 2, 4, 1024)   0           conv4_block9_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 2, 4, 256)    262144      conv4_block9_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 2, 4, 256)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_pad (ZeroPadding (None, 4, 6, 256)    0           conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 2, 4, 256)    589824      conv4_block9_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 2, 4, 256)    0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Add)          (None, 2, 4, 1024)   0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block10_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block10_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block10_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Add)         (None, 2, 4, 1024)   0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block11_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block11_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block11_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Add)         (None, 2, 4, 1024)   0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block12_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block12_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block12_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Add)         (None, 2, 4, 1024)   0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block13_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block13_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block13_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Add)         (None, 2, 4, 1024)   0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block14_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block14_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block14_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Add)         (None, 2, 4, 1024)   0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block15_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block15_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block15_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Add)         (None, 2, 4, 1024)   0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block16_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block16_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block16_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Add)         (None, 2, 4, 1024)   0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block17_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block17_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block17_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Add)         (None, 2, 4, 1024)   0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block18_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block18_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block18_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Add)         (None, 2, 4, 1024)   0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block19_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block19_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block19_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Add)         (None, 2, 4, 1024)   0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block20_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block20_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block20_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Add)         (None, 2, 4, 1024)   0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block21_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block21_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block21_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Add)         (None, 2, 4, 1024)   0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block22_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block22_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block22_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Add)         (None, 2, 4, 1024)   0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block23_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block23_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block23_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Add)         (None, 2, 4, 1024)   0           conv4_block22_out[0][0]          \n",
            "                                                                 conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block24_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block24_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block24_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block24_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block24_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_out (Add)         (None, 2, 4, 1024)   0           conv4_block23_out[0][0]          \n",
            "                                                                 conv4_block24_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block24_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block25_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block25_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block25_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block25_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block25_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_out (Add)         (None, 2, 4, 1024)   0           conv4_block24_out[0][0]          \n",
            "                                                                 conv4_block25_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block25_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block26_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block26_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block26_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block26_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block26_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_out (Add)         (None, 2, 4, 1024)   0           conv4_block25_out[0][0]          \n",
            "                                                                 conv4_block26_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block26_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block27_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block27_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block27_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block27_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block27_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_out (Add)         (None, 2, 4, 1024)   0           conv4_block26_out[0][0]          \n",
            "                                                                 conv4_block27_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block27_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block28_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block28_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block28_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block28_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block28_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_out (Add)         (None, 2, 4, 1024)   0           conv4_block27_out[0][0]          \n",
            "                                                                 conv4_block28_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block28_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block29_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block29_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block29_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block29_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block29_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_out (Add)         (None, 2, 4, 1024)   0           conv4_block28_out[0][0]          \n",
            "                                                                 conv4_block29_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block29_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block30_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block30_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block30_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block30_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block30_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_out (Add)         (None, 2, 4, 1024)   0           conv4_block29_out[0][0]          \n",
            "                                                                 conv4_block30_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block30_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block31_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block31_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block31_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block31_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block31_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_out (Add)         (None, 2, 4, 1024)   0           conv4_block30_out[0][0]          \n",
            "                                                                 conv4_block31_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block31_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block32_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block32_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block32_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block32_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block32_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_out (Add)         (None, 2, 4, 1024)   0           conv4_block31_out[0][0]          \n",
            "                                                                 conv4_block32_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block32_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block33_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block33_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block33_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block33_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block33_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block33_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block33_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block33_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block33_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_out (Add)         (None, 2, 4, 1024)   0           conv4_block32_out[0][0]          \n",
            "                                                                 conv4_block33_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block33_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block34_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block34_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block34_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block34_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block34_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block34_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block34_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block34_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block34_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_out (Add)         (None, 2, 4, 1024)   0           conv4_block33_out[0][0]          \n",
            "                                                                 conv4_block34_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block34_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block35_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block35_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block35_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block35_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block35_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_conv (Conv2D)   (None, 2, 4, 256)    589824      conv4_block35_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block35_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_relu (Activatio (None, 2, 4, 256)    0           conv4_block35_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_3_conv (Conv2D)   (None, 2, 4, 1024)   263168      conv4_block35_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_out (Add)         (None, 2, 4, 1024)   0           conv4_block34_out[0][0]          \n",
            "                                                                 conv4_block35_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_preact_bn (BatchN (None, 2, 4, 1024)   4096        conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_preact_relu (Acti (None, 2, 4, 1024)   0           conv4_block36_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_conv (Conv2D)   (None, 2, 4, 256)    262144      conv4_block36_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_bn (BatchNormal (None, 2, 4, 256)    1024        conv4_block36_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_relu (Activatio (None, 2, 4, 256)    0           conv4_block36_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_pad (ZeroPaddin (None, 4, 6, 256)    0           conv4_block36_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_conv (Conv2D)   (None, 1, 2, 256)    589824      conv4_block36_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_bn (BatchNormal (None, 1, 2, 256)    1024        conv4_block36_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_relu (Activatio (None, 1, 2, 256)    0           conv4_block36_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling2D) (None, 1, 2, 1024)   0           conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_3_conv (Conv2D)   (None, 1, 2, 1024)   263168      conv4_block36_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_out (Add)         (None, 1, 2, 1024)   0           max_pooling2d_28[0][0]           \n",
            "                                                                 conv4_block36_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 1, 2, 1024)   4096        conv4_block36_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 1, 2, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 2, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 3, 4, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 2, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 1, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 1, 2, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 1, 2, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 1, 2, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 1, 2, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 2, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 3, 4, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 2, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 1, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 1, 2, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 1, 2, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 1, 2, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 2, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 3, 4, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 2, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 1, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 1, 2, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 1, 2, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 1, 2, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 4096)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (None, 256)          1048832     flatten_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 3)            771         dense_33[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 59,381,251\n",
            "Trainable params: 59,237,507\n",
            "Non-trainable params: 143,744\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 761s 8s/step - loss: 1.4536 - accuracy: 0.4948 - val_loss: 64657.1133 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 731s 8s/step - loss: 0.7643 - accuracy: 0.6281 - val_loss: 69766.8750 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 724s 8s/step - loss: 0.6718 - accuracy: 0.6722 - val_loss: 3161.0942 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 718s 8s/step - loss: 0.6206 - accuracy: 0.7150 - val_loss: 4303.7173 - val_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 722s 8s/step - loss: 0.7054 - accuracy: 0.6944 - val_loss: 12595.3555 - val_accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 726s 8s/step - loss: 0.6769 - accuracy: 0.7025 - val_loss: 137318.4062 - val_accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 718s 8s/step - loss: 0.6898 - accuracy: 0.7361 - val_loss: 3326.1492 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 707s 8s/step - loss: 0.5757 - accuracy: 0.7310 - val_loss: 2994.6467 - val_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 708s 8s/step - loss: 0.5484 - accuracy: 0.7643 - val_loss: 4941.3652 - val_accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 706s 8s/step - loss: 0.5496 - accuracy: 0.7748 - val_loss: 81464.7344 - val_accuracy: 0.3333\n",
            "Resnet152\n",
            "Train Accuracy of the model is 0.33205974296630775\n",
            "Test Accuracy of the model is 0.3333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0As6m-rhbF6"
      },
      "source": [
        "**EfficientNetB7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M8nDAEh714kh",
        "outputId": "ed70a5ea-955d-491c-a118-9160ccfbf797"
      },
      "source": [
        "# load existing CNN from tensorflow. Here we use VGG16, pretrained on imagenet. we will not include_top.\r\n",
        "# include_top means the flatten layer + the following dense layers. Wen only use the CNN-blocks from this network.\r\n",
        "model = applications.EfficientNetB7(weights='imagenet', include_top=False, input_shape=X_train.shape[1:])\r\n",
        "\r\n",
        "flat1 = Flatten()(model.output) # add a flatten to the VGG16\r\n",
        "class1 = Dense(256, activation='relu')(flat1) # add a Dense layer after the flatten\r\n",
        "class2 = BatchNormalization()(class1) # This is optional to avoid overfitting\r\n",
        "class3 = Dropout(0.2)(class2) # Dropout is optional.\r\n",
        "\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "output = Dense(3, activation='softmax')(class3) # add a dense layer after the 256-dense layer\r\n",
        "\r\n",
        "model = Model(inputs=model.inputs, outputs=output) # define our final model. The first part is from VGG16 and the output is the layer defined above\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 30 , validation_data = (X_test, y_test))\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print(\"Inception EfficientNetB7\")\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.xlim([0, 1])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 32, 55, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "rescaling_2 (Rescaling)         (None, 32, 55, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "normalization_2 (Normalization) (None, 32, 55, 3)    7           rescaling_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv_pad (ZeroPadding2D)   (None, 33, 57, 3)    0           normalization_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv (Conv2D)              (None, 16, 28, 64)   1728        stem_conv_pad[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "stem_bn (BatchNormalization)    (None, 16, 28, 64)   256         stem_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "stem_activation (Activation)    (None, 16, 28, 64)   0           stem_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1a_dwconv (DepthwiseConv2D (None, 16, 28, 64)   576         stem_activation[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1a_bn (BatchNormalization) (None, 16, 28, 64)   256         block1a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1a_activation (Activation) (None, 16, 28, 64)   0           block1a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_squeeze (GlobalAvera (None, 64)           0           block1a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reshape (Reshape)    (None, 1, 1, 64)     0           block1a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reduce (Conv2D)      (None, 1, 1, 16)     1040        block1a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_expand (Conv2D)      (None, 1, 1, 64)     1088        block1a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_excite (Multiply)    (None, 16, 28, 64)   0           block1a_activation[0][0]         \n",
            "                                                                 block1a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_conv (Conv2D)   (None, 16, 28, 32)   2048        block1a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_bn (BatchNormal (None, 16, 28, 32)   128         block1a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1b_dwconv (DepthwiseConv2D (None, 16, 28, 32)   288         block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_bn (BatchNormalization) (None, 16, 28, 32)   128         block1b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1b_activation (Activation) (None, 16, 28, 32)   0           block1b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_squeeze (GlobalAvera (None, 32)           0           block1b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_excite (Multiply)    (None, 16, 28, 32)   0           block1b_activation[0][0]         \n",
            "                                                                 block1b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_project_conv (Conv2D)   (None, 16, 28, 32)   1024        block1b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_project_bn (BatchNormal (None, 16, 28, 32)   128         block1b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1b_drop (Dropout)          (None, 16, 28, 32)   0           block1b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_add (Add)               (None, 16, 28, 32)   0           block1b_drop[0][0]               \n",
            "                                                                 block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_dwconv (DepthwiseConv2D (None, 16, 28, 32)   288         block1b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block1c_bn (BatchNormalization) (None, 16, 28, 32)   128         block1c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1c_activation (Activation) (None, 16, 28, 32)   0           block1c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_squeeze (GlobalAvera (None, 32)           0           block1c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_excite (Multiply)    (None, 16, 28, 32)   0           block1c_activation[0][0]         \n",
            "                                                                 block1c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1c_project_conv (Conv2D)   (None, 16, 28, 32)   1024        block1c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1c_project_bn (BatchNormal (None, 16, 28, 32)   128         block1c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1c_drop (Dropout)          (None, 16, 28, 32)   0           block1c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_add (Add)               (None, 16, 28, 32)   0           block1c_drop[0][0]               \n",
            "                                                                 block1b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block1d_dwconv (DepthwiseConv2D (None, 16, 28, 32)   288         block1c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block1d_bn (BatchNormalization) (None, 16, 28, 32)   128         block1d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1d_activation (Activation) (None, 16, 28, 32)   0           block1d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_squeeze (GlobalAvera (None, 32)           0           block1d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_excite (Multiply)    (None, 16, 28, 32)   0           block1d_activation[0][0]         \n",
            "                                                                 block1d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1d_project_conv (Conv2D)   (None, 16, 28, 32)   1024        block1d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1d_project_bn (BatchNormal (None, 16, 28, 32)   128         block1d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1d_drop (Dropout)          (None, 16, 28, 32)   0           block1d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1d_add (Add)               (None, 16, 28, 32)   0           block1d_drop[0][0]               \n",
            "                                                                 block1c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_conv (Conv2D)    (None, 16, 28, 192)  6144        block1d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_bn (BatchNormali (None, 16, 28, 192)  768         block2a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_activation (Acti (None, 16, 28, 192)  0           block2a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv_pad (ZeroPadding (None, 17, 29, 192)  0           block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv (DepthwiseConv2D (None, 8, 14, 192)   1728        block2a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_bn (BatchNormalization) (None, 8, 14, 192)   768         block2a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2a_activation (Activation) (None, 8, 14, 192)   0           block2a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_squeeze (GlobalAvera (None, 192)          0           block2a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_excite (Multiply)    (None, 8, 14, 192)   0           block2a_activation[0][0]         \n",
            "                                                                 block2a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_conv (Conv2D)   (None, 8, 14, 48)    9216        block2a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_bn (BatchNormal (None, 8, 14, 48)    192         block2a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_conv (Conv2D)    (None, 8, 14, 288)   13824       block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_bn (BatchNormali (None, 8, 14, 288)   1152        block2b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_activation (Acti (None, 8, 14, 288)   0           block2b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_dwconv (DepthwiseConv2D (None, 8, 14, 288)   2592        block2b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2b_bn (BatchNormalization) (None, 8, 14, 288)   1152        block2b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2b_activation (Activation) (None, 8, 14, 288)   0           block2b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_squeeze (GlobalAvera (None, 288)          0           block2b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_excite (Multiply)    (None, 8, 14, 288)   0           block2b_activation[0][0]         \n",
            "                                                                 block2b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_conv (Conv2D)   (None, 8, 14, 48)    13824       block2b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_bn (BatchNormal (None, 8, 14, 48)    192         block2b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_drop (Dropout)          (None, 8, 14, 48)    0           block2b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_add (Add)               (None, 8, 14, 48)    0           block2b_drop[0][0]               \n",
            "                                                                 block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_conv (Conv2D)    (None, 8, 14, 288)   13824       block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_bn (BatchNormali (None, 8, 14, 288)   1152        block2c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_activation (Acti (None, 8, 14, 288)   0           block2c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_dwconv (DepthwiseConv2D (None, 8, 14, 288)   2592        block2c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2c_bn (BatchNormalization) (None, 8, 14, 288)   1152        block2c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2c_activation (Activation) (None, 8, 14, 288)   0           block2c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_squeeze (GlobalAvera (None, 288)          0           block2c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_excite (Multiply)    (None, 8, 14, 288)   0           block2c_activation[0][0]         \n",
            "                                                                 block2c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_project_conv (Conv2D)   (None, 8, 14, 48)    13824       block2c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_project_bn (BatchNormal (None, 8, 14, 48)    192         block2c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2c_drop (Dropout)          (None, 8, 14, 48)    0           block2c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_add (Add)               (None, 8, 14, 48)    0           block2c_drop[0][0]               \n",
            "                                                                 block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_conv (Conv2D)    (None, 8, 14, 288)   13824       block2c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_bn (BatchNormali (None, 8, 14, 288)   1152        block2d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_activation (Acti (None, 8, 14, 288)   0           block2d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_dwconv (DepthwiseConv2D (None, 8, 14, 288)   2592        block2d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2d_bn (BatchNormalization) (None, 8, 14, 288)   1152        block2d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2d_activation (Activation) (None, 8, 14, 288)   0           block2d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_squeeze (GlobalAvera (None, 288)          0           block2d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_excite (Multiply)    (None, 8, 14, 288)   0           block2d_activation[0][0]         \n",
            "                                                                 block2d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_project_conv (Conv2D)   (None, 8, 14, 48)    13824       block2d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_project_bn (BatchNormal (None, 8, 14, 48)    192         block2d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2d_drop (Dropout)          (None, 8, 14, 48)    0           block2d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_add (Add)               (None, 8, 14, 48)    0           block2d_drop[0][0]               \n",
            "                                                                 block2c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2e_expand_conv (Conv2D)    (None, 8, 14, 288)   13824       block2d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2e_expand_bn (BatchNormali (None, 8, 14, 288)   1152        block2e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2e_expand_activation (Acti (None, 8, 14, 288)   0           block2e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2e_dwconv (DepthwiseConv2D (None, 8, 14, 288)   2592        block2e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2e_bn (BatchNormalization) (None, 8, 14, 288)   1152        block2e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2e_activation (Activation) (None, 8, 14, 288)   0           block2e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_squeeze (GlobalAvera (None, 288)          0           block2e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_excite (Multiply)    (None, 8, 14, 288)   0           block2e_activation[0][0]         \n",
            "                                                                 block2e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2e_project_conv (Conv2D)   (None, 8, 14, 48)    13824       block2e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2e_project_bn (BatchNormal (None, 8, 14, 48)    192         block2e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2e_drop (Dropout)          (None, 8, 14, 48)    0           block2e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2e_add (Add)               (None, 8, 14, 48)    0           block2e_drop[0][0]               \n",
            "                                                                 block2d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2f_expand_conv (Conv2D)    (None, 8, 14, 288)   13824       block2e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2f_expand_bn (BatchNormali (None, 8, 14, 288)   1152        block2f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2f_expand_activation (Acti (None, 8, 14, 288)   0           block2f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2f_dwconv (DepthwiseConv2D (None, 8, 14, 288)   2592        block2f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2f_bn (BatchNormalization) (None, 8, 14, 288)   1152        block2f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2f_activation (Activation) (None, 8, 14, 288)   0           block2f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_squeeze (GlobalAvera (None, 288)          0           block2f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_excite (Multiply)    (None, 8, 14, 288)   0           block2f_activation[0][0]         \n",
            "                                                                 block2f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2f_project_conv (Conv2D)   (None, 8, 14, 48)    13824       block2f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2f_project_bn (BatchNormal (None, 8, 14, 48)    192         block2f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2f_drop (Dropout)          (None, 8, 14, 48)    0           block2f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2f_add (Add)               (None, 8, 14, 48)    0           block2f_drop[0][0]               \n",
            "                                                                 block2e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2g_expand_conv (Conv2D)    (None, 8, 14, 288)   13824       block2f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2g_expand_bn (BatchNormali (None, 8, 14, 288)   1152        block2g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2g_expand_activation (Acti (None, 8, 14, 288)   0           block2g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2g_dwconv (DepthwiseConv2D (None, 8, 14, 288)   2592        block2g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2g_bn (BatchNormalization) (None, 8, 14, 288)   1152        block2g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2g_activation (Activation) (None, 8, 14, 288)   0           block2g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_squeeze (GlobalAvera (None, 288)          0           block2g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_excite (Multiply)    (None, 8, 14, 288)   0           block2g_activation[0][0]         \n",
            "                                                                 block2g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2g_project_conv (Conv2D)   (None, 8, 14, 48)    13824       block2g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2g_project_bn (BatchNormal (None, 8, 14, 48)    192         block2g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2g_drop (Dropout)          (None, 8, 14, 48)    0           block2g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2g_add (Add)               (None, 8, 14, 48)    0           block2g_drop[0][0]               \n",
            "                                                                 block2f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_conv (Conv2D)    (None, 8, 14, 288)   13824       block2g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_bn (BatchNormali (None, 8, 14, 288)   1152        block3a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_activation (Acti (None, 8, 14, 288)   0           block3a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv_pad (ZeroPadding (None, 11, 17, 288)  0           block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv (DepthwiseConv2D (None, 4, 7, 288)    7200        block3a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_bn (BatchNormalization) (None, 4, 7, 288)    1152        block3a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3a_activation (Activation) (None, 4, 7, 288)    0           block3a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_squeeze (GlobalAvera (None, 288)          0           block3a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_excite (Multiply)    (None, 4, 7, 288)    0           block3a_activation[0][0]         \n",
            "                                                                 block3a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_conv (Conv2D)   (None, 4, 7, 80)     23040       block3a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_bn (BatchNormal (None, 4, 7, 80)     320         block3a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_conv (Conv2D)    (None, 4, 7, 480)    38400       block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_bn (BatchNormali (None, 4, 7, 480)    1920        block3b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_activation (Acti (None, 4, 7, 480)    0           block3b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_dwconv (DepthwiseConv2D (None, 4, 7, 480)    12000       block3b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3b_bn (BatchNormalization) (None, 4, 7, 480)    1920        block3b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3b_activation (Activation) (None, 4, 7, 480)    0           block3b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_squeeze (GlobalAvera (None, 480)          0           block3b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_excite (Multiply)    (None, 4, 7, 480)    0           block3b_activation[0][0]         \n",
            "                                                                 block3b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_conv (Conv2D)   (None, 4, 7, 80)     38400       block3b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_bn (BatchNormal (None, 4, 7, 80)     320         block3b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_drop (Dropout)          (None, 4, 7, 80)     0           block3b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_add (Add)               (None, 4, 7, 80)     0           block3b_drop[0][0]               \n",
            "                                                                 block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_conv (Conv2D)    (None, 4, 7, 480)    38400       block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_bn (BatchNormali (None, 4, 7, 480)    1920        block3c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_activation (Acti (None, 4, 7, 480)    0           block3c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_dwconv (DepthwiseConv2D (None, 4, 7, 480)    12000       block3c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3c_bn (BatchNormalization) (None, 4, 7, 480)    1920        block3c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3c_activation (Activation) (None, 4, 7, 480)    0           block3c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_squeeze (GlobalAvera (None, 480)          0           block3c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_excite (Multiply)    (None, 4, 7, 480)    0           block3c_activation[0][0]         \n",
            "                                                                 block3c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_project_conv (Conv2D)   (None, 4, 7, 80)     38400       block3c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_project_bn (BatchNormal (None, 4, 7, 80)     320         block3c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3c_drop (Dropout)          (None, 4, 7, 80)     0           block3c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_add (Add)               (None, 4, 7, 80)     0           block3c_drop[0][0]               \n",
            "                                                                 block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_conv (Conv2D)    (None, 4, 7, 480)    38400       block3c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_bn (BatchNormali (None, 4, 7, 480)    1920        block3d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_activation (Acti (None, 4, 7, 480)    0           block3d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_dwconv (DepthwiseConv2D (None, 4, 7, 480)    12000       block3d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3d_bn (BatchNormalization) (None, 4, 7, 480)    1920        block3d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3d_activation (Activation) (None, 4, 7, 480)    0           block3d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_squeeze (GlobalAvera (None, 480)          0           block3d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_excite (Multiply)    (None, 4, 7, 480)    0           block3d_activation[0][0]         \n",
            "                                                                 block3d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_project_conv (Conv2D)   (None, 4, 7, 80)     38400       block3d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_project_bn (BatchNormal (None, 4, 7, 80)     320         block3d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3d_drop (Dropout)          (None, 4, 7, 80)     0           block3d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_add (Add)               (None, 4, 7, 80)     0           block3d_drop[0][0]               \n",
            "                                                                 block3c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3e_expand_conv (Conv2D)    (None, 4, 7, 480)    38400       block3d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3e_expand_bn (BatchNormali (None, 4, 7, 480)    1920        block3e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3e_expand_activation (Acti (None, 4, 7, 480)    0           block3e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3e_dwconv (DepthwiseConv2D (None, 4, 7, 480)    12000       block3e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3e_bn (BatchNormalization) (None, 4, 7, 480)    1920        block3e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3e_activation (Activation) (None, 4, 7, 480)    0           block3e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_squeeze (GlobalAvera (None, 480)          0           block3e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_excite (Multiply)    (None, 4, 7, 480)    0           block3e_activation[0][0]         \n",
            "                                                                 block3e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3e_project_conv (Conv2D)   (None, 4, 7, 80)     38400       block3e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3e_project_bn (BatchNormal (None, 4, 7, 80)     320         block3e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3e_drop (Dropout)          (None, 4, 7, 80)     0           block3e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3e_add (Add)               (None, 4, 7, 80)     0           block3e_drop[0][0]               \n",
            "                                                                 block3d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3f_expand_conv (Conv2D)    (None, 4, 7, 480)    38400       block3e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3f_expand_bn (BatchNormali (None, 4, 7, 480)    1920        block3f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3f_expand_activation (Acti (None, 4, 7, 480)    0           block3f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3f_dwconv (DepthwiseConv2D (None, 4, 7, 480)    12000       block3f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3f_bn (BatchNormalization) (None, 4, 7, 480)    1920        block3f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3f_activation (Activation) (None, 4, 7, 480)    0           block3f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_squeeze (GlobalAvera (None, 480)          0           block3f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_excite (Multiply)    (None, 4, 7, 480)    0           block3f_activation[0][0]         \n",
            "                                                                 block3f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3f_project_conv (Conv2D)   (None, 4, 7, 80)     38400       block3f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3f_project_bn (BatchNormal (None, 4, 7, 80)     320         block3f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3f_drop (Dropout)          (None, 4, 7, 80)     0           block3f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3f_add (Add)               (None, 4, 7, 80)     0           block3f_drop[0][0]               \n",
            "                                                                 block3e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3g_expand_conv (Conv2D)    (None, 4, 7, 480)    38400       block3f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3g_expand_bn (BatchNormali (None, 4, 7, 480)    1920        block3g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3g_expand_activation (Acti (None, 4, 7, 480)    0           block3g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3g_dwconv (DepthwiseConv2D (None, 4, 7, 480)    12000       block3g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3g_bn (BatchNormalization) (None, 4, 7, 480)    1920        block3g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3g_activation (Activation) (None, 4, 7, 480)    0           block3g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_squeeze (GlobalAvera (None, 480)          0           block3g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_excite (Multiply)    (None, 4, 7, 480)    0           block3g_activation[0][0]         \n",
            "                                                                 block3g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3g_project_conv (Conv2D)   (None, 4, 7, 80)     38400       block3g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3g_project_bn (BatchNormal (None, 4, 7, 80)     320         block3g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3g_drop (Dropout)          (None, 4, 7, 80)     0           block3g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3g_add (Add)               (None, 4, 7, 80)     0           block3g_drop[0][0]               \n",
            "                                                                 block3f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_conv (Conv2D)    (None, 4, 7, 480)    38400       block3g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_bn (BatchNormali (None, 4, 7, 480)    1920        block4a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_activation (Acti (None, 4, 7, 480)    0           block4a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv_pad (ZeroPadding (None, 5, 9, 480)    0           block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv (DepthwiseConv2D (None, 2, 4, 480)    4320        block4a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_bn (BatchNormalization) (None, 2, 4, 480)    1920        block4a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4a_activation (Activation) (None, 2, 4, 480)    0           block4a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_squeeze (GlobalAvera (None, 480)          0           block4a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_excite (Multiply)    (None, 2, 4, 480)    0           block4a_activation[0][0]         \n",
            "                                                                 block4a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_conv (Conv2D)   (None, 2, 4, 160)    76800       block4a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_bn (BatchNormal (None, 2, 4, 160)    640         block4a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_activation (Acti (None, 2, 4, 960)    0           block4b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4b_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4b_activation (Activation) (None, 2, 4, 960)    0           block4b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_squeeze (GlobalAvera (None, 960)          0           block4b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_excite (Multiply)    (None, 2, 4, 960)    0           block4b_activation[0][0]         \n",
            "                                                                 block4b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_bn (BatchNormal (None, 2, 4, 160)    640         block4b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_drop (Dropout)          (None, 2, 4, 160)    0           block4b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_add (Add)               (None, 2, 4, 160)    0           block4b_drop[0][0]               \n",
            "                                                                 block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_activation (Acti (None, 2, 4, 960)    0           block4c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4c_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4c_activation (Activation) (None, 2, 4, 960)    0           block4c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_squeeze (GlobalAvera (None, 960)          0           block4c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_excite (Multiply)    (None, 2, 4, 960)    0           block4c_activation[0][0]         \n",
            "                                                                 block4c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_bn (BatchNormal (None, 2, 4, 160)    640         block4c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4c_drop (Dropout)          (None, 2, 4, 160)    0           block4c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_add (Add)               (None, 2, 4, 160)    0           block4c_drop[0][0]               \n",
            "                                                                 block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_activation (Acti (None, 2, 4, 960)    0           block4d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4d_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4d_activation (Activation) (None, 2, 4, 960)    0           block4d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_squeeze (GlobalAvera (None, 960)          0           block4d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_excite (Multiply)    (None, 2, 4, 960)    0           block4d_activation[0][0]         \n",
            "                                                                 block4d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_project_bn (BatchNormal (None, 2, 4, 160)    640         block4d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4d_drop (Dropout)          (None, 2, 4, 160)    0           block4d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_add (Add)               (None, 2, 4, 160)    0           block4d_drop[0][0]               \n",
            "                                                                 block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_activation (Acti (None, 2, 4, 960)    0           block4e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4e_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4e_activation (Activation) (None, 2, 4, 960)    0           block4e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_squeeze (GlobalAvera (None, 960)          0           block4e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_excite (Multiply)    (None, 2, 4, 960)    0           block4e_activation[0][0]         \n",
            "                                                                 block4e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_project_bn (BatchNormal (None, 2, 4, 160)    640         block4e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4e_drop (Dropout)          (None, 2, 4, 160)    0           block4e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_add (Add)               (None, 2, 4, 160)    0           block4e_drop[0][0]               \n",
            "                                                                 block4d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_activation (Acti (None, 2, 4, 960)    0           block4f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4f_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4f_activation (Activation) (None, 2, 4, 960)    0           block4f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_squeeze (GlobalAvera (None, 960)          0           block4f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_excite (Multiply)    (None, 2, 4, 960)    0           block4f_activation[0][0]         \n",
            "                                                                 block4f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_project_bn (BatchNormal (None, 2, 4, 160)    640         block4f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4f_drop (Dropout)          (None, 2, 4, 160)    0           block4f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_add (Add)               (None, 2, 4, 160)    0           block4f_drop[0][0]               \n",
            "                                                                 block4e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4g_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4g_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4g_expand_activation (Acti (None, 2, 4, 960)    0           block4g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4g_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4g_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4g_activation (Activation) (None, 2, 4, 960)    0           block4g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_squeeze (GlobalAvera (None, 960)          0           block4g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_excite (Multiply)    (None, 2, 4, 960)    0           block4g_activation[0][0]         \n",
            "                                                                 block4g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4g_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4g_project_bn (BatchNormal (None, 2, 4, 160)    640         block4g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4g_drop (Dropout)          (None, 2, 4, 160)    0           block4g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4g_add (Add)               (None, 2, 4, 160)    0           block4g_drop[0][0]               \n",
            "                                                                 block4f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4h_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4h_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4h_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4h_expand_activation (Acti (None, 2, 4, 960)    0           block4h_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4h_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4h_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4h_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4h_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4h_activation (Activation) (None, 2, 4, 960)    0           block4h_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_squeeze (GlobalAvera (None, 960)          0           block4h_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4h_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4h_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4h_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_excite (Multiply)    (None, 2, 4, 960)    0           block4h_activation[0][0]         \n",
            "                                                                 block4h_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4h_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4h_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4h_project_bn (BatchNormal (None, 2, 4, 160)    640         block4h_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4h_drop (Dropout)          (None, 2, 4, 160)    0           block4h_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4h_add (Add)               (None, 2, 4, 160)    0           block4h_drop[0][0]               \n",
            "                                                                 block4g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4i_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4i_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4i_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4i_expand_activation (Acti (None, 2, 4, 960)    0           block4i_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4i_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4i_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4i_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4i_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4i_activation (Activation) (None, 2, 4, 960)    0           block4i_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_squeeze (GlobalAvera (None, 960)          0           block4i_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4i_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4i_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4i_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_excite (Multiply)    (None, 2, 4, 960)    0           block4i_activation[0][0]         \n",
            "                                                                 block4i_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4i_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4i_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4i_project_bn (BatchNormal (None, 2, 4, 160)    640         block4i_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4i_drop (Dropout)          (None, 2, 4, 160)    0           block4i_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4i_add (Add)               (None, 2, 4, 160)    0           block4i_drop[0][0]               \n",
            "                                                                 block4h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4j_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4j_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block4j_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4j_expand_activation (Acti (None, 2, 4, 960)    0           block4j_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4j_dwconv (DepthwiseConv2D (None, 2, 4, 960)    8640        block4j_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4j_bn (BatchNormalization) (None, 2, 4, 960)    3840        block4j_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4j_activation (Activation) (None, 2, 4, 960)    0           block4j_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_squeeze (GlobalAvera (None, 960)          0           block4j_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4j_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4j_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4j_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_excite (Multiply)    (None, 2, 4, 960)    0           block4j_activation[0][0]         \n",
            "                                                                 block4j_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4j_project_conv (Conv2D)   (None, 2, 4, 160)    153600      block4j_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4j_project_bn (BatchNormal (None, 2, 4, 160)    640         block4j_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4j_drop (Dropout)          (None, 2, 4, 160)    0           block4j_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4j_add (Add)               (None, 2, 4, 160)    0           block4j_drop[0][0]               \n",
            "                                                                 block4i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_conv (Conv2D)    (None, 2, 4, 960)    153600      block4j_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_bn (BatchNormali (None, 2, 4, 960)    3840        block5a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_activation (Acti (None, 2, 4, 960)    0           block5a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_dwconv (DepthwiseConv2D (None, 2, 4, 960)    24000       block5a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5a_bn (BatchNormalization) (None, 2, 4, 960)    3840        block5a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5a_activation (Activation) (None, 2, 4, 960)    0           block5a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_squeeze (GlobalAvera (None, 960)          0           block5a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_excite (Multiply)    (None, 2, 4, 960)    0           block5a_activation[0][0]         \n",
            "                                                                 block5a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_conv (Conv2D)   (None, 2, 4, 224)    215040      block5a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_bn (BatchNormal (None, 2, 4, 224)    896         block5a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_activation (Acti (None, 2, 4, 1344)   0           block5b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5b_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5b_activation (Activation) (None, 2, 4, 1344)   0           block5b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_squeeze (GlobalAvera (None, 1344)         0           block5b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5b_activation[0][0]         \n",
            "                                                                 block5b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_bn (BatchNormal (None, 2, 4, 224)    896         block5b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_drop (Dropout)          (None, 2, 4, 224)    0           block5b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_add (Add)               (None, 2, 4, 224)    0           block5b_drop[0][0]               \n",
            "                                                                 block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_activation (Acti (None, 2, 4, 1344)   0           block5c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5c_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5c_activation (Activation) (None, 2, 4, 1344)   0           block5c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_squeeze (GlobalAvera (None, 1344)         0           block5c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5c_activation[0][0]         \n",
            "                                                                 block5c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_bn (BatchNormal (None, 2, 4, 224)    896         block5c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5c_drop (Dropout)          (None, 2, 4, 224)    0           block5c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_add (Add)               (None, 2, 4, 224)    0           block5c_drop[0][0]               \n",
            "                                                                 block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_activation (Acti (None, 2, 4, 1344)   0           block5d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5d_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5d_activation (Activation) (None, 2, 4, 1344)   0           block5d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_squeeze (GlobalAvera (None, 1344)         0           block5d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5d_activation[0][0]         \n",
            "                                                                 block5d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_project_bn (BatchNormal (None, 2, 4, 224)    896         block5d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5d_drop (Dropout)          (None, 2, 4, 224)    0           block5d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_add (Add)               (None, 2, 4, 224)    0           block5d_drop[0][0]               \n",
            "                                                                 block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_activation (Acti (None, 2, 4, 1344)   0           block5e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5e_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5e_activation (Activation) (None, 2, 4, 1344)   0           block5e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_squeeze (GlobalAvera (None, 1344)         0           block5e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5e_activation[0][0]         \n",
            "                                                                 block5e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_project_bn (BatchNormal (None, 2, 4, 224)    896         block5e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5e_drop (Dropout)          (None, 2, 4, 224)    0           block5e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_add (Add)               (None, 2, 4, 224)    0           block5e_drop[0][0]               \n",
            "                                                                 block5d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_activation (Acti (None, 2, 4, 1344)   0           block5f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5f_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5f_activation (Activation) (None, 2, 4, 1344)   0           block5f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_squeeze (GlobalAvera (None, 1344)         0           block5f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5f_activation[0][0]         \n",
            "                                                                 block5f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_project_bn (BatchNormal (None, 2, 4, 224)    896         block5f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5f_drop (Dropout)          (None, 2, 4, 224)    0           block5f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_add (Add)               (None, 2, 4, 224)    0           block5f_drop[0][0]               \n",
            "                                                                 block5e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5g_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5g_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5g_expand_activation (Acti (None, 2, 4, 1344)   0           block5g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5g_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5g_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5g_activation (Activation) (None, 2, 4, 1344)   0           block5g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_squeeze (GlobalAvera (None, 1344)         0           block5g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5g_activation[0][0]         \n",
            "                                                                 block5g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5g_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5g_project_bn (BatchNormal (None, 2, 4, 224)    896         block5g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5g_drop (Dropout)          (None, 2, 4, 224)    0           block5g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5g_add (Add)               (None, 2, 4, 224)    0           block5g_drop[0][0]               \n",
            "                                                                 block5f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5h_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5h_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5h_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5h_expand_activation (Acti (None, 2, 4, 1344)   0           block5h_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5h_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5h_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5h_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5h_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5h_activation (Activation) (None, 2, 4, 1344)   0           block5h_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_squeeze (GlobalAvera (None, 1344)         0           block5h_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5h_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5h_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5h_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5h_activation[0][0]         \n",
            "                                                                 block5h_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5h_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5h_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5h_project_bn (BatchNormal (None, 2, 4, 224)    896         block5h_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5h_drop (Dropout)          (None, 2, 4, 224)    0           block5h_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5h_add (Add)               (None, 2, 4, 224)    0           block5h_drop[0][0]               \n",
            "                                                                 block5g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5i_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5i_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5i_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5i_expand_activation (Acti (None, 2, 4, 1344)   0           block5i_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5i_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5i_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5i_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5i_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5i_activation (Activation) (None, 2, 4, 1344)   0           block5i_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_squeeze (GlobalAvera (None, 1344)         0           block5i_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5i_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5i_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5i_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5i_activation[0][0]         \n",
            "                                                                 block5i_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5i_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5i_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5i_project_bn (BatchNormal (None, 2, 4, 224)    896         block5i_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5i_drop (Dropout)          (None, 2, 4, 224)    0           block5i_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5i_add (Add)               (None, 2, 4, 224)    0           block5i_drop[0][0]               \n",
            "                                                                 block5h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5j_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5j_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block5j_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5j_expand_activation (Acti (None, 2, 4, 1344)   0           block5j_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5j_dwconv (DepthwiseConv2D (None, 2, 4, 1344)   33600       block5j_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5j_bn (BatchNormalization) (None, 2, 4, 1344)   5376        block5j_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5j_activation (Activation) (None, 2, 4, 1344)   0           block5j_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_squeeze (GlobalAvera (None, 1344)         0           block5j_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5j_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5j_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5j_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_excite (Multiply)    (None, 2, 4, 1344)   0           block5j_activation[0][0]         \n",
            "                                                                 block5j_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5j_project_conv (Conv2D)   (None, 2, 4, 224)    301056      block5j_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5j_project_bn (BatchNormal (None, 2, 4, 224)    896         block5j_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5j_drop (Dropout)          (None, 2, 4, 224)    0           block5j_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5j_add (Add)               (None, 2, 4, 224)    0           block5j_drop[0][0]               \n",
            "                                                                 block5i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_conv (Conv2D)    (None, 2, 4, 1344)   301056      block5j_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_bn (BatchNormali (None, 2, 4, 1344)   5376        block6a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_activation (Acti (None, 2, 4, 1344)   0           block6a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv_pad (ZeroPadding (None, 5, 7, 1344)   0           block6a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv (DepthwiseConv2D (None, 1, 2, 1344)   33600       block6a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_bn (BatchNormalization) (None, 1, 2, 1344)   5376        block6a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6a_activation (Activation) (None, 1, 2, 1344)   0           block6a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_squeeze (GlobalAvera (None, 1344)         0           block6a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block6a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block6a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block6a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_excite (Multiply)    (None, 1, 2, 1344)   0           block6a_activation[0][0]         \n",
            "                                                                 block6a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_conv (Conv2D)   (None, 1, 2, 384)    516096      block6a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_activation (Acti (None, 1, 2, 2304)   0           block6b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6b_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6b_activation (Activation) (None, 1, 2, 2304)   0           block6b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_squeeze (GlobalAvera (None, 2304)         0           block6b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6b_activation[0][0]         \n",
            "                                                                 block6b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_drop (Dropout)          (None, 1, 2, 384)    0           block6b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_add (Add)               (None, 1, 2, 384)    0           block6b_drop[0][0]               \n",
            "                                                                 block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_activation (Acti (None, 1, 2, 2304)   0           block6c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6c_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6c_activation (Activation) (None, 1, 2, 2304)   0           block6c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_squeeze (GlobalAvera (None, 2304)         0           block6c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6c_activation[0][0]         \n",
            "                                                                 block6c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6c_drop (Dropout)          (None, 1, 2, 384)    0           block6c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_add (Add)               (None, 1, 2, 384)    0           block6c_drop[0][0]               \n",
            "                                                                 block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_activation (Acti (None, 1, 2, 2304)   0           block6d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6d_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6d_activation (Activation) (None, 1, 2, 2304)   0           block6d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_squeeze (GlobalAvera (None, 2304)         0           block6d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6d_activation[0][0]         \n",
            "                                                                 block6d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6d_drop (Dropout)          (None, 1, 2, 384)    0           block6d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_add (Add)               (None, 1, 2, 384)    0           block6d_drop[0][0]               \n",
            "                                                                 block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6e_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6e_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6e_expand_activation (Acti (None, 1, 2, 2304)   0           block6e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6e_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6e_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6e_activation (Activation) (None, 1, 2, 2304)   0           block6e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_squeeze (GlobalAvera (None, 2304)         0           block6e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6e_activation[0][0]         \n",
            "                                                                 block6e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6e_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6e_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6e_drop (Dropout)          (None, 1, 2, 384)    0           block6e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6e_add (Add)               (None, 1, 2, 384)    0           block6e_drop[0][0]               \n",
            "                                                                 block6d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6f_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6f_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6f_expand_activation (Acti (None, 1, 2, 2304)   0           block6f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6f_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6f_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6f_activation (Activation) (None, 1, 2, 2304)   0           block6f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_squeeze (GlobalAvera (None, 2304)         0           block6f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6f_activation[0][0]         \n",
            "                                                                 block6f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6f_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6f_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6f_drop (Dropout)          (None, 1, 2, 384)    0           block6f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6f_add (Add)               (None, 1, 2, 384)    0           block6f_drop[0][0]               \n",
            "                                                                 block6e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6g_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6g_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6g_expand_activation (Acti (None, 1, 2, 2304)   0           block6g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6g_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6g_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6g_activation (Activation) (None, 1, 2, 2304)   0           block6g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_squeeze (GlobalAvera (None, 2304)         0           block6g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6g_activation[0][0]         \n",
            "                                                                 block6g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6g_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6g_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6g_drop (Dropout)          (None, 1, 2, 384)    0           block6g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6g_add (Add)               (None, 1, 2, 384)    0           block6g_drop[0][0]               \n",
            "                                                                 block6f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6h_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6h_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6h_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6h_expand_activation (Acti (None, 1, 2, 2304)   0           block6h_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6h_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6h_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6h_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6h_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6h_activation (Activation) (None, 1, 2, 2304)   0           block6h_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_squeeze (GlobalAvera (None, 2304)         0           block6h_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6h_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6h_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6h_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6h_activation[0][0]         \n",
            "                                                                 block6h_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6h_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6h_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6h_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6h_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6h_drop (Dropout)          (None, 1, 2, 384)    0           block6h_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6h_add (Add)               (None, 1, 2, 384)    0           block6h_drop[0][0]               \n",
            "                                                                 block6g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6i_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6i_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6i_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6i_expand_activation (Acti (None, 1, 2, 2304)   0           block6i_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6i_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6i_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6i_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6i_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6i_activation (Activation) (None, 1, 2, 2304)   0           block6i_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_squeeze (GlobalAvera (None, 2304)         0           block6i_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6i_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6i_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6i_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6i_activation[0][0]         \n",
            "                                                                 block6i_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6i_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6i_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6i_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6i_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6i_drop (Dropout)          (None, 1, 2, 384)    0           block6i_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6i_add (Add)               (None, 1, 2, 384)    0           block6i_drop[0][0]               \n",
            "                                                                 block6h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6j_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6j_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6j_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6j_expand_activation (Acti (None, 1, 2, 2304)   0           block6j_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6j_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6j_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6j_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6j_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6j_activation (Activation) (None, 1, 2, 2304)   0           block6j_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_squeeze (GlobalAvera (None, 2304)         0           block6j_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6j_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6j_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6j_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6j_activation[0][0]         \n",
            "                                                                 block6j_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6j_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6j_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6j_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6j_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6j_drop (Dropout)          (None, 1, 2, 384)    0           block6j_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6j_add (Add)               (None, 1, 2, 384)    0           block6j_drop[0][0]               \n",
            "                                                                 block6i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6k_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6j_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6k_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6k_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6k_expand_activation (Acti (None, 1, 2, 2304)   0           block6k_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6k_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6k_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6k_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6k_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6k_activation (Activation) (None, 1, 2, 2304)   0           block6k_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_squeeze (GlobalAvera (None, 2304)         0           block6k_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6k_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6k_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6k_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6k_activation[0][0]         \n",
            "                                                                 block6k_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6k_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6k_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6k_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6k_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6k_drop (Dropout)          (None, 1, 2, 384)    0           block6k_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6k_add (Add)               (None, 1, 2, 384)    0           block6k_drop[0][0]               \n",
            "                                                                 block6j_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6l_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6k_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6l_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6l_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6l_expand_activation (Acti (None, 1, 2, 2304)   0           block6l_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6l_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6l_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6l_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6l_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6l_activation (Activation) (None, 1, 2, 2304)   0           block6l_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_squeeze (GlobalAvera (None, 2304)         0           block6l_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6l_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6l_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6l_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6l_activation[0][0]         \n",
            "                                                                 block6l_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6l_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6l_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6l_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6l_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6l_drop (Dropout)          (None, 1, 2, 384)    0           block6l_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6l_add (Add)               (None, 1, 2, 384)    0           block6l_drop[0][0]               \n",
            "                                                                 block6k_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6m_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6l_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6m_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block6m_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6m_expand_activation (Acti (None, 1, 2, 2304)   0           block6m_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6m_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   57600       block6m_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6m_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block6m_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6m_activation (Activation) (None, 1, 2, 2304)   0           block6m_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_squeeze (GlobalAvera (None, 2304)         0           block6m_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6m_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6m_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6m_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_excite (Multiply)    (None, 1, 2, 2304)   0           block6m_activation[0][0]         \n",
            "                                                                 block6m_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6m_project_conv (Conv2D)   (None, 1, 2, 384)    884736      block6m_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6m_project_bn (BatchNormal (None, 1, 2, 384)    1536        block6m_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6m_drop (Dropout)          (None, 1, 2, 384)    0           block6m_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6m_add (Add)               (None, 1, 2, 384)    0           block6m_drop[0][0]               \n",
            "                                                                 block6l_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_conv (Conv2D)    (None, 1, 2, 2304)   884736      block6m_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_bn (BatchNormali (None, 1, 2, 2304)   9216        block7a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_activation (Acti (None, 1, 2, 2304)   0           block7a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_dwconv (DepthwiseConv2D (None, 1, 2, 2304)   20736       block7a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7a_bn (BatchNormalization) (None, 1, 2, 2304)   9216        block7a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7a_activation (Activation) (None, 1, 2, 2304)   0           block7a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_squeeze (GlobalAvera (None, 2304)         0           block7a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_excite (Multiply)    (None, 1, 2, 2304)   0           block7a_activation[0][0]         \n",
            "                                                                 block7a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_conv (Conv2D)   (None, 1, 2, 640)    1474560     block7a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_bn (BatchNormal (None, 1, 2, 640)    2560        block7a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7b_expand_conv (Conv2D)    (None, 1, 2, 3840)   2457600     block7a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_expand_bn (BatchNormali (None, 1, 2, 3840)   15360       block7b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7b_expand_activation (Acti (None, 1, 2, 3840)   0           block7b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7b_dwconv (DepthwiseConv2D (None, 1, 2, 3840)   34560       block7b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7b_bn (BatchNormalization) (None, 1, 2, 3840)   15360       block7b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7b_activation (Activation) (None, 1, 2, 3840)   0           block7b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_squeeze (GlobalAvera (None, 3840)         0           block7b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_excite (Multiply)    (None, 1, 2, 3840)   0           block7b_activation[0][0]         \n",
            "                                                                 block7b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7b_project_conv (Conv2D)   (None, 1, 2, 640)    2457600     block7b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7b_project_bn (BatchNormal (None, 1, 2, 640)    2560        block7b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7b_drop (Dropout)          (None, 1, 2, 640)    0           block7b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_add (Add)               (None, 1, 2, 640)    0           block7b_drop[0][0]               \n",
            "                                                                 block7a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_expand_conv (Conv2D)    (None, 1, 2, 3840)   2457600     block7b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7c_expand_bn (BatchNormali (None, 1, 2, 3840)   15360       block7c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7c_expand_activation (Acti (None, 1, 2, 3840)   0           block7c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7c_dwconv (DepthwiseConv2D (None, 1, 2, 3840)   34560       block7c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7c_bn (BatchNormalization) (None, 1, 2, 3840)   15360       block7c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7c_activation (Activation) (None, 1, 2, 3840)   0           block7c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_squeeze (GlobalAvera (None, 3840)         0           block7c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_excite (Multiply)    (None, 1, 2, 3840)   0           block7c_activation[0][0]         \n",
            "                                                                 block7c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7c_project_conv (Conv2D)   (None, 1, 2, 640)    2457600     block7c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7c_project_bn (BatchNormal (None, 1, 2, 640)    2560        block7c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7c_drop (Dropout)          (None, 1, 2, 640)    0           block7c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_add (Add)               (None, 1, 2, 640)    0           block7c_drop[0][0]               \n",
            "                                                                 block7b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7d_expand_conv (Conv2D)    (None, 1, 2, 3840)   2457600     block7c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7d_expand_bn (BatchNormali (None, 1, 2, 3840)   15360       block7d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7d_expand_activation (Acti (None, 1, 2, 3840)   0           block7d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7d_dwconv (DepthwiseConv2D (None, 1, 2, 3840)   34560       block7d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7d_bn (BatchNormalization) (None, 1, 2, 3840)   15360       block7d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7d_activation (Activation) (None, 1, 2, 3840)   0           block7d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_squeeze (GlobalAvera (None, 3840)         0           block7d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_excite (Multiply)    (None, 1, 2, 3840)   0           block7d_activation[0][0]         \n",
            "                                                                 block7d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7d_project_conv (Conv2D)   (None, 1, 2, 640)    2457600     block7d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7d_project_bn (BatchNormal (None, 1, 2, 640)    2560        block7d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7d_drop (Dropout)          (None, 1, 2, 640)    0           block7d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7d_add (Add)               (None, 1, 2, 640)    0           block7d_drop[0][0]               \n",
            "                                                                 block7c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "top_conv (Conv2D)               (None, 1, 2, 2560)   1638400     block7d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "top_bn (BatchNormalization)     (None, 1, 2, 2560)   10240       top_conv[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "top_activation (Activation)     (None, 1, 2, 2560)   0           top_bn[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 5120)         0           top_activation[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 256)          1310976     flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 256)          1024        dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 256)          0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 3)            771         dropout_30[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 65,410,458\n",
            "Trainable params: 65,099,219\n",
            "Non-trainable params: 311,239\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "90/90 [==============================] - 793s 8s/step - loss: 1.7006 - accuracy: 0.4534 - val_loss: 1.0827 - val_accuracy: 0.3533\n",
            "Epoch 2/30\n",
            "90/90 [==============================] - 750s 8s/step - loss: 0.7812 - accuracy: 0.6244 - val_loss: 1.8022 - val_accuracy: 0.3400\n",
            "Epoch 3/30\n",
            "90/90 [==============================] - 748s 8s/step - loss: 0.8049 - accuracy: 0.6131 - val_loss: 1.4413 - val_accuracy: 0.3667\n",
            "Epoch 4/30\n",
            "90/90 [==============================] - 761s 8s/step - loss: 0.6966 - accuracy: 0.6739 - val_loss: 1.3566 - val_accuracy: 0.3533\n",
            "Epoch 5/30\n",
            "90/90 [==============================] - 757s 8s/step - loss: 0.6917 - accuracy: 0.6911 - val_loss: 2.0416 - val_accuracy: 0.3467\n",
            "Epoch 6/30\n",
            "90/90 [==============================] - 746s 8s/step - loss: 0.6420 - accuracy: 0.7001 - val_loss: 2.6458 - val_accuracy: 0.3000\n",
            "Epoch 7/30\n",
            "90/90 [==============================] - 739s 8s/step - loss: 0.6131 - accuracy: 0.7240 - val_loss: 4.1123 - val_accuracy: 0.3733\n",
            "Epoch 8/30\n",
            "90/90 [==============================] - 743s 8s/step - loss: 0.6417 - accuracy: 0.7301 - val_loss: 8.3625 - val_accuracy: 0.3333\n",
            "Epoch 9/30\n",
            "90/90 [==============================] - 749s 8s/step - loss: 0.5809 - accuracy: 0.7312 - val_loss: 18.2575 - val_accuracy: 0.3333\n",
            "Epoch 10/30\n",
            "90/90 [==============================] - 755s 8s/step - loss: 0.5928 - accuracy: 0.7407 - val_loss: 15.1002 - val_accuracy: 0.3400\n",
            "Epoch 11/30\n",
            "90/90 [==============================] - 756s 8s/step - loss: 0.5492 - accuracy: 0.7453 - val_loss: 7.2527 - val_accuracy: 0.3600\n",
            "Epoch 12/30\n",
            "90/90 [==============================] - 763s 8s/step - loss: 0.5785 - accuracy: 0.7454 - val_loss: 4.5265 - val_accuracy: 0.3333\n",
            "Epoch 13/30\n",
            "90/90 [==============================] - 756s 8s/step - loss: 0.5577 - accuracy: 0.7519 - val_loss: 140.8788 - val_accuracy: 0.3333\n",
            "Epoch 14/30\n",
            "90/90 [==============================] - 760s 8s/step - loss: 0.5598 - accuracy: 0.7471 - val_loss: 1.2912 - val_accuracy: 0.2467\n",
            "Epoch 15/30\n",
            "64/90 [====================>.........] - ETA: 3:50 - loss: 0.5732 - accuracy: 0.7539"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-42b07420b79b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0my_pred_model1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0my_test_model1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax9Jt3a_hhVF"
      },
      "source": [
        "**ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NzDPi4VlqjZ",
        "outputId": "56987bed-8e6b-4f71-a2f3-041caae76f2b"
      },
      "source": [
        "# load existing CNN from tensorflow. Here we use VGG16, pretrained on imagenet. we will not include_top.\r\n",
        "# include_top means the flatten layer + the following dense layers. Wen only use the CNN-blocks from this network.\r\n",
        "model = applications.ResNet50(weights='imagenet', include_top=False, input_shape=X_train.shape[1:])\r\n",
        "\r\n",
        "flat1 = Flatten()(model.output) # add a flatten to the VGG16\r\n",
        "class1 = Dense(256, activation='relu')(flat1) # add a Dense layer after the flatten\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "output = Dense(3, activation='softmax')(class1) # add a dense layer after the 256-dense layer\r\n",
        "\r\n",
        "model = Model(inputs=model.inputs, outputs=output) # define our final model. The first part is from VGG16 and the output is the layer defined above\r\n",
        "\r\n",
        "\r\n",
        "#apply learning rate\r\n",
        "opt = optimizers.Adam(learning_rate=0.00005)\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=1e-5,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "\r\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # make sure we have categorical_crossentropy as loss\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 10 , validation_data = (X_test, y_test))\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print(\"Inception Resnet 50\")\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 32, 55, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 61, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 28, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 28, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 28, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 30, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 14, 64)    0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 14, 64)    4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 14, 64)    0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 14, 64)    36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 14, 64)    0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 14, 256)   16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 14, 256)   16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 14, 256)   1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 14, 256)   1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 14, 256)   0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 14, 256)   0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 14, 64)    16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 14, 64)    0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 14, 64)    36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 14, 64)    0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 14, 256)   16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 14, 256)   1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 14, 256)   0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 14, 256)   0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 14, 64)    16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 14, 64)    0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 14, 64)    36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 14, 64)    256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 14, 64)    0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 14, 256)   16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 14, 256)   1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 14, 256)   0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 14, 256)   0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 7, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 7, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 7, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 4, 7, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 4, 7, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 7, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 4, 7, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 4, 7, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 4, 7, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 7, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 7, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 7, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 4, 7, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 4, 7, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 4, 7, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 4, 7, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 7, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 7, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 7, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 4, 7, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 4, 7, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 4, 7, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 4, 7, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 7, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 7, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 7, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 4, 7, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 4, 7, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 4, 7, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 4, 7, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 4, 7, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 4, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 2, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 2, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 2, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 2, 4, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 2, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 2, 4, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 2, 4, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 2, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 2, 4, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 2, 4, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 2, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 2, 4, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 2, 4, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 2, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 2, 4, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 2, 4, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 2, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 2, 4, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 2, 4, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 2, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 1, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 1, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 1, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 1, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 1, 2, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 1, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 1, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 1, 2, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 1, 2, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 1, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 1, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 1, 2, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 1, 2, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 4096)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 256)          1048832     flatten_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 3)            771         dense_20[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 24,637,315\n",
            "Trainable params: 24,584,195\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 397s 4s/step - loss: 1.4541 - accuracy: 0.4571 - val_loss: 2.2545 - val_accuracy: 0.3600\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 384s 4s/step - loss: 0.8726 - accuracy: 0.6210 - val_loss: 3.0444 - val_accuracy: 0.3533\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 384s 4s/step - loss: 0.8014 - accuracy: 0.6603 - val_loss: 11.4352 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 388s 4s/step - loss: 0.6736 - accuracy: 0.7285 - val_loss: 27.6819 - val_accuracy: 0.3533\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 388s 4s/step - loss: 0.6115 - accuracy: 0.7207 - val_loss: 74.8862 - val_accuracy: 0.3400\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 385s 4s/step - loss: 0.6199 - accuracy: 0.7360 - val_loss: 82.8503 - val_accuracy: 0.3267\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 386s 4s/step - loss: 0.5557 - accuracy: 0.7466 - val_loss: 190.5356 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 382s 4s/step - loss: 0.5625 - accuracy: 0.7599 - val_loss: 179.5620 - val_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 386s 4s/step - loss: 0.4922 - accuracy: 0.7945 - val_loss: 148.5308 - val_accuracy: 0.2533\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 394s 4s/step - loss: 0.5677 - accuracy: 0.7583 - val_loss: 724.8725 - val_accuracy: 0.3333\n",
            "Inception Resnet 50\n",
            "Train Accuracy of the model is 0.33205974296630775\n",
            "Test Accuracy of the model is 0.3333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBTVQIdNhlGR"
      },
      "source": [
        "**MobilNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lS3DE9SOxGzS",
        "outputId": "594e6d11-f276-4213-befd-90b112b05076"
      },
      "source": [
        "# load existing CNN from tensorflow. Here we use VGG16, pretrained on imagenet. we will not include_top.\r\n",
        "# include_top means the flatten layer + the following dense layers. Wen only use the CNN-blocks from this network.\r\n",
        "model = applications.MobileNet(weights='imagenet', include_top=False, input_shape=X_train.shape[1:])\r\n",
        "\r\n",
        "flat1 = Flatten()(model.output) # add a flatten to the VGG16\r\n",
        "class1 = Dense(128, activation='relu')(flat1) # add a Dense layer after the flatten\r\n",
        "#class2 = add(Dropout(0.1)) # Dropout is optional.\r\n",
        "class2 = BatchNormalization()(class1) # BatchNormalization is optional\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "output = Dense(3, activation='softmax')(class1) # add a dense layer after the 256-dense layer\r\n",
        "\r\n",
        "model = Model(inputs=model.inputs, outputs=output) # define our final model. The first part is from VGG16 and the output is the layer defined above\r\n",
        "\r\n",
        "\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=0.00001,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=0.0005)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "diagramm =model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 20 , validation_data = (X_test, y_test))\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print(\"Inception MobileNet\")\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 32, 55, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 16, 28, 32)        864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 16, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 16, 28, 32)        288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 16, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 16, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 16, 28, 64)        2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 16, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 16, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 17, 29, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 8, 14, 64)         576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 8, 14, 64)         256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 8, 14, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 8, 14, 128)        8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 8, 14, 128)        512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 8, 14, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 8, 14, 128)        1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 8, 14, 128)        512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 8, 14, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 8, 14, 128)        16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 8, 14, 128)        512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 8, 14, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 9, 15, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 4, 7, 128)         1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 4, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 4, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 4, 7, 256)         32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 4, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 4, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 4, 7, 256)         2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 4, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 4, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 4, 7, 256)         65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 4, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 4, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 5, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 2, 3, 256)         2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 2, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 2, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 2, 3, 512)         131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 2, 3, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 2, 3, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 2, 3, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 2, 3, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 2, 3, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 2, 3, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 2, 3, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 2, 3, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 2, 3, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 2, 3, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 2, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 2, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 3, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 3,360,451\n",
            "Trainable params: 3,338,563\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "90/90 [==============================] - 44s 458ms/step - loss: 1.4420 - accuracy: 0.4744 - val_loss: 1.4837 - val_accuracy: 0.3267\n",
            "Epoch 2/20\n",
            "90/90 [==============================] - 41s 450ms/step - loss: 0.8630 - accuracy: 0.6064 - val_loss: 1.1262 - val_accuracy: 0.4333\n",
            "Epoch 3/20\n",
            "90/90 [==============================] - 41s 454ms/step - loss: 0.7790 - accuracy: 0.6386 - val_loss: 1.5221 - val_accuracy: 0.3600\n",
            "Epoch 4/20\n",
            "90/90 [==============================] - 41s 452ms/step - loss: 0.7076 - accuracy: 0.6670 - val_loss: 1.1154 - val_accuracy: 0.4200\n",
            "Epoch 5/20\n",
            "90/90 [==============================] - 41s 451ms/step - loss: 0.6745 - accuracy: 0.6779 - val_loss: 1.2638 - val_accuracy: 0.3733\n",
            "Epoch 6/20\n",
            "90/90 [==============================] - 41s 451ms/step - loss: 0.6236 - accuracy: 0.6990 - val_loss: 1.4065 - val_accuracy: 0.3733\n",
            "Epoch 7/20\n",
            "90/90 [==============================] - 41s 451ms/step - loss: 0.6317 - accuracy: 0.7056 - val_loss: 1.3497 - val_accuracy: 0.4600\n",
            "Epoch 8/20\n",
            "90/90 [==============================] - 41s 453ms/step - loss: 0.5901 - accuracy: 0.7361 - val_loss: 1.3915 - val_accuracy: 0.3867\n",
            "Epoch 9/20\n",
            "90/90 [==============================] - 41s 457ms/step - loss: 0.5817 - accuracy: 0.7351 - val_loss: 1.1429 - val_accuracy: 0.4600\n",
            "Epoch 10/20\n",
            "90/90 [==============================] - 41s 453ms/step - loss: 0.5827 - accuracy: 0.7398 - val_loss: 1.2163 - val_accuracy: 0.4333\n",
            "Epoch 11/20\n",
            "90/90 [==============================] - 40s 449ms/step - loss: 0.5136 - accuracy: 0.7694 - val_loss: 1.3392 - val_accuracy: 0.3933\n",
            "Epoch 12/20\n",
            "90/90 [==============================] - 40s 449ms/step - loss: 0.5568 - accuracy: 0.7517 - val_loss: 1.7880 - val_accuracy: 0.3733\n",
            "Epoch 13/20\n",
            "90/90 [==============================] - 40s 449ms/step - loss: 0.5107 - accuracy: 0.7688 - val_loss: 2.1167 - val_accuracy: 0.3533\n",
            "Epoch 14/20\n",
            "90/90 [==============================] - 40s 450ms/step - loss: 0.4864 - accuracy: 0.7826 - val_loss: 2.0320 - val_accuracy: 0.4067\n",
            "Epoch 15/20\n",
            "90/90 [==============================] - 40s 448ms/step - loss: 0.5186 - accuracy: 0.7742 - val_loss: 1.5400 - val_accuracy: 0.4733\n",
            "Epoch 16/20\n",
            "90/90 [==============================] - 40s 449ms/step - loss: 0.4928 - accuracy: 0.7824 - val_loss: 1.5162 - val_accuracy: 0.4733\n",
            "Epoch 17/20\n",
            "90/90 [==============================] - 40s 447ms/step - loss: 0.4611 - accuracy: 0.7953 - val_loss: 1.5547 - val_accuracy: 0.4600\n",
            "Epoch 18/20\n",
            "90/90 [==============================] - 41s 450ms/step - loss: 0.4817 - accuracy: 0.7847 - val_loss: 1.5176 - val_accuracy: 0.4733\n",
            "Epoch 19/20\n",
            "90/90 [==============================] - 41s 450ms/step - loss: 0.4531 - accuracy: 0.7966 - val_loss: 1.6435 - val_accuracy: 0.4067\n",
            "Epoch 20/20\n",
            "90/90 [==============================] - 40s 449ms/step - loss: 0.4261 - accuracy: 0.8163 - val_loss: 1.6903 - val_accuracy: 0.4400\n",
            "Inception MobileNet\n",
            "Train Accuracy of the model is 0.48523792983674885\n",
            "Test Accuracy of the model is 0.44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-PguvijhrVc"
      },
      "source": [
        "**EfficientNetB0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iwtUH4DZMqtW",
        "outputId": "73a2758e-5b3f-43bc-d1cb-01b82b81dd01"
      },
      "source": [
        "# load existing CNN from tensorflow. Here we use VGG16, pretrained on imagenet. we will not include_top.\r\n",
        "# include_top means the flatten layer + the following dense layers. Wen only use the CNN-blocks from this network.\r\n",
        "model = applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=X_train.shape[1:])\r\n",
        "\r\n",
        "flat1 = Flatten()(model.output) # add a flatten to the VGG16\r\n",
        "class1 = Dense(256, activation='relu')(flat1) # add a Dense layer after the flatten\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "output = Dense(3, activation='softmax')(class1) # add a dense layer after the 256-dense layer\r\n",
        "\r\n",
        "model = Model(inputs=model.inputs, outputs=output) # define our final model. The first part is from VGG16 and the output is the layer defined above\r\n",
        "\r\n",
        "\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=1e-5,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 100 , validation_data = (X_test, y_test))\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print(\"Inception Resnet 50\")\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 32, 55, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "rescaling_1 (Rescaling)         (None, 32, 55, 3)    0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "normalization_1 (Normalization) (None, 32, 55, 3)    7           rescaling_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv_pad (ZeroPadding2D)   (None, 33, 57, 3)    0           normalization_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv (Conv2D)              (None, 16, 28, 32)   864         stem_conv_pad[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "stem_bn (BatchNormalization)    (None, 16, 28, 32)   128         stem_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "stem_activation (Activation)    (None, 16, 28, 32)   0           stem_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1a_dwconv (DepthwiseConv2D (None, 16, 28, 32)   288         stem_activation[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1a_bn (BatchNormalization) (None, 16, 28, 32)   128         block1a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1a_activation (Activation) (None, 16, 28, 32)   0           block1a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_excite (Multiply)    (None, 16, 28, 32)   0           block1a_activation[0][0]         \n",
            "                                                                 block1a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_conv (Conv2D)   (None, 16, 28, 16)   512         block1a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_bn (BatchNormal (None, 16, 28, 16)   64          block1a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_conv (Conv2D)    (None, 16, 28, 96)   1536        block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_bn (BatchNormali (None, 16, 28, 96)   384         block2a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_activation (Acti (None, 16, 28, 96)   0           block2a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv_pad (ZeroPadding (None, 17, 29, 96)   0           block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv (DepthwiseConv2D (None, 8, 14, 96)    864         block2a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_bn (BatchNormalization) (None, 8, 14, 96)    384         block2a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2a_activation (Activation) (None, 8, 14, 96)    0           block2a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_excite (Multiply)    (None, 8, 14, 96)    0           block2a_activation[0][0]         \n",
            "                                                                 block2a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_conv (Conv2D)   (None, 8, 14, 24)    2304        block2a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_bn (BatchNormal (None, 8, 14, 24)    96          block2a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_conv (Conv2D)    (None, 8, 14, 144)   3456        block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_bn (BatchNormali (None, 8, 14, 144)   576         block2b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_activation (Acti (None, 8, 14, 144)   0           block2b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_dwconv (DepthwiseConv2D (None, 8, 14, 144)   1296        block2b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2b_bn (BatchNormalization) (None, 8, 14, 144)   576         block2b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2b_activation (Activation) (None, 8, 14, 144)   0           block2b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_excite (Multiply)    (None, 8, 14, 144)   0           block2b_activation[0][0]         \n",
            "                                                                 block2b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_conv (Conv2D)   (None, 8, 14, 24)    3456        block2b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_bn (BatchNormal (None, 8, 14, 24)    96          block2b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_drop (Dropout)          (None, 8, 14, 24)    0           block2b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_add (Add)               (None, 8, 14, 24)    0           block2b_drop[0][0]               \n",
            "                                                                 block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_conv (Conv2D)    (None, 8, 14, 144)   3456        block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_bn (BatchNormali (None, 8, 14, 144)   576         block3a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_activation (Acti (None, 8, 14, 144)   0           block3a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv_pad (ZeroPadding (None, 11, 17, 144)  0           block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv (DepthwiseConv2D (None, 4, 7, 144)    3600        block3a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_bn (BatchNormalization) (None, 4, 7, 144)    576         block3a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3a_activation (Activation) (None, 4, 7, 144)    0           block3a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_excite (Multiply)    (None, 4, 7, 144)    0           block3a_activation[0][0]         \n",
            "                                                                 block3a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_conv (Conv2D)   (None, 4, 7, 40)     5760        block3a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_bn (BatchNormal (None, 4, 7, 40)     160         block3a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_conv (Conv2D)    (None, 4, 7, 240)    9600        block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_bn (BatchNormali (None, 4, 7, 240)    960         block3b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_activation (Acti (None, 4, 7, 240)    0           block3b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_dwconv (DepthwiseConv2D (None, 4, 7, 240)    6000        block3b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3b_bn (BatchNormalization) (None, 4, 7, 240)    960         block3b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3b_activation (Activation) (None, 4, 7, 240)    0           block3b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_excite (Multiply)    (None, 4, 7, 240)    0           block3b_activation[0][0]         \n",
            "                                                                 block3b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_conv (Conv2D)   (None, 4, 7, 40)     9600        block3b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_bn (BatchNormal (None, 4, 7, 40)     160         block3b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_drop (Dropout)          (None, 4, 7, 40)     0           block3b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_add (Add)               (None, 4, 7, 40)     0           block3b_drop[0][0]               \n",
            "                                                                 block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_conv (Conv2D)    (None, 4, 7, 240)    9600        block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_bn (BatchNormali (None, 4, 7, 240)    960         block4a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_activation (Acti (None, 4, 7, 240)    0           block4a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv_pad (ZeroPadding (None, 5, 9, 240)    0           block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv (DepthwiseConv2D (None, 2, 4, 240)    2160        block4a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_bn (BatchNormalization) (None, 2, 4, 240)    960         block4a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4a_activation (Activation) (None, 2, 4, 240)    0           block4a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_excite (Multiply)    (None, 2, 4, 240)    0           block4a_activation[0][0]         \n",
            "                                                                 block4a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_conv (Conv2D)   (None, 2, 4, 80)     19200       block4a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_bn (BatchNormal (None, 2, 4, 80)     320         block4a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_conv (Conv2D)    (None, 2, 4, 480)    38400       block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_bn (BatchNormali (None, 2, 4, 480)    1920        block4b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_activation (Acti (None, 2, 4, 480)    0           block4b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_dwconv (DepthwiseConv2D (None, 2, 4, 480)    4320        block4b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4b_bn (BatchNormalization) (None, 2, 4, 480)    1920        block4b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4b_activation (Activation) (None, 2, 4, 480)    0           block4b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_excite (Multiply)    (None, 2, 4, 480)    0           block4b_activation[0][0]         \n",
            "                                                                 block4b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_conv (Conv2D)   (None, 2, 4, 80)     38400       block4b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_bn (BatchNormal (None, 2, 4, 80)     320         block4b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_drop (Dropout)          (None, 2, 4, 80)     0           block4b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_add (Add)               (None, 2, 4, 80)     0           block4b_drop[0][0]               \n",
            "                                                                 block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_conv (Conv2D)    (None, 2, 4, 480)    38400       block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_bn (BatchNormali (None, 2, 4, 480)    1920        block4c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_activation (Acti (None, 2, 4, 480)    0           block4c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_dwconv (DepthwiseConv2D (None, 2, 4, 480)    4320        block4c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4c_bn (BatchNormalization) (None, 2, 4, 480)    1920        block4c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4c_activation (Activation) (None, 2, 4, 480)    0           block4c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_excite (Multiply)    (None, 2, 4, 480)    0           block4c_activation[0][0]         \n",
            "                                                                 block4c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_conv (Conv2D)   (None, 2, 4, 80)     38400       block4c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_bn (BatchNormal (None, 2, 4, 80)     320         block4c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4c_drop (Dropout)          (None, 2, 4, 80)     0           block4c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_add (Add)               (None, 2, 4, 80)     0           block4c_drop[0][0]               \n",
            "                                                                 block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_conv (Conv2D)    (None, 2, 4, 480)    38400       block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_bn (BatchNormali (None, 2, 4, 480)    1920        block5a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_activation (Acti (None, 2, 4, 480)    0           block5a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_dwconv (DepthwiseConv2D (None, 2, 4, 480)    12000       block5a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5a_bn (BatchNormalization) (None, 2, 4, 480)    1920        block5a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5a_activation (Activation) (None, 2, 4, 480)    0           block5a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_excite (Multiply)    (None, 2, 4, 480)    0           block5a_activation[0][0]         \n",
            "                                                                 block5a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_conv (Conv2D)   (None, 2, 4, 112)    53760       block5a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_bn (BatchNormal (None, 2, 4, 112)    448         block5a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_conv (Conv2D)    (None, 2, 4, 672)    75264       block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_bn (BatchNormali (None, 2, 4, 672)    2688        block5b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_activation (Acti (None, 2, 4, 672)    0           block5b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_dwconv (DepthwiseConv2D (None, 2, 4, 672)    16800       block5b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5b_bn (BatchNormalization) (None, 2, 4, 672)    2688        block5b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5b_activation (Activation) (None, 2, 4, 672)    0           block5b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_excite (Multiply)    (None, 2, 4, 672)    0           block5b_activation[0][0]         \n",
            "                                                                 block5b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_conv (Conv2D)   (None, 2, 4, 112)    75264       block5b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_bn (BatchNormal (None, 2, 4, 112)    448         block5b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_drop (Dropout)          (None, 2, 4, 112)    0           block5b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_add (Add)               (None, 2, 4, 112)    0           block5b_drop[0][0]               \n",
            "                                                                 block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_conv (Conv2D)    (None, 2, 4, 672)    75264       block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_bn (BatchNormali (None, 2, 4, 672)    2688        block5c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_activation (Acti (None, 2, 4, 672)    0           block5c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_dwconv (DepthwiseConv2D (None, 2, 4, 672)    16800       block5c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5c_bn (BatchNormalization) (None, 2, 4, 672)    2688        block5c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5c_activation (Activation) (None, 2, 4, 672)    0           block5c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_excite (Multiply)    (None, 2, 4, 672)    0           block5c_activation[0][0]         \n",
            "                                                                 block5c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_conv (Conv2D)   (None, 2, 4, 112)    75264       block5c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_bn (BatchNormal (None, 2, 4, 112)    448         block5c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5c_drop (Dropout)          (None, 2, 4, 112)    0           block5c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_add (Add)               (None, 2, 4, 112)    0           block5c_drop[0][0]               \n",
            "                                                                 block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_conv (Conv2D)    (None, 2, 4, 672)    75264       block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_bn (BatchNormali (None, 2, 4, 672)    2688        block6a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_activation (Acti (None, 2, 4, 672)    0           block6a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv_pad (ZeroPadding (None, 5, 7, 672)    0           block6a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv (DepthwiseConv2D (None, 1, 2, 672)    16800       block6a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_bn (BatchNormalization) (None, 1, 2, 672)    2688        block6a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6a_activation (Activation) (None, 1, 2, 672)    0           block6a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_excite (Multiply)    (None, 1, 2, 672)    0           block6a_activation[0][0]         \n",
            "                                                                 block6a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_conv (Conv2D)   (None, 1, 2, 192)    129024      block6a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_bn (BatchNormal (None, 1, 2, 192)    768         block6a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_conv (Conv2D)    (None, 1, 2, 1152)   221184      block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_bn (BatchNormali (None, 1, 2, 1152)   4608        block6b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_activation (Acti (None, 1, 2, 1152)   0           block6b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_dwconv (DepthwiseConv2D (None, 1, 2, 1152)   28800       block6b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6b_bn (BatchNormalization) (None, 1, 2, 1152)   4608        block6b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6b_activation (Activation) (None, 1, 2, 1152)   0           block6b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_excite (Multiply)    (None, 1, 2, 1152)   0           block6b_activation[0][0]         \n",
            "                                                                 block6b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_conv (Conv2D)   (None, 1, 2, 192)    221184      block6b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_bn (BatchNormal (None, 1, 2, 192)    768         block6b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_drop (Dropout)          (None, 1, 2, 192)    0           block6b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_add (Add)               (None, 1, 2, 192)    0           block6b_drop[0][0]               \n",
            "                                                                 block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_conv (Conv2D)    (None, 1, 2, 1152)   221184      block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_bn (BatchNormali (None, 1, 2, 1152)   4608        block6c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_activation (Acti (None, 1, 2, 1152)   0           block6c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_dwconv (DepthwiseConv2D (None, 1, 2, 1152)   28800       block6c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6c_bn (BatchNormalization) (None, 1, 2, 1152)   4608        block6c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6c_activation (Activation) (None, 1, 2, 1152)   0           block6c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_excite (Multiply)    (None, 1, 2, 1152)   0           block6c_activation[0][0]         \n",
            "                                                                 block6c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_conv (Conv2D)   (None, 1, 2, 192)    221184      block6c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_bn (BatchNormal (None, 1, 2, 192)    768         block6c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6c_drop (Dropout)          (None, 1, 2, 192)    0           block6c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_add (Add)               (None, 1, 2, 192)    0           block6c_drop[0][0]               \n",
            "                                                                 block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_conv (Conv2D)    (None, 1, 2, 1152)   221184      block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_bn (BatchNormali (None, 1, 2, 1152)   4608        block6d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_activation (Acti (None, 1, 2, 1152)   0           block6d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_dwconv (DepthwiseConv2D (None, 1, 2, 1152)   28800       block6d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6d_bn (BatchNormalization) (None, 1, 2, 1152)   4608        block6d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6d_activation (Activation) (None, 1, 2, 1152)   0           block6d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_excite (Multiply)    (None, 1, 2, 1152)   0           block6d_activation[0][0]         \n",
            "                                                                 block6d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_conv (Conv2D)   (None, 1, 2, 192)    221184      block6d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_bn (BatchNormal (None, 1, 2, 192)    768         block6d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6d_drop (Dropout)          (None, 1, 2, 192)    0           block6d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_add (Add)               (None, 1, 2, 192)    0           block6d_drop[0][0]               \n",
            "                                                                 block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_conv (Conv2D)    (None, 1, 2, 1152)   221184      block6d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_bn (BatchNormali (None, 1, 2, 1152)   4608        block7a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_activation (Acti (None, 1, 2, 1152)   0           block7a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_dwconv (DepthwiseConv2D (None, 1, 2, 1152)   10368       block7a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7a_bn (BatchNormalization) (None, 1, 2, 1152)   4608        block7a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7a_activation (Activation) (None, 1, 2, 1152)   0           block7a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_excite (Multiply)    (None, 1, 2, 1152)   0           block7a_activation[0][0]         \n",
            "                                                                 block7a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_conv (Conv2D)   (None, 1, 2, 320)    368640      block7a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_bn (BatchNormal (None, 1, 2, 320)    1280        block7a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "top_conv (Conv2D)               (None, 1, 2, 1280)   409600      block7a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "top_bn (BatchNormalization)     (None, 1, 2, 1280)   5120        top_conv[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "top_activation (Activation)     (None, 1, 2, 1280)   0           top_bn[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_16 (Flatten)            (None, 2560)         0           top_activation[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 256)          655616      flatten_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 3)            771         dense_28[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,705,958\n",
            "Trainable params: 4,663,935\n",
            "Non-trainable params: 42,023\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "90/90 [==============================] - 61s 577ms/step - loss: 1.4305 - accuracy: 0.3229 - val_loss: 1.2004 - val_accuracy: 0.3667\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 52s 576ms/step - loss: 1.2384 - accuracy: 0.3695 - val_loss: 1.1894 - val_accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 54s 598ms/step - loss: 1.1602 - accuracy: 0.4168 - val_loss: 22.2775 - val_accuracy: 0.3733\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 56s 621ms/step - loss: 1.1097 - accuracy: 0.4443 - val_loss: 582.0492 - val_accuracy: 0.3800\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 56s 621ms/step - loss: 1.0873 - accuracy: 0.4478 - val_loss: 4730.5815 - val_accuracy: 0.3133\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 54s 602ms/step - loss: 1.0227 - accuracy: 0.5010 - val_loss: 12864.3301 - val_accuracy: 0.2733\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 53s 590ms/step - loss: 1.0353 - accuracy: 0.4853 - val_loss: 22946.0742 - val_accuracy: 0.3467\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 56s 620ms/step - loss: 0.9771 - accuracy: 0.5338 - val_loss: 37166.6445 - val_accuracy: 0.3600\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 54s 597ms/step - loss: 0.9471 - accuracy: 0.5319 - val_loss: 67012.7969 - val_accuracy: 0.3533\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 50s 556ms/step - loss: 0.9728 - accuracy: 0.5102 - val_loss: 94874.0156 - val_accuracy: 0.3200\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 49s 548ms/step - loss: 0.9658 - accuracy: 0.5318 - val_loss: 129680.7188 - val_accuracy: 0.3133\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 49s 540ms/step - loss: 0.9544 - accuracy: 0.5516 - val_loss: 116608.7031 - val_accuracy: 0.3467\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 51s 564ms/step - loss: 0.9420 - accuracy: 0.5476 - val_loss: 144308.5625 - val_accuracy: 0.3600\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 53s 585ms/step - loss: 0.9397 - accuracy: 0.5423 - val_loss: 177053.3906 - val_accuracy: 0.3600\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 55s 610ms/step - loss: 0.9150 - accuracy: 0.5478 - val_loss: 161447.8906 - val_accuracy: 0.3400\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 54s 596ms/step - loss: 0.9229 - accuracy: 0.5383 - val_loss: 120742.4688 - val_accuracy: 0.3467\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - 54s 598ms/step - loss: 0.8700 - accuracy: 0.5949 - val_loss: 131427.8906 - val_accuracy: 0.3333\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - 50s 558ms/step - loss: 0.9107 - accuracy: 0.5603 - val_loss: 165094.5000 - val_accuracy: 0.2933\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - 52s 580ms/step - loss: 0.8888 - accuracy: 0.5787 - val_loss: 162213.4844 - val_accuracy: 0.2933\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - 57s 631ms/step - loss: 0.8905 - accuracy: 0.5734 - val_loss: 197390.5000 - val_accuracy: 0.3467\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - 52s 582ms/step - loss: 0.8868 - accuracy: 0.5613 - val_loss: 155332.8594 - val_accuracy: 0.3000\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - 51s 564ms/step - loss: 0.8517 - accuracy: 0.5920 - val_loss: 151986.0781 - val_accuracy: 0.3000\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - 49s 548ms/step - loss: 0.8406 - accuracy: 0.6067 - val_loss: 169777.5156 - val_accuracy: 0.3400\n",
            "Epoch 24/100\n",
            "90/90 [==============================] - 49s 547ms/step - loss: 0.8703 - accuracy: 0.5930 - val_loss: 193085.7344 - val_accuracy: 0.3133\n",
            "Epoch 25/100\n",
            "90/90 [==============================] - 51s 566ms/step - loss: 0.8500 - accuracy: 0.5897 - val_loss: 187748.0000 - val_accuracy: 0.3467\n",
            "Epoch 26/100\n",
            "90/90 [==============================] - 54s 605ms/step - loss: 0.8450 - accuracy: 0.6004 - val_loss: 158826.4844 - val_accuracy: 0.2667\n",
            "Epoch 27/100\n",
            "90/90 [==============================] - 57s 634ms/step - loss: 0.8118 - accuracy: 0.6077 - val_loss: 128645.1094 - val_accuracy: 0.3600\n",
            "Epoch 28/100\n",
            "90/90 [==============================] - 56s 624ms/step - loss: 0.8733 - accuracy: 0.5676 - val_loss: 154401.6250 - val_accuracy: 0.3133\n",
            "Epoch 29/100\n",
            "90/90 [==============================] - 54s 599ms/step - loss: 0.7977 - accuracy: 0.6089 - val_loss: 120994.3594 - val_accuracy: 0.3467\n",
            "Epoch 30/100\n",
            "90/90 [==============================] - 51s 567ms/step - loss: 0.8271 - accuracy: 0.6120 - val_loss: 154700.6875 - val_accuracy: 0.3200\n",
            "Epoch 31/100\n",
            "90/90 [==============================] - 53s 593ms/step - loss: 0.8097 - accuracy: 0.6072 - val_loss: 176275.5938 - val_accuracy: 0.4067\n",
            "Epoch 32/100\n",
            "90/90 [==============================] - 51s 568ms/step - loss: 0.7952 - accuracy: 0.6149 - val_loss: 132511.4062 - val_accuracy: 0.3133\n",
            "Epoch 33/100\n",
            "90/90 [==============================] - 50s 558ms/step - loss: 0.8444 - accuracy: 0.5779 - val_loss: 146456.0781 - val_accuracy: 0.3267\n",
            "Epoch 34/100\n",
            "90/90 [==============================] - 50s 553ms/step - loss: 0.7874 - accuracy: 0.6082 - val_loss: 206309.4062 - val_accuracy: 0.2933\n",
            "Epoch 35/100\n",
            "90/90 [==============================] - 49s 547ms/step - loss: 0.8015 - accuracy: 0.6048 - val_loss: 181559.2188 - val_accuracy: 0.2800\n",
            "Epoch 36/100\n",
            "90/90 [==============================] - 51s 561ms/step - loss: 0.7859 - accuracy: 0.6216 - val_loss: 156405.6562 - val_accuracy: 0.3400\n",
            "Epoch 37/100\n",
            "90/90 [==============================] - 52s 575ms/step - loss: 0.7809 - accuracy: 0.6291 - val_loss: 209370.1875 - val_accuracy: 0.2200\n",
            "Epoch 38/100\n",
            "90/90 [==============================] - 57s 635ms/step - loss: 0.7715 - accuracy: 0.6361 - val_loss: 180203.1406 - val_accuracy: 0.2933\n",
            "Epoch 39/100\n",
            "90/90 [==============================] - 57s 628ms/step - loss: 0.7686 - accuracy: 0.6329 - val_loss: 171140.9062 - val_accuracy: 0.3133\n",
            "Epoch 40/100\n",
            "90/90 [==============================] - 54s 601ms/step - loss: 0.7866 - accuracy: 0.6218 - val_loss: 157091.8125 - val_accuracy: 0.3600\n",
            "Epoch 41/100\n",
            "90/90 [==============================] - 51s 569ms/step - loss: 0.7792 - accuracy: 0.6393 - val_loss: 123389.9062 - val_accuracy: 0.3000\n",
            "Epoch 42/100\n",
            "90/90 [==============================] - 53s 584ms/step - loss: 0.7573 - accuracy: 0.6541 - val_loss: 178677.1250 - val_accuracy: 0.3733\n",
            "Epoch 43/100\n",
            "90/90 [==============================] - 53s 584ms/step - loss: 0.7833 - accuracy: 0.6071 - val_loss: 128368.8281 - val_accuracy: 0.3133\n",
            "Epoch 44/100\n",
            "90/90 [==============================] - 51s 564ms/step - loss: 0.7445 - accuracy: 0.6358 - val_loss: 134858.8594 - val_accuracy: 0.3600\n",
            "Epoch 45/100\n",
            "90/90 [==============================] - 52s 579ms/step - loss: 0.7864 - accuracy: 0.6279 - val_loss: 128744.6016 - val_accuracy: 0.4133\n",
            "Epoch 46/100\n",
            "90/90 [==============================] - 51s 564ms/step - loss: 0.7299 - accuracy: 0.6539 - val_loss: 151261.6562 - val_accuracy: 0.3533\n",
            "Epoch 47/100\n",
            "90/90 [==============================] - 50s 551ms/step - loss: 0.7736 - accuracy: 0.6316 - val_loss: 134961.0469 - val_accuracy: 0.2933\n",
            "Epoch 48/100\n",
            "90/90 [==============================] - 53s 586ms/step - loss: 0.7392 - accuracy: 0.6417 - val_loss: 106869.3984 - val_accuracy: 0.3533\n",
            "Epoch 49/100\n",
            "90/90 [==============================] - 57s 630ms/step - loss: 0.7180 - accuracy: 0.6618 - val_loss: 138535.4375 - val_accuracy: 0.3200\n",
            "Epoch 50/100\n",
            "90/90 [==============================] - 55s 606ms/step - loss: 0.7688 - accuracy: 0.6384 - val_loss: 148371.8906 - val_accuracy: 0.3200\n",
            "Epoch 51/100\n",
            "90/90 [==============================] - 59s 652ms/step - loss: 0.7464 - accuracy: 0.6323 - val_loss: 137870.6719 - val_accuracy: 0.3200\n",
            "Epoch 52/100\n",
            "90/90 [==============================] - 57s 632ms/step - loss: 0.7494 - accuracy: 0.6444 - val_loss: 124968.5078 - val_accuracy: 0.3533\n",
            "Epoch 53/100\n",
            "90/90 [==============================] - 55s 605ms/step - loss: 0.7216 - accuracy: 0.6503 - val_loss: 171958.1875 - val_accuracy: 0.2800\n",
            "Epoch 54/100\n",
            "90/90 [==============================] - 57s 638ms/step - loss: 0.7137 - accuracy: 0.6574 - val_loss: 156551.5938 - val_accuracy: 0.3133\n",
            "Epoch 55/100\n",
            "90/90 [==============================] - 53s 585ms/step - loss: 0.7305 - accuracy: 0.6616 - val_loss: 129571.6172 - val_accuracy: 0.3733\n",
            "Epoch 56/100\n",
            "90/90 [==============================] - 50s 555ms/step - loss: 0.7302 - accuracy: 0.6594 - val_loss: 153783.3906 - val_accuracy: 0.3600\n",
            "Epoch 57/100\n",
            "90/90 [==============================] - 53s 584ms/step - loss: 0.7338 - accuracy: 0.6530 - val_loss: 148020.4531 - val_accuracy: 0.3200\n",
            "Epoch 58/100\n",
            "90/90 [==============================] - 53s 589ms/step - loss: 0.7286 - accuracy: 0.6610 - val_loss: 201131.2344 - val_accuracy: 0.3733\n",
            "Epoch 59/100\n",
            "90/90 [==============================] - 55s 611ms/step - loss: 0.7337 - accuracy: 0.6557 - val_loss: 183198.0938 - val_accuracy: 0.3800\n",
            "Epoch 60/100\n",
            "90/90 [==============================] - 55s 616ms/step - loss: 0.7117 - accuracy: 0.6697 - val_loss: 165203.2188 - val_accuracy: 0.3533\n",
            "Epoch 61/100\n",
            "90/90 [==============================] - 59s 659ms/step - loss: 0.7560 - accuracy: 0.6462 - val_loss: 219352.9844 - val_accuracy: 0.2933\n",
            "Epoch 62/100\n",
            "90/90 [==============================] - 59s 652ms/step - loss: 0.7403 - accuracy: 0.6425 - val_loss: 248631.0469 - val_accuracy: 0.3067\n",
            "Epoch 63/100\n",
            "90/90 [==============================] - 58s 643ms/step - loss: 0.7216 - accuracy: 0.6497 - val_loss: 233401.4688 - val_accuracy: 0.3200\n",
            "Epoch 64/100\n",
            "90/90 [==============================] - 57s 638ms/step - loss: 0.6921 - accuracy: 0.6945 - val_loss: 222184.3750 - val_accuracy: 0.3400\n",
            "Epoch 65/100\n",
            "90/90 [==============================] - 58s 646ms/step - loss: 0.6849 - accuracy: 0.6728 - val_loss: 201394.3438 - val_accuracy: 0.3400\n",
            "Epoch 66/100\n",
            "90/90 [==============================] - 51s 564ms/step - loss: 0.6955 - accuracy: 0.6716 - val_loss: 213247.8125 - val_accuracy: 0.2867\n",
            "Epoch 67/100\n",
            "90/90 [==============================] - 50s 558ms/step - loss: 0.7028 - accuracy: 0.6883 - val_loss: 191107.4062 - val_accuracy: 0.3533\n",
            "Epoch 68/100\n",
            "90/90 [==============================] - 51s 572ms/step - loss: 0.7357 - accuracy: 0.6551 - val_loss: 189204.1875 - val_accuracy: 0.3000\n",
            "Epoch 69/100\n",
            "90/90 [==============================] - 50s 553ms/step - loss: 0.7114 - accuracy: 0.6662 - val_loss: 197412.7656 - val_accuracy: 0.3267\n",
            "Epoch 70/100\n",
            "90/90 [==============================] - 54s 601ms/step - loss: 0.6970 - accuracy: 0.6518 - val_loss: 169101.9375 - val_accuracy: 0.3533\n",
            "Epoch 71/100\n",
            "90/90 [==============================] - 58s 649ms/step - loss: 0.7317 - accuracy: 0.6604 - val_loss: 190547.0469 - val_accuracy: 0.3133\n",
            "Epoch 72/100\n",
            "90/90 [==============================] - 59s 651ms/step - loss: 0.6960 - accuracy: 0.6682 - val_loss: 181739.5781 - val_accuracy: 0.3333\n",
            "Epoch 73/100\n",
            "90/90 [==============================] - 59s 652ms/step - loss: 0.6779 - accuracy: 0.6736 - val_loss: 173750.3906 - val_accuracy: 0.2933\n",
            "Epoch 74/100\n",
            "90/90 [==============================] - 57s 632ms/step - loss: 0.6795 - accuracy: 0.6806 - val_loss: 182283.6250 - val_accuracy: 0.3333\n",
            "Epoch 75/100\n",
            "90/90 [==============================] - 53s 593ms/step - loss: 0.7082 - accuracy: 0.6641 - val_loss: 187703.5938 - val_accuracy: 0.3467\n",
            "Epoch 76/100\n",
            "90/90 [==============================] - 54s 600ms/step - loss: 0.6581 - accuracy: 0.6897 - val_loss: 204259.7656 - val_accuracy: 0.3267\n",
            "Epoch 77/100\n",
            "90/90 [==============================] - 52s 581ms/step - loss: 0.7117 - accuracy: 0.6637 - val_loss: 218760.1719 - val_accuracy: 0.2933\n",
            "Epoch 78/100\n",
            "66/90 [=====================>........] - ETA: 13s - loss: 0.6942 - accuracy: 0.6681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4be6d7242992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0my_pred_model1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0my_test_model1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUclvlJShwQO"
      },
      "source": [
        "**DenseNet201**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MsvG6SqDNe7w",
        "outputId": "4511f7b0-bf16-46b5-caf8-e44ff4c5a836"
      },
      "source": [
        "# load existing CNN from tensorflow. Here we use VGG16, pretrained on imagenet. we will not include_top.\r\n",
        "# include_top means the flatten layer + the following dense layers. Wen only use the CNN-blocks from this network.\r\n",
        "model = applications.DenseNet201(weights='imagenet', include_top=False, input_shape=X_train.shape[1:])\r\n",
        "\r\n",
        "flat1 = Flatten()(model.output) # add a flatten to the VGG16\r\n",
        "class1 = Dense(256, activation='relu')(flat1) # add a Dense layer after the flatten\r\n",
        "class2 = BatchNormalization()(class1) # This is optional to avoid overfitting\r\n",
        "class3 = Dropout(0.2)(class2) # Dropout is optional.\r\n",
        "\r\n",
        "# Use softmax and 3 ouput layers because of three labels\r\n",
        "output = Dense(3, activation='softmax')(class3) # add a dense layer after the 256-dense layer\r\n",
        "\r\n",
        "model = Model(inputs=model.inputs, outputs=output) # define our final model. The first part is from VGG16 and the output is the layer defined above\r\n",
        "\r\n",
        "\r\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=0.00001,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "diagramm = model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 100 , validation_data = (X_test, y_test))\r\n",
        "y_pred_model1 = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "y_test_model1 = np.argmax(y_test, axis=-1)\r\n",
        "y_train_model1 = np.argmax(y_train, axis=-1)\r\n",
        "print(\"Inception DensNet201\")\r\n",
        "print('Train Accuracy of the model is', accuracy_score(y_train_model1, np.argmax(model.predict(X_train), axis=-1)))\r\n",
        "print('Test Accuracy of the model is', accuracy_score(y_test_model1, y_pred_model1))\r\n",
        "\r\n",
        "# Plot accuracy graph\r\n",
        "plt.plot(diagramm.history['accuracy'])\r\n",
        "plt.plot(diagramm.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.xlim([0, 1])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Plot loss graph\r\n",
        "plt.plot(diagramm.history['loss'])\r\n",
        "plt.plot(diagramm.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           [(None, 32, 55, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 38, 61, 3)    0           input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 16, 28, 64)   9408        zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 16, 28, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 16, 28, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 18, 30, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 8, 14, 64)    0           zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 14, 64)    256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 8, 14, 64)    0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 14, 128)   8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 14, 128)   512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 14, 128)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 14, 32)    36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 8, 14, 96)    0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 8, 14, 96)    384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 8, 14, 96)    0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 14, 128)   12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 14, 128)   512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 14, 128)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 14, 32)    36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 8, 14, 128)   0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 8, 14, 128)   512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 8, 14, 128)   0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 14, 128)   16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 14, 128)   512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 14, 128)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 14, 32)    36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 8, 14, 160)   0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 8, 14, 160)   640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 8, 14, 160)   0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 8, 14, 128)   20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 8, 14, 128)   512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 8, 14, 128)   0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 8, 14, 32)    36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 8, 14, 192)   0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 8, 14, 192)   768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 8, 14, 192)   0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 8, 14, 128)   24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 8, 14, 128)   512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 8, 14, 128)   0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 8, 14, 32)    36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 8, 14, 224)   0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 8, 14, 224)   896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 8, 14, 224)   0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 8, 14, 128)   28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 8, 14, 128)   512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 8, 14, 128)   0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 8, 14, 32)    36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 8, 14, 256)   0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 8, 14, 256)   1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 8, 14, 256)   0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 8, 14, 128)   32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 4, 7, 128)    0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 7, 128)    512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 4, 7, 128)    0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 7, 128)    16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 7, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 4, 7, 160)    0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 4, 7, 160)    640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 4, 7, 160)    0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 7, 128)    20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 7, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 4, 7, 192)    0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 4, 7, 192)    768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 4, 7, 192)    0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 7, 128)    24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 7, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 4, 7, 224)    0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 4, 7, 224)    896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 4, 7, 224)    0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 7, 128)    28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 7, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 4, 7, 256)    0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 4, 7, 256)    1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 4, 7, 256)    0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 4, 7, 128)    32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 4, 7, 128)    0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 4, 7, 288)    0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 4, 7, 288)    1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 4, 7, 288)    0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 4, 7, 128)    36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 4, 7, 128)    0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 4, 7, 320)    0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 4, 7, 320)    1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 4, 7, 320)    0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 4, 7, 128)    40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 4, 7, 128)    0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 4, 7, 352)    0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 4, 7, 352)    1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 4, 7, 352)    0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 4, 7, 128)    45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 4, 7, 128)    0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 4, 7, 384)    0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 4, 7, 384)    1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 4, 7, 384)    0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 4, 7, 128)    49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 4, 7, 128)    512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 4, 7, 128)    0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 4, 7, 32)     36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 4, 7, 416)    0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 4, 7, 416)    1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 4, 7, 416)    0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 4, 7, 128)    53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 4, 7, 128)    512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 4, 7, 128)    0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 4, 7, 32)     36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 4, 7, 448)    0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 4, 7, 448)    1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 4, 7, 448)    0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 4, 7, 128)    57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 4, 7, 128)    512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 4, 7, 128)    0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 4, 7, 32)     36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 4, 7, 480)    0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 4, 7, 480)    1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 4, 7, 480)    0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 4, 7, 128)    61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 4, 7, 128)    512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 4, 7, 128)    0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 4, 7, 32)     36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 4, 7, 512)    0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 4, 7, 512)    2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 4, 7, 512)    0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 4, 7, 256)    131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 2, 3, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 3, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 2, 3, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 3, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 3, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 2, 3, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 2, 3, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 2, 3, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 3, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 3, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 2, 3, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 2, 3, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 2, 3, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 3, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 3, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 2, 3, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 2, 3, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 2, 3, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 3, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 3, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 2, 3, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 2, 3, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 2, 3, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 3, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 3, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 2, 3, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 2, 3, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 2, 3, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 3, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 3, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 2, 3, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 2, 3, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 2, 3, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 2, 3, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 2, 3, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 2, 3, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 2, 3, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 2, 3, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 2, 3, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 2, 3, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 2, 3, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 2, 3, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 2, 3, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 2, 3, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 2, 3, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 2, 3, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 2, 3, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 2, 3, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 2, 3, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 2, 3, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 2, 3, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 2, 3, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 2, 3, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 2, 3, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 2, 3, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 2, 3, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 2, 3, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 2, 3, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 2, 3, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 2, 3, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 2, 3, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 2, 3, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 2, 3, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 2, 3, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 2, 3, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 2, 3, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 2, 3, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 2, 3, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 2, 3, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 2, 3, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 2, 3, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 2, 3, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 2, 3, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 2, 3, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 2, 3, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 2, 3, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 2, 3, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 2, 3, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 2, 3, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 2, 3, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 2, 3, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 2, 3, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 2, 3, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 2, 3, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 2, 3, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 2, 3, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 2, 3, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 2, 3, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 2, 3, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 2, 3, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 2, 3, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 2, 3, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 2, 3, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 2, 3, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 2, 3, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 2, 3, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 2, 3, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 2, 3, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 2, 3, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 2, 3, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 2, 3, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 2, 3, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 2, 3, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 2, 3, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 2, 3, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 2, 3, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 2, 3, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 2, 3, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_0_bn (BatchNormal (None, 2, 3, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_0_relu (Activatio (None, 2, 3, 1024)   0           conv4_block25_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_conv (Conv2D)   (None, 2, 3, 128)    131072      conv4_block25_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_concat (Concatena (None, 2, 3, 1056)   0           conv4_block24_concat[0][0]       \n",
            "                                                                 conv4_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_0_bn (BatchNormal (None, 2, 3, 1056)   4224        conv4_block25_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_0_relu (Activatio (None, 2, 3, 1056)   0           conv4_block26_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_conv (Conv2D)   (None, 2, 3, 128)    135168      conv4_block26_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_concat (Concatena (None, 2, 3, 1088)   0           conv4_block25_concat[0][0]       \n",
            "                                                                 conv4_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_0_bn (BatchNormal (None, 2, 3, 1088)   4352        conv4_block26_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_0_relu (Activatio (None, 2, 3, 1088)   0           conv4_block27_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_conv (Conv2D)   (None, 2, 3, 128)    139264      conv4_block27_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_concat (Concatena (None, 2, 3, 1120)   0           conv4_block26_concat[0][0]       \n",
            "                                                                 conv4_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_0_bn (BatchNormal (None, 2, 3, 1120)   4480        conv4_block27_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_0_relu (Activatio (None, 2, 3, 1120)   0           conv4_block28_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_conv (Conv2D)   (None, 2, 3, 128)    143360      conv4_block28_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_concat (Concatena (None, 2, 3, 1152)   0           conv4_block27_concat[0][0]       \n",
            "                                                                 conv4_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_0_bn (BatchNormal (None, 2, 3, 1152)   4608        conv4_block28_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_0_relu (Activatio (None, 2, 3, 1152)   0           conv4_block29_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_conv (Conv2D)   (None, 2, 3, 128)    147456      conv4_block29_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_concat (Concatena (None, 2, 3, 1184)   0           conv4_block28_concat[0][0]       \n",
            "                                                                 conv4_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_0_bn (BatchNormal (None, 2, 3, 1184)   4736        conv4_block29_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_0_relu (Activatio (None, 2, 3, 1184)   0           conv4_block30_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_conv (Conv2D)   (None, 2, 3, 128)    151552      conv4_block30_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_concat (Concatena (None, 2, 3, 1216)   0           conv4_block29_concat[0][0]       \n",
            "                                                                 conv4_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_0_bn (BatchNormal (None, 2, 3, 1216)   4864        conv4_block30_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_0_relu (Activatio (None, 2, 3, 1216)   0           conv4_block31_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_conv (Conv2D)   (None, 2, 3, 128)    155648      conv4_block31_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_concat (Concatena (None, 2, 3, 1248)   0           conv4_block30_concat[0][0]       \n",
            "                                                                 conv4_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_0_bn (BatchNormal (None, 2, 3, 1248)   4992        conv4_block31_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_0_relu (Activatio (None, 2, 3, 1248)   0           conv4_block32_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_conv (Conv2D)   (None, 2, 3, 128)    159744      conv4_block32_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_concat (Concatena (None, 2, 3, 1280)   0           conv4_block31_concat[0][0]       \n",
            "                                                                 conv4_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_0_bn (BatchNormal (None, 2, 3, 1280)   5120        conv4_block32_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_0_relu (Activatio (None, 2, 3, 1280)   0           conv4_block33_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_conv (Conv2D)   (None, 2, 3, 128)    163840      conv4_block33_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block33_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block33_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block33_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_concat (Concatena (None, 2, 3, 1312)   0           conv4_block32_concat[0][0]       \n",
            "                                                                 conv4_block33_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_0_bn (BatchNormal (None, 2, 3, 1312)   5248        conv4_block33_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_0_relu (Activatio (None, 2, 3, 1312)   0           conv4_block34_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_conv (Conv2D)   (None, 2, 3, 128)    167936      conv4_block34_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block34_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block34_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block34_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_concat (Concatena (None, 2, 3, 1344)   0           conv4_block33_concat[0][0]       \n",
            "                                                                 conv4_block34_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_0_bn (BatchNormal (None, 2, 3, 1344)   5376        conv4_block34_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_0_relu (Activatio (None, 2, 3, 1344)   0           conv4_block35_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_conv (Conv2D)   (None, 2, 3, 128)    172032      conv4_block35_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block35_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block35_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block35_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_concat (Concatena (None, 2, 3, 1376)   0           conv4_block34_concat[0][0]       \n",
            "                                                                 conv4_block35_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_0_bn (BatchNormal (None, 2, 3, 1376)   5504        conv4_block35_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_0_relu (Activatio (None, 2, 3, 1376)   0           conv4_block36_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_conv (Conv2D)   (None, 2, 3, 128)    176128      conv4_block36_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block36_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block36_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block36_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_concat (Concatena (None, 2, 3, 1408)   0           conv4_block35_concat[0][0]       \n",
            "                                                                 conv4_block36_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_0_bn (BatchNormal (None, 2, 3, 1408)   5632        conv4_block36_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_0_relu (Activatio (None, 2, 3, 1408)   0           conv4_block37_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_1_conv (Conv2D)   (None, 2, 3, 128)    180224      conv4_block37_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block37_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block37_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block37_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block37_concat (Concatena (None, 2, 3, 1440)   0           conv4_block36_concat[0][0]       \n",
            "                                                                 conv4_block37_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_0_bn (BatchNormal (None, 2, 3, 1440)   5760        conv4_block37_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_0_relu (Activatio (None, 2, 3, 1440)   0           conv4_block38_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_1_conv (Conv2D)   (None, 2, 3, 128)    184320      conv4_block38_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block38_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block38_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block38_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block38_concat (Concatena (None, 2, 3, 1472)   0           conv4_block37_concat[0][0]       \n",
            "                                                                 conv4_block38_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_0_bn (BatchNormal (None, 2, 3, 1472)   5888        conv4_block38_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_0_relu (Activatio (None, 2, 3, 1472)   0           conv4_block39_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_1_conv (Conv2D)   (None, 2, 3, 128)    188416      conv4_block39_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block39_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block39_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block39_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block39_concat (Concatena (None, 2, 3, 1504)   0           conv4_block38_concat[0][0]       \n",
            "                                                                 conv4_block39_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_0_bn (BatchNormal (None, 2, 3, 1504)   6016        conv4_block39_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_0_relu (Activatio (None, 2, 3, 1504)   0           conv4_block40_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_1_conv (Conv2D)   (None, 2, 3, 128)    192512      conv4_block40_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block40_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block40_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block40_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block40_concat (Concatena (None, 2, 3, 1536)   0           conv4_block39_concat[0][0]       \n",
            "                                                                 conv4_block40_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_0_bn (BatchNormal (None, 2, 3, 1536)   6144        conv4_block40_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_0_relu (Activatio (None, 2, 3, 1536)   0           conv4_block41_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_1_conv (Conv2D)   (None, 2, 3, 128)    196608      conv4_block41_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block41_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block41_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block41_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block41_concat (Concatena (None, 2, 3, 1568)   0           conv4_block40_concat[0][0]       \n",
            "                                                                 conv4_block41_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_0_bn (BatchNormal (None, 2, 3, 1568)   6272        conv4_block41_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_0_relu (Activatio (None, 2, 3, 1568)   0           conv4_block42_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_1_conv (Conv2D)   (None, 2, 3, 128)    200704      conv4_block42_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block42_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block42_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block42_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block42_concat (Concatena (None, 2, 3, 1600)   0           conv4_block41_concat[0][0]       \n",
            "                                                                 conv4_block42_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_0_bn (BatchNormal (None, 2, 3, 1600)   6400        conv4_block42_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_0_relu (Activatio (None, 2, 3, 1600)   0           conv4_block43_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_1_conv (Conv2D)   (None, 2, 3, 128)    204800      conv4_block43_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block43_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block43_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block43_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block43_concat (Concatena (None, 2, 3, 1632)   0           conv4_block42_concat[0][0]       \n",
            "                                                                 conv4_block43_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_0_bn (BatchNormal (None, 2, 3, 1632)   6528        conv4_block43_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_0_relu (Activatio (None, 2, 3, 1632)   0           conv4_block44_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_1_conv (Conv2D)   (None, 2, 3, 128)    208896      conv4_block44_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block44_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block44_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block44_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block44_concat (Concatena (None, 2, 3, 1664)   0           conv4_block43_concat[0][0]       \n",
            "                                                                 conv4_block44_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_0_bn (BatchNormal (None, 2, 3, 1664)   6656        conv4_block44_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_0_relu (Activatio (None, 2, 3, 1664)   0           conv4_block45_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_1_conv (Conv2D)   (None, 2, 3, 128)    212992      conv4_block45_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block45_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block45_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block45_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block45_concat (Concatena (None, 2, 3, 1696)   0           conv4_block44_concat[0][0]       \n",
            "                                                                 conv4_block45_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_0_bn (BatchNormal (None, 2, 3, 1696)   6784        conv4_block45_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_0_relu (Activatio (None, 2, 3, 1696)   0           conv4_block46_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_1_conv (Conv2D)   (None, 2, 3, 128)    217088      conv4_block46_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block46_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block46_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block46_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block46_concat (Concatena (None, 2, 3, 1728)   0           conv4_block45_concat[0][0]       \n",
            "                                                                 conv4_block46_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_0_bn (BatchNormal (None, 2, 3, 1728)   6912        conv4_block46_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_0_relu (Activatio (None, 2, 3, 1728)   0           conv4_block47_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_1_conv (Conv2D)   (None, 2, 3, 128)    221184      conv4_block47_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block47_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block47_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block47_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block47_concat (Concatena (None, 2, 3, 1760)   0           conv4_block46_concat[0][0]       \n",
            "                                                                 conv4_block47_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_0_bn (BatchNormal (None, 2, 3, 1760)   7040        conv4_block47_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_0_relu (Activatio (None, 2, 3, 1760)   0           conv4_block48_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_1_conv (Conv2D)   (None, 2, 3, 128)    225280      conv4_block48_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_1_bn (BatchNormal (None, 2, 3, 128)    512         conv4_block48_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_1_relu (Activatio (None, 2, 3, 128)    0           conv4_block48_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_2_conv (Conv2D)   (None, 2, 3, 32)     36864       conv4_block48_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block48_concat (Concatena (None, 2, 3, 1792)   0           conv4_block47_concat[0][0]       \n",
            "                                                                 conv4_block48_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 2, 3, 1792)   7168        conv4_block48_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 2, 3, 1792)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 2, 3, 896)    1605632     pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 1, 1, 896)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 1, 896)    3584        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 1, 1, 896)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 128)    114688      conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 1, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 1, 1, 928)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 1, 1, 928)    3712        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 1, 1, 928)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 128)    118784      conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 1, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 1, 1, 960)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 1, 1, 960)    3840        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 1, 1, 960)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 128)    122880      conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 1, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 1, 1, 992)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 1, 1, 992)    3968        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 1, 1, 992)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 1, 1, 128)    126976      conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 1, 1, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 1, 1, 1024)   0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 1, 1, 1024)   4096        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 1, 1, 1024)   0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 1, 1, 128)    131072      conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 1, 1, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 1, 1, 1056)   0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 1, 1, 1056)   4224        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 1, 1, 1056)   0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 1, 1, 128)    135168      conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 1, 1, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 1, 1, 1088)   0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 1, 1, 1088)   4352        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 1, 1, 1088)   0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 1, 1, 128)    139264      conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 1, 1, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 1, 1, 1120)   0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 1, 1, 1120)   4480        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 1, 1, 1120)   0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 1, 1, 128)    143360      conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 1, 1, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 1, 1, 1152)   0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 1, 1, 1152)   4608        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 1, 1, 1152)   0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 1, 1, 128)    147456      conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 1, 1, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 1, 1, 1184)   0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 1, 1, 1184)   4736        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 1, 1, 1184)   0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 1, 1, 128)    151552      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 1, 1, 1216)   0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 1, 1, 1216)   4864        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 1, 1, 1216)   0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 1, 1, 128)    155648      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 1, 1, 1248)   0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 1, 1, 1248)   4992        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 1, 1, 1248)   0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 1, 1, 128)    159744      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 1, 1, 1280)   0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 1, 1, 1280)   5120        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 1, 1, 1280)   0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 1, 1, 128)    163840      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 1, 1, 1312)   0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 1, 1, 1312)   5248        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 1, 1, 1312)   0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 1, 1, 128)    167936      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 1, 1, 1344)   0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 1, 1, 1344)   5376        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 1, 1, 1344)   0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 1, 1, 128)    172032      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 1, 1, 1376)   0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 1, 1, 1376)   5504        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 1, 1, 1376)   0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 1, 1, 128)    176128      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 1, 1, 1408)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_0_bn (BatchNormal (None, 1, 1, 1408)   5632        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_0_relu (Activatio (None, 1, 1, 1408)   0           conv5_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_1_conv (Conv2D)   (None, 1, 1, 128)    180224      conv5_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block17_concat (Concatena (None, 1, 1, 1440)   0           conv5_block16_concat[0][0]       \n",
            "                                                                 conv5_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_0_bn (BatchNormal (None, 1, 1, 1440)   5760        conv5_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_0_relu (Activatio (None, 1, 1, 1440)   0           conv5_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_1_conv (Conv2D)   (None, 1, 1, 128)    184320      conv5_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block18_concat (Concatena (None, 1, 1, 1472)   0           conv5_block17_concat[0][0]       \n",
            "                                                                 conv5_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_0_bn (BatchNormal (None, 1, 1, 1472)   5888        conv5_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_0_relu (Activatio (None, 1, 1, 1472)   0           conv5_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_1_conv (Conv2D)   (None, 1, 1, 128)    188416      conv5_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block19_concat (Concatena (None, 1, 1, 1504)   0           conv5_block18_concat[0][0]       \n",
            "                                                                 conv5_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_0_bn (BatchNormal (None, 1, 1, 1504)   6016        conv5_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_0_relu (Activatio (None, 1, 1, 1504)   0           conv5_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_1_conv (Conv2D)   (None, 1, 1, 128)    192512      conv5_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block20_concat (Concatena (None, 1, 1, 1536)   0           conv5_block19_concat[0][0]       \n",
            "                                                                 conv5_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_0_bn (BatchNormal (None, 1, 1, 1536)   6144        conv5_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_0_relu (Activatio (None, 1, 1, 1536)   0           conv5_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_1_conv (Conv2D)   (None, 1, 1, 128)    196608      conv5_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block21_concat (Concatena (None, 1, 1, 1568)   0           conv5_block20_concat[0][0]       \n",
            "                                                                 conv5_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_0_bn (BatchNormal (None, 1, 1, 1568)   6272        conv5_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_0_relu (Activatio (None, 1, 1, 1568)   0           conv5_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_1_conv (Conv2D)   (None, 1, 1, 128)    200704      conv5_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block22_concat (Concatena (None, 1, 1, 1600)   0           conv5_block21_concat[0][0]       \n",
            "                                                                 conv5_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_0_bn (BatchNormal (None, 1, 1, 1600)   6400        conv5_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_0_relu (Activatio (None, 1, 1, 1600)   0           conv5_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_1_conv (Conv2D)   (None, 1, 1, 128)    204800      conv5_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block23_concat (Concatena (None, 1, 1, 1632)   0           conv5_block22_concat[0][0]       \n",
            "                                                                 conv5_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_0_bn (BatchNormal (None, 1, 1, 1632)   6528        conv5_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_0_relu (Activatio (None, 1, 1, 1632)   0           conv5_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_1_conv (Conv2D)   (None, 1, 1, 128)    208896      conv5_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block24_concat (Concatena (None, 1, 1, 1664)   0           conv5_block23_concat[0][0]       \n",
            "                                                                 conv5_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_0_bn (BatchNormal (None, 1, 1, 1664)   6656        conv5_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_0_relu (Activatio (None, 1, 1, 1664)   0           conv5_block25_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_1_conv (Conv2D)   (None, 1, 1, 128)    212992      conv5_block25_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block25_concat (Concatena (None, 1, 1, 1696)   0           conv5_block24_concat[0][0]       \n",
            "                                                                 conv5_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_0_bn (BatchNormal (None, 1, 1, 1696)   6784        conv5_block25_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_0_relu (Activatio (None, 1, 1, 1696)   0           conv5_block26_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_1_conv (Conv2D)   (None, 1, 1, 128)    217088      conv5_block26_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block26_concat (Concatena (None, 1, 1, 1728)   0           conv5_block25_concat[0][0]       \n",
            "                                                                 conv5_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_0_bn (BatchNormal (None, 1, 1, 1728)   6912        conv5_block26_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_0_relu (Activatio (None, 1, 1, 1728)   0           conv5_block27_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_1_conv (Conv2D)   (None, 1, 1, 128)    221184      conv5_block27_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block27_concat (Concatena (None, 1, 1, 1760)   0           conv5_block26_concat[0][0]       \n",
            "                                                                 conv5_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_0_bn (BatchNormal (None, 1, 1, 1760)   7040        conv5_block27_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_0_relu (Activatio (None, 1, 1, 1760)   0           conv5_block28_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_1_conv (Conv2D)   (None, 1, 1, 128)    225280      conv5_block28_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block28_concat (Concatena (None, 1, 1, 1792)   0           conv5_block27_concat[0][0]       \n",
            "                                                                 conv5_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_0_bn (BatchNormal (None, 1, 1, 1792)   7168        conv5_block28_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_0_relu (Activatio (None, 1, 1, 1792)   0           conv5_block29_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_1_conv (Conv2D)   (None, 1, 1, 128)    229376      conv5_block29_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block29_concat (Concatena (None, 1, 1, 1824)   0           conv5_block28_concat[0][0]       \n",
            "                                                                 conv5_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_0_bn (BatchNormal (None, 1, 1, 1824)   7296        conv5_block29_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_0_relu (Activatio (None, 1, 1, 1824)   0           conv5_block30_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_1_conv (Conv2D)   (None, 1, 1, 128)    233472      conv5_block30_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block30_concat (Concatena (None, 1, 1, 1856)   0           conv5_block29_concat[0][0]       \n",
            "                                                                 conv5_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_0_bn (BatchNormal (None, 1, 1, 1856)   7424        conv5_block30_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_0_relu (Activatio (None, 1, 1, 1856)   0           conv5_block31_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_1_conv (Conv2D)   (None, 1, 1, 128)    237568      conv5_block31_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block31_concat (Concatena (None, 1, 1, 1888)   0           conv5_block30_concat[0][0]       \n",
            "                                                                 conv5_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_0_bn (BatchNormal (None, 1, 1, 1888)   7552        conv5_block31_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_0_relu (Activatio (None, 1, 1, 1888)   0           conv5_block32_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_1_conv (Conv2D)   (None, 1, 1, 128)    241664      conv5_block32_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block32_concat (Concatena (None, 1, 1, 1920)   0           conv5_block31_concat[0][0]       \n",
            "                                                                 conv5_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 1, 1, 1920)   7680        conv5_block32_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 1, 1, 1920)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_16 (Flatten)            (None, 1920)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 256)          491776      flatten_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 256)          1024        dense_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 256)          0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (None, 3)            771         dropout_17[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 18,815,555\n",
            "Trainable params: 18,585,987\n",
            "Non-trainable params: 229,568\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "90/90 [==============================] - 210s 2s/step - loss: 1.5514 - accuracy: 0.3684 - val_loss: 17.4587 - val_accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 187s 2s/step - loss: 1.4738 - accuracy: 0.4014 - val_loss: 90.9408 - val_accuracy: 0.3200\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 188s 2s/step - loss: 1.3008 - accuracy: 0.4541 - val_loss: 212.8949 - val_accuracy: 0.3467\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 185s 2s/step - loss: 1.2142 - accuracy: 0.4840 - val_loss: 532.6926 - val_accuracy: 0.3467\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 185s 2s/step - loss: 1.1890 - accuracy: 0.5184 - val_loss: 519.9362 - val_accuracy: 0.4067\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 185s 2s/step - loss: 1.1370 - accuracy: 0.5389 - val_loss: 794.7221 - val_accuracy: 0.3600\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 186s 2s/step - loss: 1.0406 - accuracy: 0.5497 - val_loss: 497.6915 - val_accuracy: 0.4333\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 186s 2s/step - loss: 0.9829 - accuracy: 0.5865 - val_loss: 565.2631 - val_accuracy: 0.3800\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.9793 - accuracy: 0.5889 - val_loss: 1298.1631 - val_accuracy: 0.3800\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.9165 - accuracy: 0.6097 - val_loss: 2994.2971 - val_accuracy: 0.3333\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 190s 2s/step - loss: 0.9781 - accuracy: 0.5843 - val_loss: 3214.1611 - val_accuracy: 0.3333\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 188s 2s/step - loss: 0.8839 - accuracy: 0.6158 - val_loss: 2960.1968 - val_accuracy: 0.3333\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 188s 2s/step - loss: 0.8439 - accuracy: 0.6204 - val_loss: 1519.1516 - val_accuracy: 0.3600\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.8865 - accuracy: 0.6259 - val_loss: 1466.4403 - val_accuracy: 0.3533\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 188s 2s/step - loss: 0.8642 - accuracy: 0.6441 - val_loss: 3491.0759 - val_accuracy: 0.3333\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 186s 2s/step - loss: 0.7979 - accuracy: 0.6498 - val_loss: 2691.4907 - val_accuracy: 0.3333\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.8269 - accuracy: 0.6297 - val_loss: 2147.3809 - val_accuracy: 0.3333\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.8426 - accuracy: 0.6497 - val_loss: 1387.5743 - val_accuracy: 0.3267\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.7977 - accuracy: 0.6432 - val_loss: 1071.7958 - val_accuracy: 0.3333\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - 188s 2s/step - loss: 0.7532 - accuracy: 0.6595 - val_loss: 1998.0800 - val_accuracy: 0.3333\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.7711 - accuracy: 0.6811 - val_loss: 2611.9724 - val_accuracy: 0.3333\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - 188s 2s/step - loss: 0.7764 - accuracy: 0.6607 - val_loss: 2002.9758 - val_accuracy: 0.3333\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - 189s 2s/step - loss: 0.7512 - accuracy: 0.6813 - val_loss: 1475.3505 - val_accuracy: 0.3333\n",
            "Epoch 24/100\n",
            "74/90 [=======================>......] - ETA: 33s - loss: 0.7380 - accuracy: 0.6769"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f7e4e121d04a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdiagramm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0my_pred_model1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0my_test_model1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}